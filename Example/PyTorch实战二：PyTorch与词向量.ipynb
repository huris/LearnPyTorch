{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a4be70",
   "metadata": {},
   "source": [
    "论文《Distributed Representations of Words and Phrases and their Compositionality》：https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf51ae4f",
   "metadata": {},
   "source": [
    "# 词向量基础\n",
    "\n",
    "计算机中如何表示一个词：“John likes to watch movies. Mary likes too.”\n",
    "\n",
    "计算机表示会生成一个词典：{\"John\":1, \"likes\":2, \"to\":3, \"watch\":4, \"movies\":5, \"also\":6, \"football\":7, \"games\":8, \"Mary\":9, \"too\":10}\n",
    "\n",
    "词典包含10个单词，每个单词有唯一的索引。\n",
    "\n",
    "开始的时候，使用one-hot方式表示每个词，即建立一个和词典一样大小的向量，然后该单词索引的位置用1，其他位置用0表示。\n",
    "- john:[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "- likes:[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "- too:[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "\n",
    "这是一种离散方式的表示，但至少计算机能读懂了。\n",
    "\n",
    "这样的方式有个问题，由于每个向量只有一个1，其余位置为0，并且互相的内积都是0。使得这些词之间没有关联互相独立。但实际情况肯定不是这样子（例如苹果和橘子的关联肯定比苹果和国王的关联要强），这使得算法对相关词的泛化能力不强。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77081a9d",
   "metadata": {},
   "source": [
    "换一种方式描述词，例如：Man, Woman, King, Queen, Apple, Orange，寻找一些特征，比如是否与性别有关，是否与高贵程度有关，是否与年龄有关，是否与食物有关，这样每个词都可能得到一种下面的表示方式：\n",
    "<img style=\"float: center;\" src=\"images/2.png\" width=\"70%\">\n",
    "\n",
    "如果用这种方法来表示苹果和橘子，则苹果和橘子肯定会非常相似，至少大部分特征是一样的，对于已经知道橙子果汁的算法，很大几率会明白苹果果汁是什么东西。\n",
    "\n",
    "对于不同的单词，算法会泛化地更好，并且，我们找的特征的个数一般会比词典小得多，比如找300个特征，则描述每个词的向量是300维，也比之前的one-hot的方式维度小得多。\n",
    "\n",
    "这种捕捉到单词之间关联称为**词嵌入表示（Word-Embedding）**\n",
    "\n",
    "如何得到这种表示？\n",
    "\n",
    "首先需要一个嵌入矩阵Embedding Matrix，一开始用one-hot，即字典的位置表示每个词，然后通过嵌入矩阵，得到每个词的词嵌入向量：\n",
    "<img style=\"float: center;\" src=\"images/3.png\" width=\"70%\">\n",
    "\n",
    "事先训练好一个词嵌入矩阵，该矩阵中每一列就是每个单词的词向量，每一行表示一个特征，上图300\\*10000的矩阵，就是10000个单词，每个单词从300个特征上进行衡量。\n",
    "\n",
    "有了这样一个矩阵之后，拿这个矩阵乘以每个单词自己的one-hot表示，就会得到每个单词的词向量表示。\n",
    "\n",
    "词嵌入矩阵如何获取？\n",
    "- 早先的时候，使用自然语言模型计算嵌入矩阵\n",
    "- 例如：I want a glass of orange______\n",
    "- 想让计算机填juice，嵌入矩阵未知，可以构建下面的神经网络进行训练：\n",
    "<img style=\"float: center;\" src=\"images/4.png\" width=\"70%\">\n",
    "\n",
    "把嵌入矩阵也当作一层参数W，通过梯度下降的方式得到。\n",
    "\n",
    "在训练网络的时候，不仅有orange juice，还有apple juice，在这个算法的激励下，苹果和橘子会学到很相似的嵌入，这样做能够让算法更好地符合训练集。因为它有时看到orange juice，有时看到apple juice，如果只有一个300维的特征向量来表示这些词，算法就会发现，要想更好地拟合数据集，就要使苹果，橘子，梨，葡萄等水果都具有相似的特征向量，这就是早期最成功的学习嵌入矩阵的算法之一。\n",
    "\n",
    "但是如果单单为了得到嵌入矩阵而去训练一个模型会很复杂且耗时，于是人们想出一种简单的方式学习词嵌入（选上下文的方式），比如单纯只为了得到嵌入矩阵，根本没必要用一句话进行训练，选用几个单词对或者短语就可以，比如要预测juice，就可以把这个当作target，然后只考虑它周围的词就可以了（orange，a glass of orange等等这些就可以了）\n",
    "\n",
    "一般通过某个单词周围的一些词就基本上海可以知道这个词的意思，比如单词bank，一般它周围的词都是money，government，finance等等，通过这些就可以推测bank与什么有关系了。这种上下文方式学习单词之间的关联，比起建立一个语言模型来说，要容易地多。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4fd94e",
   "metadata": {},
   "source": [
    "那么，对于一个句子，如何选择上下文和目标词呢？\n",
    "\n",
    "可以用Skip-Gram模型，做法是**抽取上下文和目标词配对，来构造一个监督学习问题**。\n",
    "\n",
    "这里的上下文不一定总是目标单词之前离得最近的4个单词或最近的n个单词，我们要做的是：\n",
    "- 首先随机选择一个单词作为context，例如：orange\n",
    "- 然后随机在一定距离内选另外一个词作为target（使用一个宽度为5或10的滑动窗口，在context附近选择一个单词作为target），可以是juice，glass，my等等。\n",
    "- 最终得到多个【context-target对】作为监督学习样本\n",
    "<img style=\"float: center;\" src=\"images/1.jpg\" width=\"70%\">\n",
    "\n",
    "skip-gram模型如何训练：\n",
    "- 假设单词数为10000，随机选择上下文context c(\"orange\")，然后根据滑动距离随机选择一个target t(\"juice\")，让神经网络学习这个映射：\n",
    "<img style=\"float: center;\" src=\"images/2.jpg\" width=\"70%\">\n",
    "\n",
    "训练的过程构建自然语言模型，经过softmax单元的输出为：$p(t|c)=\\frac{e^{\\theta^T_te_c}}{\\sum^{10000}_{j=1}e^{\\theta^T_je_c}}$\n",
    "\n",
    "其中，$\\theta_t$为target对应的参数，$e_c$为context的embedding vector，即$e_c=E\\cdot o_c$\n",
    "\n",
    "相应的loss函数为：$L(\\hat{y},y)=-\\sum^{10000}_{i=1}y_i\\log\\hat{y_i}$\n",
    "\n",
    "之后使用梯度下降算法，迭代优化，最终得到嵌入矩阵E。\n",
    "\n",
    "以上就是Skig-Gram模型：它把一个单词orange作为输入，并预测这个词从左数或者从右数的某个词，预测上下文词前面或后面的一些词是什么词。\n",
    "\n",
    "简单理解：有一些正确的单词对，想让模型做一个训练，把上下文输入进去，预测出最终的目标。比如有orange-juice，orange-glass，orange-my，当输入orange时，分别输出后面的三个单词，这样训练好的时候，就可以通过中心词去预测周围的单词了。\n",
    "\n",
    "Skip-Gram模型是Word2Vec的一种，Word2Vec另一种模型CBOW（Continuous Bag of Words），它获得中间词两边的上下文，去预测中间的词。\n",
    "\n",
    "**缺点：**\n",
    "- softmax公式中分母是求和，如果有10000个单词的时候，模型最后输出的时候都要考虑进来，10000个单词究竟哪个单词概率最大。（计算量过大）\n",
    "- 论文中提到两个解决方法：\n",
    "  - 层级softmax分类（Hierarchical softmax classifier）\n",
    "  - 负采样方式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2910197",
   "metadata": {},
   "source": [
    "**负采样方式（Negative sample）**：判断选取的context和target是否构成一组正确的context-target对，一般包含一个正样本和k个负样本，例如：\n",
    "- “orange”为context word，“juice”为target word，很明显“orange juice”是一组context-target对，为正样本，相应的target label为1。\n",
    "- “orange”为context word不变，target word随机选择“king”、“book”、“the”或者“of”等。这些都是错误的context-target对，为负样本，相应的target label为0。\n",
    "\n",
    "这就是如何生成训练集的方法，选一个正样本和k个负样本。\n",
    "\n",
    "固定某个context word对应的负样本个数k遵循：\n",
    "- 若训练样本较小，k一般选择5-20\n",
    "- 若训练样本较大，k一般选择2-5即可"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed226e0f",
   "metadata": {},
   "source": [
    "**从x映射到y的监督模型**\n",
    "<img style=\"float: center;\" src=\"images/5.png\" width=\"70%\">\n",
    "\n",
    "负采样的数学模型：$P(y=1|c, t)=\\sigma\\left(\\theta^T_t, e_c\\right)$\n",
    "\n",
    "其中，$\\sigma$表示sigmoid激活函数，某个固定的正样本对应k个负样本（模型共包含k+1个二分类，对比之前的10000个输出单元的softmax分类，计算量小很多，大大提高模型运算速度）\n",
    "\n",
    "每一次训练，都是k+1个二分类问题，就看target的那几个是不是我们想要的0或者1，然后用这几个去计算损失更新参数即可。\n",
    "\n",
    "如何选择负样本对应的target单词？可以随机选择，但论文中提出一个更实用、效果更好的方法，就是根据该词出现的频率进行选择，概率公式为：$P(w_i)=\\frac{f(w_i)^{3/4}}{\\sum^{10000}_jf(w_j)^{3/4}}$\n",
    "\n",
    "论文中损失函数：$loss=\\log\\sigma\\left(v_{w_O}^{'T}v_{w_I}\\right)+\\sum^k_{i=1}\\mathbb{E}_{w_i\\sim P_n(w)}\\left[\\log\\sigma(-v_{w_i}^{'T}v_{w_I})\\right]$\n",
    "\n",
    "损失函数理解：输入时选择的上下文，即此处的$v_{w_I}$，是embedding之后的向量，而输出是正负样本的embedding后的向量。\n",
    "\n",
    "前面部分是正样本和上下文的关系，$v_{w_O}$就是正样本embedding后的形式，两个内积操作就是两者的关系程度（内积的几何意义，如果两个向量的关系越接近，则内积就会越大），后面那部分是负样本和上下文的关系，希望上下文与正样本的关系尽可能的近，也就是前面那部分越大越好，希望负样本与上下文的关系尽可能的小，但是后面发现内积前加了个负号，那就表示后面那部分越大越好。（最终损失函数越大越好，因此后面的损失函数要取相反数-loss）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93d635a",
   "metadata": {},
   "source": [
    "# 实现skip-gram模型\n",
    "\n",
    "思路：\n",
    "- 建立一个词汇表（字典），根据训练集进行构建\n",
    "- 根据这个词汇表，建立模型训练\n",
    "- 训练过程中保存模型参数，测试的时候导入就可以直接进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8668ef98",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e25b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as tud\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "# 为了保证实验结果可以复现，经常把random seed固定在某一个值\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(1)\n",
    "\n",
    "# 设置超参数\n",
    "K = 100    # 负样本的个数, 每一个正样本对应100个负样本\n",
    "C = 3    # 附近单词的门限\n",
    "NUM_EPOCHS = 2   # 训练epoch数\n",
    "MAX_VOCAB_SIZE = 30000   # 词典中单词的个数\n",
    "LEARNING_RATE = 0.2   # 初始学习率\n",
    "EMBEDDING_SIZE = 100   # 词向量特征的个数\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "LOG_FILE = \"word_embedding.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af99547c",
   "metadata": {},
   "source": [
    "## 构建一张词汇表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc873e08",
   "metadata": {},
   "source": [
    "从文本文件中读取所有的文字，然后通过这些文字创建一个vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d38ee12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize函数，把一篇文本转成一个个单词\n",
    "def word_tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "with open(\"./data/text8.train.txt\", 'r') as fin:\n",
    "    text = fin.read()\n",
    "\n",
    "# 把每句话的单词分开\n",
    "text = [w for w in word_tokenize(text.lower())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a4a599",
   "metadata": {},
   "source": [
    "单词数量过大，选择最常见的30000个单词，后面不常用的统一用unk表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "333b3baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dict(Counter(text).most_common(MAX_VOCAB_SIZE - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f385f379",
   "metadata": {},
   "source": [
    "添加一个UNK单词表示所有不常见的单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c338dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab[\"<unk>\"] = len(text) - np.sum(list(vocab.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc65f1",
   "metadata": {},
   "source": [
    "记录每个单词的index的mapping，以及index到单词的mapping，单词的count，单词frequency，以及单词总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a41421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立映射\n",
    "idx_to_word = [word for word in vocab.keys()]\n",
    "word_to_idx = {word: i for i, word in enumerate(idx_to_word)}\n",
    "\n",
    "# 统计单词的频率和个数\n",
    "word_counts = np.array([count for count in vocab.values()], dtype=np.float32)\n",
    "word_freqs = word_counts / np.sum(word_counts)\n",
    "word_freqs = word_freqs ** (3./4.)\n",
    "word_freqs = word_freqs / np.sum(word_freqs)  # 论文中的计算频率的公式，选择中心词用\n",
    "VOCAB_SIZE = len(idx_to_word)   # 30000个单词的词表建立完毕"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf07072",
   "metadata": {},
   "source": [
    "## 实现DataLoader\n",
    "\n",
    "DataLoader，是PyTorch中数据读取的一个重要接口，该接口定义在dataloader.py中，只要是用PyTorch来训练模型基本上都会用到这个接口。\n",
    "\n",
    "目的：将自定义的Dataset根据batch size大小，是否shuffle等封装成一个batch size大小的Tensor，用于后面的训练。\n",
    "\n",
    "有了Dataloader之后，就可以轻松随机打乱整个数据集，拿到一个batch size的数据。\n",
    "\n",
    "注意：\n",
    "- dataloader本质是一个可迭代对象，使用iter()访问，不能使用next()访问\n",
    "- 使用iter(dataloader)返回一个迭代器，然后使用next访问\n",
    "- 可以使用`for inputs, labels in dataloaders`进行可迭代对象的访问\n",
    "- 同时需要实现dataset对象，传入到dataloader中，然后内部使用yeild返回每一次 batch的数据\n",
    "\n",
    "一个比较好的写Dataloader教程：https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "torch.utils.data.Dataset表示数据集的抽象类，自定义数据集应继承Dataset并覆盖以下方法：\n",
    "- \\_\\_len\\_\\_：函数需要返回整个数据集中有多少个item，之后通过len(dataset)返回数据集大小\n",
    "- \\_\\_getitem\\_\\_：根据给定的index返回一个item，dataset[i]可以用于获取第i个样本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f6008b",
   "metadata": {},
   "source": [
    "当前任务中，dataloader需要获取以下内容：\n",
    "- 所有text编码成数字，然后用二次采样处理这些数字\n",
    "- 保存字典表，单词数，词频\n",
    "- 每个iteration sample一个中心词\n",
    "- 根据当前中心词返回context单词\n",
    "- 根据中心词采样一些负样本单词\n",
    "- 返回单词的counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d98a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先，DataLoader继承torch.utils.data.Dataset\n",
    "class WordEmbeddingDataset(tud.Dataset):\n",
    "    # 把上面有的先保存下来\n",
    "    def __init__(self, text, word_to_idx, idx_to_word, word_freqs, word_counts):\n",
    "        ''' \n",
    "        text: a list of words, all text from the training dataset\n",
    "        word_to_idx: the dictionary from word to idx\n",
    "        idx_to_word: idx to word mapping\n",
    "        word_freqs: the frequency of each word\n",
    "        word_counts: the word counts\n",
    "        '''\n",
    "        super(WordEmbeddingDataset, self).__init__()\n",
    "        # 训练集的每个单词在词典中的位置\n",
    "        self.text_encode = [word_to_idx.get(word, VOCAB_SIZE - 1) for word in text]\n",
    "        # 转成张量\n",
    "        self.text_encode = torch.Tensor(self.text_encode).long()\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.idx_to_word = idx_to_word\n",
    "        self.word_freqs = word_freqs\n",
    "        self.word_counts = torch.Tensor(word_counts)\n",
    "\n",
    "    # 返回整个数据集（所有单词的长度）\n",
    "    def __len__(self):\n",
    "        return len(self.text_encode)\n",
    "\n",
    "    # 实现getitem函数  这个告诉模型应该怎么取数据，这是关键\n",
    "    def __getitem__(self, idx):\n",
    "        ''' 这个function返回以下数据用于训练\n",
    "        - 中心词\n",
    "        - 这个单词附近的(positive)单词\n",
    "        - 随机采样的K个单词作为negative sample\n",
    "        '''\n",
    "        center_word = self.text_encode[idx]  # 中心词的位置\n",
    "        # Windows的index\n",
    "        pos_indics = list(range(idx - C,idx)) + list(range(idx + 1, idx + C + 1))\n",
    "        # 取余， 防止超出text的长度\n",
    "        pos_indics = [i % len(self.text_encode) for i in pos_indics]\n",
    "        pos_words = self.text_encode[pos_indics]  # 正样本取周围单词\n",
    "         # 根据单词的频率采样，对于每一个正确的单词，要采集K个错误的单词\n",
    "        neg_words = torch.multinomial(torch.tensor(self.word_freqs), K * pos_words.shape[0], True)\n",
    "\n",
    "        return center_word, pos_words, neg_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3759e717",
   "metadata": {},
   "source": [
    "新建一个dataset和DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc329e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WordEmbeddingDataset(text, word_to_idx, idx_to_word, word_freqs, word_counts)\n",
    "dataset.text_encode.size()   # 15304686个单词\n",
    "\n",
    "# 有了dataset之后，就可以非常简单的用DataLoader变成一个DataLoader\n",
    "# 这样可以非常轻松的产生batch， 并且可以shuffle\n",
    "dataloader = tud.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf86520",
   "metadata": {},
   "source": [
    "取Batch的时候就非常简单了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c532087a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 1769,    62,    11, 21115,  6716, 29999,  1045,   138,   460, 29999,\n",
       "         29999, 29999,     1,    18,  9235,     2,  8312,     9, 13824, 29999,\n",
       "         29999,  1714,    22,  1562,     0,    30,     0,     0,    22,   990,\n",
       "           445,    33,  4390,  7219,     0,   255,  1217,     5,     1,     4,\n",
       "            29,    20,     0,  2487,  1534,   991,     3,    18,    28,   141,\n",
       "           193,  2800,     1,     9,   337,   127,   157,   149,   107,   236,\n",
       "             6,    84,    43, 29828,    52,   403,   186,    83,  1265,   552,\n",
       "             2,   595,  2798,    33,    12,  8462,    10,   127,  8872,  1514,\n",
       "          6620,   217,     1,  3680,  5804,     5, 29999,   956, 19058, 21389,\n",
       "           495,    39,    30,   349,   416,    11,     5,     1,     1,     6,\n",
       "             1,   122,   211,  2719,   873,     0,    22, 24620,    22,    93,\n",
       "             0,   535,    99,  1734,     3,  1269,  5909,     3,    15,  5069,\n",
       "          1706, 17024, 29999,    28,   169,   129,  5025, 10759]),\n",
       " tensor([[27921,     1,   107,  3219,    40,     5],\n",
       "         [ 3832,   634,  1536,   116,  2567,   938],\n",
       "         [  661,   296,   620,   227,   774,  4676],\n",
       "         [   98,  8425,    29,    34,  1069,    60],\n",
       "         [   22,   253,    66, 16886,    38,    49],\n",
       "         [29999,   604, 29999,  4965,     3,     8],\n",
       "         [ 2274,  1081,    10,     4,     0,  2128],\n",
       "         [   11,    30,   616, 29999,    17,    52],\n",
       "         [   15,     7,    22, 10132,     6, 14444],\n",
       "         [   51, 29999,     2,    32,   194,    10],\n",
       "         [13251,     0,   540,    17,    37, 29392],\n",
       "         [   86,    11, 26305,     4,     0,    42],\n",
       "         [ 6604,     0,   553,     0,  6818,   387],\n",
       "         [  496,   246,   331,   482,   312,     0],\n",
       "         [28413,   451,   400,  1494,  1861,     1],\n",
       "         [  245,   143, 29999, 29999,     7,  4501],\n",
       "         [ 6623,    26,    68,    75,  3511,    76],\n",
       "         [    9,    15,     3,     7,     7,    15],\n",
       "         [ 1812,     1,  3571,  9824,     0,   258],\n",
       "         [ 1535,   811,   877,  1535,   811,   877],\n",
       "         [    3,    20,     9, 26166,   537,    16],\n",
       "         [ 1326,   168,   639, 29999,   325, 11916],\n",
       "         [    3,     8,    15,    26,    17,   108],\n",
       "         [10360,     2,   940,    60,     5,   182],\n",
       "         [    2,  2319,    24,  4398,     1,   458],\n",
       "         [    0,  3476,    38,   139,  1114,  3434],\n",
       "         [    5, 26413,   143,  1797,    17,    45],\n",
       "         [  617,    46,   736, 14267,    55,  3435],\n",
       "         [    3,     8,     3, 29999, 12448,  7130],\n",
       "         [   22,    15, 29999,    17,     0,    45],\n",
       "         [  142,     0,  9504,    10,   205,  1181],\n",
       "         [    2,  1305, 28342,  1968,     5,   979],\n",
       "         [  420,   711,  2959,     1, 29999,     4],\n",
       "         [    3,    16,    12,    47,   527,     0],\n",
       "         [   11,   470,     1, 29999,     2,   780],\n",
       "         [   31,  4261,    23,    96,   108,     1],\n",
       "         [  199,   238,   100, 13330,     1,  1259],\n",
       "         [  232,     6,    31,   851,  1244,  1210],\n",
       "         [    1,  2191,  2570,   112,     1,  2191],\n",
       "         [    2,   731,  5379,     3,     8,     3],\n",
       "         [    0,   125,  6752,   686,    18,  5659],\n",
       "         [    9,     7,     7,     0, 17323,    40],\n",
       "         [    1,   158,     1,   674,  2110,   302],\n",
       "         [ 1625,  2125,     2,   374, 28455,     4],\n",
       "         [   19,     0,    66,  5072,  3224,  5683],\n",
       "         [11916,   991, 29999,  6102,   634,   524],\n",
       "         [13946,   277,   118,     8,     8,    12],\n",
       "         [    0,   246,   365, 18480, 13442,     4],\n",
       "         [  619,   598,  8108,   227,  8108,    26],\n",
       "         [ 1978,    18,   183,  2042,  3594,   511],\n",
       "         [   90,  1265,  1901,     1,    50,    63],\n",
       "         [ 8943, 12354,     0,  1355,     2,    89],\n",
       "         [   17,     5,   928,  8299,     1,  3773],\n",
       "         [    3,    12,     3,  3180, 12330, 29999],\n",
       "         [  389,     0,   246,     2,  1090,     4],\n",
       "         [   29,  3445,    27,  3698,   185,    29],\n",
       "         [11829,    28, 10866,  2075,     3,    20],\n",
       "         [ 7794,     1,     0, 12126,     1,     0],\n",
       "         [   18,  4313,    19,   767,    72,    70],\n",
       "         [  932,  1981,     4,   788,  4574,  3862],\n",
       "         [   37,    31, 16090,    11,     0, 29999],\n",
       "         [    2,   114,     0,    80,   773,  1456],\n",
       "         [  804, 12614,     2,  2046,     4,   187],\n",
       "         [ 1705,  1218,    18,    35,    17,  1369],\n",
       "         [  838,   609,     0,  7808,  4002, 10387],\n",
       "         [ 2060,    47, 13230,     0, 29999,     2],\n",
       "         [   27, 23856,    25,  3948,    23,     0],\n",
       "         [ 6476,     6,    52,    26,    10,   696],\n",
       "         [ 7862,    13,     0,   435,    41,    26],\n",
       "         [   53,    56,  9364,   582,     0,  1797],\n",
       "         [ 2546,    23,    65,    42, 29999,  4262],\n",
       "         [  465,    82,     4,     2,  3584,     1],\n",
       "         [ 2549,  1472,     2,  2005,    19,    33],\n",
       "         [   16,     7,    14,  1167,    34, 14015],\n",
       "         [  398,   274,     7,    20,     9,    16],\n",
       "         [   55,   288,     0,     1,     0,   376],\n",
       "         [  215,     6,  5502,   696,     6, 24355],\n",
       "         [ 4479,     4,     0,    81,     1,     0],\n",
       "         [ 5458,  6299,    23,    49, 14646, 29424],\n",
       "         [ 1192,     6,    31, 17208,  4060,  1592],\n",
       "         [    1,  7227,    67,     2,  3004,  3581],\n",
       "         [  941,  1300,    23,  1918,  6600,  4329],\n",
       "         [    0,   413,   113,  6058,    26,    40],\n",
       "         [    0,  2736,   524,     5,   874,    23],\n",
       "         [   14,   159,  6298,  1967,    38,   265],\n",
       "         [16474,   188, 14056,   122,  4866,   109],\n",
       "         [    1,     0, 29999, 29999,     5,   170],\n",
       "         [ 1702,     2,     0,  3249,    10,  6748],\n",
       "         [   45,  2249, 15372,  2155,   987,    24],\n",
       "         [  738,    24,     0,   421,     3,     9],\n",
       "         [    2, 22746,  1041,    13,    21,    81],\n",
       "         [    0,  8999,  3115,   108,    64,  8659],\n",
       "         [  347,    18, 11663,  2067,   223,  3300],\n",
       "         [14809, 18381,  2367,    23, 29999, 29999],\n",
       "         [  355,     5,  1485,     4,    44,  1213],\n",
       "         [ 1699,    11,   110,    42, 17711,   105],\n",
       "         [    0,  4378,    34,  1818,     1,     0],\n",
       "         [  148,   300,   121,   325,   570,   225],\n",
       "         [    5,   171,   137,     5, 29999,  2936],\n",
       "         [   28,   603, 10573,    31,    59,     4],\n",
       "         [    0,   979, 28719,  1363,     4,   387],\n",
       "         [ 3548,  5920,    13, 14810,  8828,    27],\n",
       "         [ 2763,    26, 29999,    12,    20,     7],\n",
       "         [  143,     1,     0,  5336,  1628,   962],\n",
       "         [ 7466,    50,     1,    39,  1705,   948],\n",
       "         [    0,   172,    10,   120,     1,     5],\n",
       "         [    4,    29,     3,    12,    15,  2973],\n",
       "         [    7,     7,     8,     9,     7,     7],\n",
       "         [  128,     9,     3,   128,    21,   128],\n",
       "         [  114,    32,  2546,    19,     0, 19029],\n",
       "         [   20,     2,     4,   937,     3,     8],\n",
       "         [   13,    44, 29999,     2,    40,    37],\n",
       "         [ 3267,     6, 29999,    26,  1284,   235],\n",
       "         [    0, 26803,  2946,    32,   860,     4],\n",
       "         [ 1278,   731,     2,   161,  3112,   211],\n",
       "         [    0,  1598,     2,    32,   298,  1991],\n",
       "         [    1,    16,  3998,    19,    25,  2796],\n",
       "         [   12,     9,    16,    12,     8,    20],\n",
       "         [   22,     3,     8,     3,   506,     3],\n",
       "         [ 3402,    34,  4350,     6,   181,    97],\n",
       "         [    1,   468,   845,     1, 14700,     2],\n",
       "         [    1,   593,  2870, 12722,    10,   148],\n",
       "         [  742,  1811,    74,     2, 19377,     0],\n",
       "         [  256,    97,  3249,  6112,  7338,   213],\n",
       "         [ 4258, 11709,  2797,   156,  3120, 29999],\n",
       "         [    8,     3,    20,    12,     8,     3],\n",
       "         [  261,     4,  1856,   321,     6,     5],\n",
       "         [   82,  5767,     2, 20954,    79,     5]]),\n",
       " tensor([[  168,    64,  2609,  ...,    51,  1945, 22262],\n",
       "         [19960,  2187,   130,  ...,   270,    36,  4065],\n",
       "         [ 1925,    48,    47,  ...,  3761,  5751,  3052],\n",
       "         ...,\n",
       "         [ 1535,     9,   361,  ...,     5,     5,  4420],\n",
       "         [  449,   585, 13442,  ...,   154,  1150, 14522],\n",
       "         [ 6520,    20,   386,  ...,  8337,   766,  1115]])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i, (center_work, pos_words, neg_words) in enumerate(dataloader):\n",
    "#     print(center_work, pos_words, neg_words)\n",
    "\n",
    "# 这一个就会得到BATCH_SIZE个数据样本，每个数据样本都是中心词，正样本和负样本的形式\n",
    "next(iter(dataloader))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99be2f0",
   "metadata": {},
   "source": [
    "## 定义PyTorch模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a1e1d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        \"\"\"初始化输入和输出的embedding\"\"\"\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        # 初始化\n",
    "        initrange = 0.5 / self.embed_size\n",
    "        self.out_embed = nn.Embedding(self.vocab_size, self.embed_size, sparse=False)\n",
    "        self.out_embed.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "        self.in_embed = nn.Embedding(self.vocab_size, self.embed_size, sparse=False)\n",
    "        # 这是在范围直接均匀分布采样\n",
    "        self.in_embed.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, input_labels, pos_labels, neg_labels):\n",
    "        \"\"\"\n",
    "        input_labels: 中心词, [batch_size]\n",
    "        pos_labels: 中心词周围 context window 出现过的单词 [batch_size * (window_size * 2)]\n",
    "        neg_labels: 中心词周围没有出现过的单词，从 negative sampling 得到 [batch_size, (window_size * 2 * K)]\n",
    "\n",
    "        return: loss, [batch_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = input_labels.size(0)\n",
    "\n",
    "        input_embedding = self.in_embed(input_labels) # batchsize * embed_size\n",
    "        pos_embedding = self.out_embed(pos_labels)   # batchsize*(2*c)*embed_size\n",
    "        neg_embedding = self.out_embed(neg_labels) # batch_size * (2*C*K) * embed_size\n",
    "\n",
    "        # 计算损失\n",
    "        input_embedding = input_embedding.unsqueeze(2)  # [batchsize,embed_size, 1]\n",
    "        log_pos = torch.bmm(pos_embedding, input_embedding).squeeze()   # [batchsize, 2*C]\n",
    "        log_neg = torch.bmm(neg_embedding, -input_embedding).squeeze()   # [batchsize, 2*C*100]\n",
    "\n",
    "        log_pos = F.logsigmoid(log_pos).sum(1)\n",
    "        log_neg = F.logsigmoid(log_neg).sum(1)\n",
    "\n",
    "        loss = log_pos + log_neg\n",
    "\n",
    "        return -loss\n",
    "\n",
    "    def input_embeddings(self):\n",
    "        return self.in_embed.weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcca9a8",
   "metadata": {},
   "source": [
    "定义PyTorch模型，移动到GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14894c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmbeddingModel(VOCAB_SIZE, EMBEDDING_SIZE)\n",
    "if USE_CUDA:\n",
    "    model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb1f86e",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "\n",
    "前向传播，计算损失，梯度清零，反向传播，参数更新\n",
    "\n",
    "- 模型一般需要训练若干个epoch\n",
    "- 每个epoch需要把所有数据分成若干个batch\n",
    "- 每个batch的输入和输出都包装成cuda tensor\n",
    "- 前向传播时，通过输入的句子预测每个单词的下一个单词\n",
    "- 用预测的模型和正确的下一个单词计算交叉熵损失\n",
    "- 清空模型当前的梯度\n",
    "- 反向传播\n",
    "- 更新模型参数\n",
    "- 每隔一定的iteration输出模型在当前iteration的loss，并且保存参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "870b9c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 0, loss: 420.0471496582031\n",
      "epoch: 0, iter: 100, loss: 293.7235107421875\n",
      "epoch: 0, iter: 200, loss: 218.88555908203125\n",
      "epoch: 0, iter: 300, loss: 173.64022827148438\n",
      "epoch: 0, iter: 400, loss: 144.0834503173828\n",
      "epoch: 0, iter: 500, loss: 141.6793212890625\n",
      "epoch: 0, iter: 600, loss: 117.61723327636719\n",
      "epoch: 0, iter: 700, loss: 135.5240020751953\n",
      "epoch: 0, iter: 800, loss: 98.03471374511719\n",
      "epoch: 0, iter: 900, loss: 96.02230072021484\n",
      "epoch: 0, iter: 1000, loss: 86.41474151611328\n",
      "epoch: 0, iter: 1100, loss: 92.35974884033203\n",
      "epoch: 0, iter: 1200, loss: 87.557373046875\n",
      "epoch: 0, iter: 1300, loss: 75.23333740234375\n",
      "epoch: 0, iter: 1400, loss: 85.7183609008789\n",
      "epoch: 0, iter: 1500, loss: 75.12042236328125\n",
      "epoch: 0, iter: 1600, loss: 69.20245361328125\n",
      "epoch: 0, iter: 1700, loss: 70.73925018310547\n",
      "epoch: 0, iter: 1800, loss: 71.04591369628906\n",
      "epoch: 0, iter: 1900, loss: 69.52195739746094\n",
      "epoch: 0, iter: 2000, loss: 65.73233032226562\n",
      "epoch: 0, iter: 2100, loss: 69.12045288085938\n",
      "epoch: 0, iter: 2200, loss: 62.132408142089844\n",
      "epoch: 0, iter: 2300, loss: 61.12019348144531\n",
      "epoch: 0, iter: 2400, loss: 55.852439880371094\n",
      "epoch: 0, iter: 2500, loss: 51.04369354248047\n",
      "epoch: 0, iter: 2600, loss: 57.56987762451172\n",
      "epoch: 0, iter: 2700, loss: 56.82640075683594\n",
      "epoch: 0, iter: 2800, loss: 50.07099914550781\n",
      "epoch: 0, iter: 2900, loss: 60.39891815185547\n",
      "epoch: 0, iter: 3000, loss: 55.851070404052734\n",
      "epoch: 0, iter: 3100, loss: 60.827754974365234\n",
      "epoch: 0, iter: 3200, loss: 52.06648635864258\n",
      "epoch: 0, iter: 3300, loss: 52.550811767578125\n",
      "epoch: 0, iter: 3400, loss: 46.157264709472656\n",
      "epoch: 0, iter: 3500, loss: 51.12921142578125\n",
      "epoch: 0, iter: 3600, loss: 52.87408447265625\n",
      "epoch: 0, iter: 3700, loss: 51.89888000488281\n",
      "epoch: 0, iter: 3800, loss: 53.42438507080078\n",
      "epoch: 0, iter: 3900, loss: 48.46092987060547\n",
      "epoch: 0, iter: 4000, loss: 47.32019805908203\n",
      "epoch: 0, iter: 4100, loss: 44.7050895690918\n",
      "epoch: 0, iter: 4200, loss: 44.42438888549805\n",
      "epoch: 0, iter: 4300, loss: 52.464237213134766\n",
      "epoch: 0, iter: 4400, loss: 41.12849044799805\n",
      "epoch: 0, iter: 4500, loss: 38.832557678222656\n",
      "epoch: 0, iter: 4600, loss: 42.68098449707031\n",
      "epoch: 0, iter: 4700, loss: 36.003353118896484\n",
      "epoch: 0, iter: 4800, loss: 41.26023864746094\n",
      "epoch: 0, iter: 4900, loss: 43.5975341796875\n",
      "epoch: 0, iter: 5000, loss: 38.413902282714844\n",
      "epoch: 0, iter: 5100, loss: 48.06983947753906\n",
      "epoch: 0, iter: 5200, loss: 36.530181884765625\n",
      "epoch: 0, iter: 5300, loss: 40.507225036621094\n",
      "epoch: 0, iter: 5400, loss: 37.90652084350586\n",
      "epoch: 0, iter: 5500, loss: 43.641170501708984\n",
      "epoch: 0, iter: 5600, loss: 39.7642822265625\n",
      "epoch: 0, iter: 5700, loss: 43.70899963378906\n",
      "epoch: 0, iter: 5800, loss: 39.736114501953125\n",
      "epoch: 0, iter: 5900, loss: 37.047218322753906\n",
      "epoch: 0, iter: 6000, loss: 44.807350158691406\n",
      "epoch: 0, iter: 6100, loss: 39.30834197998047\n",
      "epoch: 0, iter: 6200, loss: 40.746620178222656\n",
      "epoch: 0, iter: 6300, loss: 38.93003463745117\n",
      "epoch: 0, iter: 6400, loss: 42.04351043701172\n",
      "epoch: 0, iter: 6500, loss: 36.34111785888672\n",
      "epoch: 0, iter: 6600, loss: 39.3355827331543\n",
      "epoch: 0, iter: 6700, loss: 40.23935317993164\n",
      "epoch: 0, iter: 6800, loss: 40.11604690551758\n",
      "epoch: 0, iter: 6900, loss: 35.788272857666016\n",
      "epoch: 0, iter: 7000, loss: 38.29764175415039\n",
      "epoch: 0, iter: 7100, loss: 38.315338134765625\n",
      "epoch: 0, iter: 7200, loss: 35.042930603027344\n",
      "epoch: 0, iter: 7300, loss: 37.7515983581543\n",
      "epoch: 0, iter: 7400, loss: 39.998046875\n",
      "epoch: 0, iter: 7500, loss: 35.48125457763672\n",
      "epoch: 0, iter: 7600, loss: 42.00115203857422\n",
      "epoch: 0, iter: 7700, loss: 42.32521438598633\n",
      "epoch: 0, iter: 7800, loss: 35.38196563720703\n",
      "epoch: 0, iter: 7900, loss: 41.39175033569336\n",
      "epoch: 0, iter: 8000, loss: 35.35164260864258\n",
      "epoch: 0, iter: 8100, loss: 36.124568939208984\n",
      "epoch: 0, iter: 8200, loss: 36.868568420410156\n",
      "epoch: 0, iter: 8300, loss: 35.750553131103516\n",
      "epoch: 0, iter: 8400, loss: 41.631744384765625\n",
      "epoch: 0, iter: 8500, loss: 41.093421936035156\n",
      "epoch: 0, iter: 8600, loss: 38.18828582763672\n",
      "epoch: 0, iter: 8700, loss: 36.941612243652344\n",
      "epoch: 0, iter: 8800, loss: 36.512611389160156\n",
      "epoch: 0, iter: 8900, loss: 37.116912841796875\n",
      "epoch: 0, iter: 9000, loss: 34.129119873046875\n",
      "epoch: 0, iter: 9100, loss: 36.25969696044922\n",
      "epoch: 0, iter: 9200, loss: 37.04295349121094\n",
      "epoch: 0, iter: 9300, loss: 35.92828369140625\n",
      "epoch: 0, iter: 9400, loss: 36.294532775878906\n",
      "epoch: 0, iter: 9500, loss: 40.417808532714844\n",
      "epoch: 0, iter: 9600, loss: 33.68529510498047\n",
      "epoch: 0, iter: 9700, loss: 35.802459716796875\n",
      "epoch: 0, iter: 9800, loss: 35.43132019042969\n",
      "epoch: 0, iter: 9900, loss: 32.74837112426758\n",
      "epoch: 0, iter: 10000, loss: 35.13810729980469\n",
      "epoch: 0, iter: 10100, loss: 34.1575927734375\n",
      "epoch: 0, iter: 10200, loss: 34.70768356323242\n",
      "epoch: 0, iter: 10300, loss: 36.29407501220703\n",
      "epoch: 0, iter: 10400, loss: 35.351383209228516\n",
      "epoch: 0, iter: 10500, loss: 35.86524200439453\n",
      "epoch: 0, iter: 10600, loss: 38.92267608642578\n",
      "epoch: 0, iter: 10700, loss: 34.194091796875\n",
      "epoch: 0, iter: 10800, loss: 33.16425323486328\n",
      "epoch: 0, iter: 10900, loss: 33.9803581237793\n",
      "epoch: 0, iter: 11000, loss: 33.32054138183594\n",
      "epoch: 0, iter: 11100, loss: 34.61780548095703\n",
      "epoch: 0, iter: 11200, loss: 35.95698928833008\n",
      "epoch: 0, iter: 11300, loss: 33.62138366699219\n",
      "epoch: 0, iter: 11400, loss: 36.341064453125\n",
      "epoch: 0, iter: 11500, loss: 34.275447845458984\n",
      "epoch: 0, iter: 11600, loss: 32.7381477355957\n",
      "epoch: 0, iter: 11700, loss: 32.69459915161133\n",
      "epoch: 0, iter: 11800, loss: 34.28376007080078\n",
      "epoch: 0, iter: 11900, loss: 33.427947998046875\n",
      "epoch: 0, iter: 12000, loss: 33.820465087890625\n",
      "epoch: 0, iter: 12100, loss: 33.51532745361328\n",
      "epoch: 0, iter: 12200, loss: 34.442787170410156\n",
      "epoch: 0, iter: 12300, loss: 33.563907623291016\n",
      "epoch: 0, iter: 12400, loss: 36.36994934082031\n",
      "epoch: 0, iter: 12500, loss: 33.730010986328125\n",
      "epoch: 0, iter: 12600, loss: 33.490325927734375\n",
      "epoch: 0, iter: 12700, loss: 34.269012451171875\n",
      "epoch: 0, iter: 12800, loss: 34.04093933105469\n",
      "epoch: 0, iter: 12900, loss: 34.626869201660156\n",
      "epoch: 0, iter: 13000, loss: 33.1113395690918\n",
      "epoch: 0, iter: 13100, loss: 33.15306854248047\n",
      "epoch: 0, iter: 13200, loss: 33.31352615356445\n",
      "epoch: 0, iter: 13300, loss: 33.82627487182617\n",
      "epoch: 0, iter: 13400, loss: 33.275360107421875\n",
      "epoch: 0, iter: 13500, loss: 33.98160934448242\n",
      "epoch: 0, iter: 13600, loss: 33.49348449707031\n",
      "epoch: 0, iter: 13700, loss: 33.1262321472168\n",
      "epoch: 0, iter: 13800, loss: 32.864295959472656\n",
      "epoch: 0, iter: 13900, loss: 32.79798126220703\n",
      "epoch: 0, iter: 14000, loss: 33.19416809082031\n",
      "epoch: 0, iter: 14100, loss: 33.309600830078125\n",
      "epoch: 0, iter: 14200, loss: 36.783626556396484\n",
      "epoch: 0, iter: 14300, loss: 33.382102966308594\n",
      "epoch: 0, iter: 14400, loss: 33.954444885253906\n",
      "epoch: 0, iter: 14500, loss: 32.45714569091797\n",
      "epoch: 0, iter: 14600, loss: 32.52001190185547\n",
      "epoch: 0, iter: 14700, loss: 33.148197174072266\n",
      "epoch: 0, iter: 14800, loss: 32.174949645996094\n",
      "epoch: 0, iter: 14900, loss: 32.678123474121094\n",
      "epoch: 0, iter: 15000, loss: 32.79936981201172\n",
      "epoch: 0, iter: 15100, loss: 32.9019775390625\n",
      "epoch: 0, iter: 15200, loss: 32.2724609375\n",
      "epoch: 0, iter: 15300, loss: 33.454200744628906\n",
      "epoch: 0, iter: 15400, loss: 33.68815612792969\n",
      "epoch: 0, iter: 15500, loss: 37.29358673095703\n",
      "epoch: 0, iter: 15600, loss: 33.09666442871094\n",
      "epoch: 0, iter: 15700, loss: 32.13060760498047\n",
      "epoch: 0, iter: 15800, loss: 32.46369552612305\n",
      "epoch: 0, iter: 15900, loss: 32.44892120361328\n",
      "epoch: 0, iter: 16000, loss: 33.339569091796875\n",
      "epoch: 0, iter: 16100, loss: 31.888938903808594\n",
      "epoch: 0, iter: 16200, loss: 35.162681579589844\n",
      "epoch: 0, iter: 16300, loss: 33.00099182128906\n",
      "epoch: 0, iter: 16400, loss: 33.269195556640625\n",
      "epoch: 0, iter: 16500, loss: 32.79420471191406\n",
      "epoch: 0, iter: 16600, loss: 32.72423553466797\n",
      "epoch: 0, iter: 16700, loss: 32.478336334228516\n",
      "epoch: 0, iter: 16800, loss: 32.541629791259766\n",
      "epoch: 0, iter: 16900, loss: 32.788787841796875\n",
      "epoch: 0, iter: 17000, loss: 32.80325698852539\n",
      "epoch: 0, iter: 17100, loss: 32.41188049316406\n",
      "epoch: 0, iter: 17200, loss: 32.277931213378906\n",
      "epoch: 0, iter: 17300, loss: 31.96575927734375\n",
      "epoch: 0, iter: 17400, loss: 33.00987243652344\n",
      "epoch: 0, iter: 17500, loss: 32.88154220581055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 17600, loss: 33.021976470947266\n",
      "epoch: 0, iter: 17700, loss: 32.39189147949219\n",
      "epoch: 0, iter: 17800, loss: 32.150604248046875\n",
      "epoch: 0, iter: 17900, loss: 32.82508087158203\n",
      "epoch: 0, iter: 18000, loss: 32.668113708496094\n",
      "epoch: 0, iter: 18100, loss: 32.69425582885742\n",
      "epoch: 0, iter: 18200, loss: 32.16299057006836\n",
      "epoch: 0, iter: 18300, loss: 32.27485656738281\n",
      "epoch: 0, iter: 18400, loss: 32.31639099121094\n",
      "epoch: 0, iter: 18500, loss: 31.150318145751953\n",
      "epoch: 0, iter: 18600, loss: 31.87506103515625\n",
      "epoch: 0, iter: 18700, loss: 32.12548065185547\n",
      "epoch: 0, iter: 18800, loss: 32.14763259887695\n",
      "epoch: 0, iter: 18900, loss: 32.636192321777344\n",
      "epoch: 0, iter: 19000, loss: 31.977798461914062\n",
      "epoch: 0, iter: 19100, loss: 32.861995697021484\n",
      "epoch: 0, iter: 19200, loss: 32.619117736816406\n",
      "epoch: 0, iter: 19300, loss: 32.857994079589844\n",
      "epoch: 0, iter: 19400, loss: 32.28169250488281\n",
      "epoch: 0, iter: 19500, loss: 32.14692306518555\n",
      "epoch: 0, iter: 19600, loss: 32.80815124511719\n",
      "epoch: 0, iter: 19700, loss: 31.39244842529297\n",
      "epoch: 0, iter: 19800, loss: 32.592079162597656\n",
      "epoch: 0, iter: 19900, loss: 32.30469512939453\n",
      "epoch: 0, iter: 20000, loss: 32.43484115600586\n",
      "epoch: 0, iter: 20100, loss: 32.23839569091797\n",
      "epoch: 0, iter: 20200, loss: 32.257415771484375\n",
      "epoch: 0, iter: 20300, loss: 35.159400939941406\n",
      "epoch: 0, iter: 20400, loss: 31.349346160888672\n",
      "epoch: 0, iter: 20500, loss: 32.97301483154297\n",
      "epoch: 0, iter: 20600, loss: 32.16208267211914\n",
      "epoch: 0, iter: 20700, loss: 32.605751037597656\n",
      "epoch: 0, iter: 20800, loss: 31.8197021484375\n",
      "epoch: 0, iter: 20900, loss: 31.748868942260742\n",
      "epoch: 0, iter: 21000, loss: 32.663230895996094\n",
      "epoch: 0, iter: 21100, loss: 32.405155181884766\n",
      "epoch: 0, iter: 21200, loss: 31.780105590820312\n",
      "epoch: 0, iter: 21300, loss: 32.45668411254883\n",
      "epoch: 0, iter: 21400, loss: 32.22198486328125\n",
      "epoch: 0, iter: 21500, loss: 35.678768157958984\n",
      "epoch: 0, iter: 21600, loss: 32.127159118652344\n",
      "epoch: 0, iter: 21700, loss: 32.136348724365234\n",
      "epoch: 0, iter: 21800, loss: 31.593048095703125\n",
      "epoch: 0, iter: 21900, loss: 32.87860107421875\n",
      "epoch: 0, iter: 22000, loss: 31.570514678955078\n",
      "epoch: 0, iter: 22100, loss: 31.91866683959961\n",
      "epoch: 0, iter: 22200, loss: 31.754594802856445\n",
      "epoch: 0, iter: 22300, loss: 32.14118957519531\n",
      "epoch: 0, iter: 22400, loss: 32.009273529052734\n",
      "epoch: 0, iter: 22500, loss: 31.483463287353516\n",
      "epoch: 0, iter: 22600, loss: 31.676591873168945\n",
      "epoch: 0, iter: 22700, loss: 32.59330368041992\n",
      "epoch: 0, iter: 22800, loss: 31.894651412963867\n",
      "epoch: 0, iter: 22900, loss: 32.38306427001953\n",
      "epoch: 0, iter: 23000, loss: 31.72562026977539\n",
      "epoch: 0, iter: 23100, loss: 32.25025177001953\n",
      "epoch: 0, iter: 23200, loss: 31.449386596679688\n",
      "epoch: 0, iter: 23300, loss: 32.11130905151367\n",
      "epoch: 0, iter: 23400, loss: 31.715259552001953\n",
      "epoch: 0, iter: 23500, loss: 31.64318084716797\n",
      "epoch: 0, iter: 23600, loss: 32.382469177246094\n",
      "epoch: 0, iter: 23700, loss: 30.776226043701172\n",
      "epoch: 0, iter: 23800, loss: 32.44413375854492\n",
      "epoch: 0, iter: 23900, loss: 32.01647186279297\n",
      "epoch: 0, iter: 24000, loss: 31.783679962158203\n",
      "epoch: 0, iter: 24100, loss: 31.83126449584961\n",
      "epoch: 0, iter: 24200, loss: 31.42390251159668\n",
      "epoch: 0, iter: 24300, loss: 31.78484344482422\n",
      "epoch: 0, iter: 24400, loss: 32.69927215576172\n",
      "epoch: 0, iter: 24500, loss: 31.526395797729492\n",
      "epoch: 0, iter: 24600, loss: 32.664764404296875\n",
      "epoch: 0, iter: 24700, loss: 31.658103942871094\n",
      "epoch: 0, iter: 24800, loss: 32.072792053222656\n",
      "epoch: 0, iter: 24900, loss: 31.130779266357422\n",
      "epoch: 0, iter: 25000, loss: 30.971038818359375\n",
      "epoch: 0, iter: 25100, loss: 31.714767456054688\n",
      "epoch: 0, iter: 25200, loss: 31.787036895751953\n",
      "epoch: 0, iter: 25300, loss: 32.364501953125\n",
      "epoch: 0, iter: 25400, loss: 31.830812454223633\n",
      "epoch: 0, iter: 25500, loss: 32.75334548950195\n",
      "epoch: 0, iter: 25600, loss: 32.12239456176758\n",
      "epoch: 0, iter: 25700, loss: 31.854713439941406\n",
      "epoch: 0, iter: 25800, loss: 32.634334564208984\n",
      "epoch: 0, iter: 25900, loss: 31.883930206298828\n",
      "epoch: 0, iter: 26000, loss: 32.21415710449219\n",
      "epoch: 0, iter: 26100, loss: 32.20066452026367\n",
      "epoch: 0, iter: 26200, loss: 32.24790954589844\n",
      "epoch: 0, iter: 26300, loss: 32.04399871826172\n",
      "epoch: 0, iter: 26400, loss: 32.26004409790039\n",
      "epoch: 0, iter: 26500, loss: 31.457181930541992\n",
      "epoch: 0, iter: 26600, loss: 31.90682601928711\n",
      "epoch: 0, iter: 26700, loss: 31.73147201538086\n",
      "epoch: 0, iter: 26800, loss: 31.9154052734375\n",
      "epoch: 0, iter: 26900, loss: 31.6570987701416\n",
      "epoch: 0, iter: 27000, loss: 32.323822021484375\n",
      "epoch: 0, iter: 27100, loss: 32.46583557128906\n",
      "epoch: 0, iter: 27200, loss: 32.380889892578125\n",
      "epoch: 0, iter: 27300, loss: 31.486835479736328\n",
      "epoch: 0, iter: 27400, loss: 31.61042022705078\n",
      "epoch: 0, iter: 27500, loss: 31.35476303100586\n",
      "epoch: 0, iter: 27600, loss: 32.038047790527344\n",
      "epoch: 0, iter: 27700, loss: 31.880908966064453\n",
      "epoch: 0, iter: 27800, loss: 31.168127059936523\n",
      "epoch: 0, iter: 27900, loss: 31.692142486572266\n",
      "epoch: 0, iter: 28000, loss: 31.17156219482422\n",
      "epoch: 0, iter: 28100, loss: 31.19502067565918\n",
      "epoch: 0, iter: 28200, loss: 32.372772216796875\n",
      "epoch: 0, iter: 28300, loss: 31.62321662902832\n",
      "epoch: 0, iter: 28400, loss: 31.319658279418945\n",
      "epoch: 0, iter: 28500, loss: 31.328914642333984\n",
      "epoch: 0, iter: 28600, loss: 31.636524200439453\n",
      "epoch: 0, iter: 28700, loss: 32.23899841308594\n",
      "epoch: 0, iter: 28800, loss: 31.617473602294922\n",
      "epoch: 0, iter: 28900, loss: 32.018333435058594\n",
      "epoch: 0, iter: 29000, loss: 32.01300811767578\n",
      "epoch: 0, iter: 29100, loss: 32.40355682373047\n",
      "epoch: 0, iter: 29200, loss: 31.461441040039062\n",
      "epoch: 0, iter: 29300, loss: 31.61422348022461\n",
      "epoch: 0, iter: 29400, loss: 31.422637939453125\n",
      "epoch: 0, iter: 29500, loss: 30.97579574584961\n",
      "epoch: 0, iter: 29600, loss: 31.84183120727539\n",
      "epoch: 0, iter: 29700, loss: 31.430072784423828\n",
      "epoch: 0, iter: 29800, loss: 31.41105079650879\n",
      "epoch: 0, iter: 29900, loss: 31.55961799621582\n",
      "epoch: 0, iter: 30000, loss: 31.889019012451172\n",
      "epoch: 0, iter: 30100, loss: 31.523969650268555\n",
      "epoch: 0, iter: 30200, loss: 31.99229621887207\n",
      "epoch: 0, iter: 30300, loss: 31.07489776611328\n",
      "epoch: 0, iter: 30400, loss: 31.744131088256836\n",
      "epoch: 0, iter: 30500, loss: 31.55629539489746\n",
      "epoch: 0, iter: 30600, loss: 31.631649017333984\n",
      "epoch: 0, iter: 30700, loss: 32.105865478515625\n",
      "epoch: 0, iter: 30800, loss: 31.055042266845703\n",
      "epoch: 0, iter: 30900, loss: 31.505626678466797\n",
      "epoch: 0, iter: 31000, loss: 31.779678344726562\n",
      "epoch: 0, iter: 31100, loss: 31.651430130004883\n",
      "epoch: 0, iter: 31200, loss: 31.602785110473633\n",
      "epoch: 0, iter: 31300, loss: 31.702640533447266\n",
      "epoch: 0, iter: 31400, loss: 31.374088287353516\n",
      "epoch: 0, iter: 31500, loss: 31.091075897216797\n",
      "epoch: 0, iter: 31600, loss: 31.64260482788086\n",
      "epoch: 0, iter: 31700, loss: 31.677955627441406\n",
      "epoch: 0, iter: 31800, loss: 31.371543884277344\n",
      "epoch: 0, iter: 31900, loss: 31.41596794128418\n",
      "epoch: 0, iter: 32000, loss: 31.612335205078125\n",
      "epoch: 0, iter: 32100, loss: 32.13520050048828\n",
      "epoch: 0, iter: 32200, loss: 31.733051300048828\n",
      "epoch: 0, iter: 32300, loss: 31.379650115966797\n",
      "epoch: 0, iter: 32400, loss: 32.07418441772461\n",
      "epoch: 0, iter: 32500, loss: 31.85396385192871\n",
      "epoch: 0, iter: 32600, loss: 32.09042739868164\n",
      "epoch: 0, iter: 32700, loss: 32.1629524230957\n",
      "epoch: 0, iter: 32800, loss: 31.526533126831055\n",
      "epoch: 0, iter: 32900, loss: 31.12891960144043\n",
      "epoch: 0, iter: 33000, loss: 31.169902801513672\n",
      "epoch: 0, iter: 33100, loss: 31.179859161376953\n",
      "epoch: 0, iter: 33200, loss: 31.539459228515625\n",
      "epoch: 0, iter: 33300, loss: 31.086231231689453\n",
      "epoch: 0, iter: 33400, loss: 31.548381805419922\n",
      "epoch: 0, iter: 33500, loss: 32.13470458984375\n",
      "epoch: 0, iter: 33600, loss: 31.057485580444336\n",
      "epoch: 0, iter: 33700, loss: 31.393047332763672\n",
      "epoch: 0, iter: 33800, loss: 31.191181182861328\n",
      "epoch: 0, iter: 33900, loss: 31.581995010375977\n",
      "epoch: 0, iter: 34000, loss: 30.891382217407227\n",
      "epoch: 0, iter: 34100, loss: 31.224136352539062\n",
      "epoch: 0, iter: 34200, loss: 31.104774475097656\n",
      "epoch: 0, iter: 34300, loss: 31.380504608154297\n",
      "epoch: 0, iter: 34400, loss: 31.74951171875\n",
      "epoch: 0, iter: 34500, loss: 31.861522674560547\n",
      "epoch: 0, iter: 34600, loss: 30.868404388427734\n",
      "epoch: 0, iter: 34700, loss: 31.533527374267578\n",
      "epoch: 0, iter: 34800, loss: 30.677236557006836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 34900, loss: 30.85108184814453\n",
      "epoch: 0, iter: 35000, loss: 31.109275817871094\n",
      "epoch: 0, iter: 35100, loss: 31.504987716674805\n",
      "epoch: 0, iter: 35200, loss: 31.164974212646484\n",
      "epoch: 0, iter: 35300, loss: 31.425212860107422\n",
      "epoch: 0, iter: 35400, loss: 31.558650970458984\n",
      "epoch: 0, iter: 35500, loss: 31.296070098876953\n",
      "epoch: 0, iter: 35600, loss: 31.726829528808594\n",
      "epoch: 0, iter: 35700, loss: 31.459388732910156\n",
      "epoch: 0, iter: 35800, loss: 31.363842010498047\n",
      "epoch: 0, iter: 35900, loss: 31.478790283203125\n",
      "epoch: 0, iter: 36000, loss: 31.512521743774414\n",
      "epoch: 0, iter: 36100, loss: 31.50742530822754\n",
      "epoch: 0, iter: 36200, loss: 31.437950134277344\n",
      "epoch: 0, iter: 36300, loss: 32.16291046142578\n",
      "epoch: 0, iter: 36400, loss: 31.010114669799805\n",
      "epoch: 0, iter: 36500, loss: 31.171680450439453\n",
      "epoch: 0, iter: 36600, loss: 31.108970642089844\n",
      "epoch: 0, iter: 36700, loss: 31.33449935913086\n",
      "epoch: 0, iter: 36800, loss: 31.325313568115234\n",
      "epoch: 0, iter: 36900, loss: 30.625179290771484\n",
      "epoch: 0, iter: 37000, loss: 31.369089126586914\n",
      "epoch: 0, iter: 37100, loss: 30.96773910522461\n",
      "epoch: 0, iter: 37200, loss: 31.788604736328125\n",
      "epoch: 0, iter: 37300, loss: 30.75663948059082\n",
      "epoch: 0, iter: 37400, loss: 31.398881912231445\n",
      "epoch: 0, iter: 37500, loss: 31.698843002319336\n",
      "epoch: 0, iter: 37600, loss: 31.749855041503906\n",
      "epoch: 0, iter: 37700, loss: 31.85443878173828\n",
      "epoch: 0, iter: 37800, loss: 31.332157135009766\n",
      "epoch: 0, iter: 37900, loss: 31.43273162841797\n",
      "epoch: 0, iter: 38000, loss: 31.361421585083008\n",
      "epoch: 0, iter: 38100, loss: 31.388004302978516\n",
      "epoch: 0, iter: 38200, loss: 31.497467041015625\n",
      "epoch: 0, iter: 38300, loss: 31.458118438720703\n",
      "epoch: 0, iter: 38400, loss: 31.50914764404297\n",
      "epoch: 0, iter: 38500, loss: 30.92000961303711\n",
      "epoch: 0, iter: 38600, loss: 31.509443283081055\n",
      "epoch: 0, iter: 38700, loss: 32.00509262084961\n",
      "epoch: 0, iter: 38800, loss: 31.41250228881836\n",
      "epoch: 0, iter: 38900, loss: 30.917842864990234\n",
      "epoch: 0, iter: 39000, loss: 31.670372009277344\n",
      "epoch: 0, iter: 39100, loss: 31.436140060424805\n",
      "epoch: 0, iter: 39200, loss: 31.172178268432617\n",
      "epoch: 0, iter: 39300, loss: 31.227745056152344\n",
      "epoch: 0, iter: 39400, loss: 31.44658660888672\n",
      "epoch: 0, iter: 39500, loss: 31.554386138916016\n",
      "epoch: 0, iter: 39600, loss: 31.11811065673828\n",
      "epoch: 0, iter: 39700, loss: 31.36079978942871\n",
      "epoch: 0, iter: 39800, loss: 31.175209045410156\n",
      "epoch: 0, iter: 39900, loss: 31.26673126220703\n",
      "epoch: 0, iter: 40000, loss: 31.215478897094727\n",
      "epoch: 0, iter: 40100, loss: 30.817962646484375\n",
      "epoch: 0, iter: 40200, loss: 30.939861297607422\n",
      "epoch: 0, iter: 40300, loss: 31.619169235229492\n",
      "epoch: 0, iter: 40400, loss: 31.648056030273438\n",
      "epoch: 0, iter: 40500, loss: 31.093053817749023\n",
      "epoch: 0, iter: 40600, loss: 31.061338424682617\n",
      "epoch: 0, iter: 40700, loss: 31.324695587158203\n",
      "epoch: 0, iter: 40800, loss: 31.382579803466797\n",
      "epoch: 0, iter: 40900, loss: 31.43083381652832\n",
      "epoch: 0, iter: 41000, loss: 31.283897399902344\n",
      "epoch: 0, iter: 41100, loss: 30.575298309326172\n",
      "epoch: 0, iter: 41200, loss: 31.435115814208984\n",
      "epoch: 0, iter: 41300, loss: 30.953184127807617\n",
      "epoch: 0, iter: 41400, loss: 31.151187896728516\n",
      "epoch: 0, iter: 41500, loss: 31.413209915161133\n",
      "epoch: 0, iter: 41600, loss: 30.98404312133789\n",
      "epoch: 0, iter: 41700, loss: 31.674259185791016\n",
      "epoch: 0, iter: 41800, loss: 31.379352569580078\n",
      "epoch: 0, iter: 41900, loss: 31.656352996826172\n",
      "epoch: 0, iter: 42000, loss: 31.38640594482422\n",
      "epoch: 0, iter: 42100, loss: 31.564537048339844\n",
      "epoch: 0, iter: 42200, loss: 30.698810577392578\n",
      "epoch: 0, iter: 42300, loss: 30.512741088867188\n",
      "epoch: 0, iter: 42400, loss: 31.834272384643555\n",
      "epoch: 0, iter: 42500, loss: 31.547222137451172\n",
      "epoch: 0, iter: 42600, loss: 31.272777557373047\n",
      "epoch: 0, iter: 42700, loss: 30.816436767578125\n",
      "epoch: 0, iter: 42800, loss: 31.22564697265625\n",
      "epoch: 0, iter: 42900, loss: 31.611284255981445\n",
      "epoch: 0, iter: 43000, loss: 30.84935188293457\n",
      "epoch: 0, iter: 43100, loss: 31.218761444091797\n",
      "epoch: 0, iter: 43200, loss: 30.90999984741211\n",
      "epoch: 0, iter: 43300, loss: 30.99444580078125\n",
      "epoch: 0, iter: 43400, loss: 31.954936981201172\n",
      "epoch: 0, iter: 43500, loss: 31.507293701171875\n",
      "epoch: 0, iter: 43600, loss: 31.271663665771484\n",
      "epoch: 0, iter: 43700, loss: 31.60310935974121\n",
      "epoch: 0, iter: 43800, loss: 31.207149505615234\n",
      "epoch: 0, iter: 43900, loss: 31.26061248779297\n",
      "epoch: 0, iter: 44000, loss: 31.54401969909668\n",
      "epoch: 0, iter: 44100, loss: 31.064640045166016\n",
      "epoch: 0, iter: 44200, loss: 31.254337310791016\n",
      "epoch: 0, iter: 44300, loss: 31.456157684326172\n",
      "epoch: 0, iter: 44400, loss: 31.354372024536133\n",
      "epoch: 0, iter: 44500, loss: 31.179513931274414\n",
      "epoch: 0, iter: 44600, loss: 31.320068359375\n",
      "epoch: 0, iter: 44700, loss: 31.00312042236328\n",
      "epoch: 0, iter: 44800, loss: 31.077112197875977\n",
      "epoch: 0, iter: 44900, loss: 30.956066131591797\n",
      "epoch: 0, iter: 45000, loss: 31.298351287841797\n",
      "epoch: 0, iter: 45100, loss: 30.96402931213379\n",
      "epoch: 0, iter: 45200, loss: 31.158403396606445\n",
      "epoch: 0, iter: 45300, loss: 30.971172332763672\n",
      "epoch: 0, iter: 45400, loss: 31.50478172302246\n",
      "epoch: 0, iter: 45500, loss: 31.492687225341797\n",
      "epoch: 0, iter: 45600, loss: 31.18555450439453\n",
      "epoch: 0, iter: 45700, loss: 30.931865692138672\n",
      "epoch: 0, iter: 45800, loss: 32.09613800048828\n",
      "epoch: 0, iter: 45900, loss: 31.31871795654297\n",
      "epoch: 0, iter: 46000, loss: 31.148996353149414\n",
      "epoch: 0, iter: 46100, loss: 30.82643699645996\n",
      "epoch: 0, iter: 46200, loss: 30.676185607910156\n",
      "epoch: 0, iter: 46300, loss: 30.93189239501953\n",
      "epoch: 0, iter: 46400, loss: 31.394023895263672\n",
      "epoch: 0, iter: 46500, loss: 31.14517593383789\n",
      "epoch: 0, iter: 46600, loss: 30.991371154785156\n",
      "epoch: 0, iter: 46700, loss: 31.06136703491211\n",
      "epoch: 0, iter: 46800, loss: 31.141521453857422\n",
      "epoch: 0, iter: 46900, loss: 31.318382263183594\n",
      "epoch: 0, iter: 47000, loss: 30.877700805664062\n",
      "epoch: 0, iter: 47100, loss: 31.205799102783203\n",
      "epoch: 0, iter: 47200, loss: 31.14288330078125\n",
      "epoch: 0, iter: 47300, loss: 31.546463012695312\n",
      "epoch: 0, iter: 47400, loss: 30.99927520751953\n",
      "epoch: 0, iter: 47500, loss: 30.961528778076172\n",
      "epoch: 0, iter: 47600, loss: 31.244632720947266\n",
      "epoch: 0, iter: 47700, loss: 31.11411476135254\n",
      "epoch: 0, iter: 47800, loss: 30.90994644165039\n",
      "epoch: 0, iter: 47900, loss: 31.151588439941406\n",
      "epoch: 0, iter: 48000, loss: 31.097763061523438\n",
      "epoch: 0, iter: 48100, loss: 31.432632446289062\n",
      "epoch: 0, iter: 48200, loss: 31.32574462890625\n",
      "epoch: 0, iter: 48300, loss: 31.46638298034668\n",
      "epoch: 0, iter: 48400, loss: 30.719860076904297\n",
      "epoch: 0, iter: 48500, loss: 31.54958724975586\n",
      "epoch: 0, iter: 48600, loss: 31.485898971557617\n",
      "epoch: 0, iter: 48700, loss: 30.650495529174805\n",
      "epoch: 0, iter: 48800, loss: 31.371259689331055\n",
      "epoch: 0, iter: 48900, loss: 31.015750885009766\n",
      "epoch: 0, iter: 49000, loss: 31.562847137451172\n",
      "epoch: 0, iter: 49100, loss: 31.167272567749023\n",
      "epoch: 0, iter: 49200, loss: 30.787384033203125\n",
      "epoch: 0, iter: 49300, loss: 31.112030029296875\n",
      "epoch: 0, iter: 49400, loss: 30.593448638916016\n",
      "epoch: 0, iter: 49500, loss: 31.521697998046875\n",
      "epoch: 0, iter: 49600, loss: 31.047107696533203\n",
      "epoch: 0, iter: 49700, loss: 31.302776336669922\n",
      "epoch: 0, iter: 49800, loss: 30.956268310546875\n",
      "epoch: 0, iter: 49900, loss: 31.06875228881836\n",
      "epoch: 0, iter: 50000, loss: 31.210609436035156\n",
      "epoch: 0, iter: 50100, loss: 30.894155502319336\n",
      "epoch: 0, iter: 50200, loss: 31.302818298339844\n",
      "epoch: 0, iter: 50300, loss: 31.0950870513916\n",
      "epoch: 0, iter: 50400, loss: 31.232391357421875\n",
      "epoch: 0, iter: 50500, loss: 31.09789276123047\n",
      "epoch: 0, iter: 50600, loss: 30.778106689453125\n",
      "epoch: 0, iter: 50700, loss: 31.466218948364258\n",
      "epoch: 0, iter: 50800, loss: 31.121654510498047\n",
      "epoch: 0, iter: 50900, loss: 31.22547721862793\n",
      "epoch: 0, iter: 51000, loss: 31.16694450378418\n",
      "epoch: 0, iter: 51100, loss: 31.62116050720215\n",
      "epoch: 0, iter: 51200, loss: 31.220848083496094\n",
      "epoch: 0, iter: 51300, loss: 31.848587036132812\n",
      "epoch: 0, iter: 51400, loss: 31.313138961791992\n",
      "epoch: 0, iter: 51500, loss: 31.296916961669922\n",
      "epoch: 0, iter: 51600, loss: 31.118091583251953\n",
      "epoch: 0, iter: 51700, loss: 31.521448135375977\n",
      "epoch: 0, iter: 51800, loss: 31.3619384765625\n",
      "epoch: 0, iter: 51900, loss: 30.852176666259766\n",
      "epoch: 0, iter: 52000, loss: 30.821500778198242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 52100, loss: 31.361873626708984\n",
      "epoch: 0, iter: 52200, loss: 30.893741607666016\n",
      "epoch: 0, iter: 52300, loss: 30.718006134033203\n",
      "epoch: 0, iter: 52400, loss: 31.015762329101562\n",
      "epoch: 0, iter: 52500, loss: 31.00485610961914\n",
      "epoch: 0, iter: 52600, loss: 31.05432891845703\n",
      "epoch: 0, iter: 52700, loss: 30.820741653442383\n",
      "epoch: 0, iter: 52800, loss: 30.87388801574707\n",
      "epoch: 0, iter: 52900, loss: 31.245819091796875\n",
      "epoch: 0, iter: 53000, loss: 31.113101959228516\n",
      "epoch: 0, iter: 53100, loss: 31.04051971435547\n",
      "epoch: 0, iter: 53200, loss: 30.783733367919922\n",
      "epoch: 0, iter: 53300, loss: 30.71259307861328\n",
      "epoch: 0, iter: 53400, loss: 31.52549934387207\n",
      "epoch: 0, iter: 53500, loss: 31.074138641357422\n",
      "epoch: 0, iter: 53600, loss: 30.682376861572266\n",
      "epoch: 0, iter: 53700, loss: 31.03972625732422\n",
      "epoch: 0, iter: 53800, loss: 30.844356536865234\n",
      "epoch: 0, iter: 53900, loss: 31.168516159057617\n",
      "epoch: 0, iter: 54000, loss: 30.87356948852539\n",
      "epoch: 0, iter: 54100, loss: 31.002277374267578\n",
      "epoch: 0, iter: 54200, loss: 31.147415161132812\n",
      "epoch: 0, iter: 54300, loss: 30.93040657043457\n",
      "epoch: 0, iter: 54400, loss: 31.39674949645996\n",
      "epoch: 0, iter: 54500, loss: 30.997756958007812\n",
      "epoch: 0, iter: 54600, loss: 30.9820556640625\n",
      "epoch: 0, iter: 54700, loss: 30.985462188720703\n",
      "epoch: 0, iter: 54800, loss: 30.72603988647461\n",
      "epoch: 0, iter: 54900, loss: 31.20616340637207\n",
      "epoch: 0, iter: 55000, loss: 31.378429412841797\n",
      "epoch: 0, iter: 55100, loss: 30.821063995361328\n",
      "epoch: 0, iter: 55200, loss: 30.86159896850586\n",
      "epoch: 0, iter: 55300, loss: 30.995410919189453\n",
      "epoch: 0, iter: 55400, loss: 30.89150047302246\n",
      "epoch: 0, iter: 55500, loss: 30.97189712524414\n",
      "epoch: 0, iter: 55600, loss: 31.15375328063965\n",
      "epoch: 0, iter: 55700, loss: 30.908920288085938\n",
      "epoch: 0, iter: 55800, loss: 31.49115753173828\n",
      "epoch: 0, iter: 55900, loss: 30.726625442504883\n",
      "epoch: 0, iter: 56000, loss: 31.300159454345703\n",
      "epoch: 0, iter: 56100, loss: 31.19672966003418\n",
      "epoch: 0, iter: 56200, loss: 30.734006881713867\n",
      "epoch: 0, iter: 56300, loss: 31.133312225341797\n",
      "epoch: 0, iter: 56400, loss: 31.236764907836914\n",
      "epoch: 0, iter: 56500, loss: 31.294586181640625\n",
      "epoch: 0, iter: 56600, loss: 30.767263412475586\n",
      "epoch: 0, iter: 56700, loss: 30.94205093383789\n",
      "epoch: 0, iter: 56800, loss: 31.734630584716797\n",
      "epoch: 0, iter: 56900, loss: 31.002988815307617\n",
      "epoch: 0, iter: 57000, loss: 30.991113662719727\n",
      "epoch: 0, iter: 57100, loss: 30.419078826904297\n",
      "epoch: 0, iter: 57200, loss: 31.085824966430664\n",
      "epoch: 0, iter: 57300, loss: 31.232624053955078\n",
      "epoch: 0, iter: 57400, loss: 30.987998962402344\n",
      "epoch: 0, iter: 57500, loss: 31.22313690185547\n",
      "epoch: 0, iter: 57600, loss: 30.843856811523438\n",
      "epoch: 0, iter: 57700, loss: 31.008670806884766\n",
      "epoch: 0, iter: 57800, loss: 31.801488876342773\n",
      "epoch: 0, iter: 57900, loss: 30.928499221801758\n",
      "epoch: 0, iter: 58000, loss: 30.728900909423828\n",
      "epoch: 0, iter: 58100, loss: 31.422687530517578\n",
      "epoch: 0, iter: 58200, loss: 30.793533325195312\n",
      "epoch: 0, iter: 58300, loss: 30.954517364501953\n",
      "epoch: 0, iter: 58400, loss: 31.496538162231445\n",
      "epoch: 0, iter: 58500, loss: 30.828275680541992\n",
      "epoch: 0, iter: 58600, loss: 31.042236328125\n",
      "epoch: 0, iter: 58700, loss: 30.78326416015625\n",
      "epoch: 0, iter: 58800, loss: 31.40312385559082\n",
      "epoch: 0, iter: 58900, loss: 30.9731502532959\n",
      "epoch: 0, iter: 59000, loss: 31.053268432617188\n",
      "epoch: 0, iter: 59100, loss: 31.30685043334961\n",
      "epoch: 0, iter: 59200, loss: 31.121906280517578\n",
      "epoch: 0, iter: 59300, loss: 30.64270782470703\n",
      "epoch: 0, iter: 59400, loss: 30.810043334960938\n",
      "epoch: 0, iter: 59500, loss: 31.057052612304688\n",
      "epoch: 0, iter: 59600, loss: 31.277307510375977\n",
      "epoch: 0, iter: 59700, loss: 30.876577377319336\n",
      "epoch: 0, iter: 59800, loss: 31.234268188476562\n",
      "epoch: 0, iter: 59900, loss: 31.161775588989258\n",
      "epoch: 0, iter: 60000, loss: 30.5039005279541\n",
      "epoch: 0, iter: 60100, loss: 31.5089168548584\n",
      "epoch: 0, iter: 60200, loss: 31.07863998413086\n",
      "epoch: 0, iter: 60300, loss: 31.599945068359375\n",
      "epoch: 0, iter: 60400, loss: 31.08795928955078\n",
      "epoch: 0, iter: 60500, loss: 31.050140380859375\n",
      "epoch: 0, iter: 60600, loss: 31.022817611694336\n",
      "epoch: 0, iter: 60700, loss: 31.137798309326172\n",
      "epoch: 0, iter: 60800, loss: 30.948143005371094\n",
      "epoch: 0, iter: 60900, loss: 31.010616302490234\n",
      "epoch: 0, iter: 61000, loss: 31.3067569732666\n",
      "epoch: 0, iter: 61100, loss: 31.03820037841797\n",
      "epoch: 0, iter: 61200, loss: 31.200389862060547\n",
      "epoch: 0, iter: 61300, loss: 31.348535537719727\n",
      "epoch: 0, iter: 61400, loss: 30.77002716064453\n",
      "epoch: 0, iter: 61500, loss: 31.357349395751953\n",
      "epoch: 0, iter: 61600, loss: 31.379135131835938\n",
      "epoch: 0, iter: 61700, loss: 31.507503509521484\n",
      "epoch: 0, iter: 61800, loss: 30.75447654724121\n",
      "epoch: 0, iter: 61900, loss: 30.7366943359375\n",
      "epoch: 0, iter: 62000, loss: 30.543977737426758\n",
      "epoch: 0, iter: 62100, loss: 30.986164093017578\n",
      "epoch: 0, iter: 62200, loss: 30.71504020690918\n",
      "epoch: 0, iter: 62300, loss: 30.874168395996094\n",
      "epoch: 0, iter: 62400, loss: 31.171356201171875\n",
      "epoch: 0, iter: 62500, loss: 30.857860565185547\n",
      "epoch: 0, iter: 62600, loss: 31.321640014648438\n",
      "epoch: 0, iter: 62700, loss: 31.09368896484375\n",
      "epoch: 0, iter: 62800, loss: 31.233774185180664\n",
      "epoch: 0, iter: 62900, loss: 31.444623947143555\n",
      "epoch: 0, iter: 63000, loss: 30.95768928527832\n",
      "epoch: 0, iter: 63100, loss: 30.80200958251953\n",
      "epoch: 0, iter: 63200, loss: 30.808534622192383\n",
      "epoch: 0, iter: 63300, loss: 31.409921646118164\n",
      "epoch: 0, iter: 63400, loss: 31.004011154174805\n",
      "epoch: 0, iter: 63500, loss: 31.15694236755371\n",
      "epoch: 0, iter: 63600, loss: 30.964189529418945\n",
      "epoch: 0, iter: 63700, loss: 30.86632537841797\n",
      "epoch: 0, iter: 63800, loss: 30.68033218383789\n",
      "epoch: 0, iter: 63900, loss: 31.00926971435547\n",
      "epoch: 0, iter: 64000, loss: 30.86907386779785\n",
      "epoch: 0, iter: 64100, loss: 31.215900421142578\n",
      "epoch: 0, iter: 64200, loss: 30.634145736694336\n",
      "epoch: 0, iter: 64300, loss: 30.67613983154297\n",
      "epoch: 0, iter: 64400, loss: 31.064476013183594\n",
      "epoch: 0, iter: 64500, loss: 30.24282455444336\n",
      "epoch: 0, iter: 64600, loss: 31.0748291015625\n",
      "epoch: 0, iter: 64700, loss: 30.745285034179688\n",
      "epoch: 0, iter: 64800, loss: 31.13530731201172\n",
      "epoch: 0, iter: 64900, loss: 30.87594223022461\n",
      "epoch: 0, iter: 65000, loss: 30.67505645751953\n",
      "epoch: 0, iter: 65100, loss: 31.31609344482422\n",
      "epoch: 0, iter: 65200, loss: 30.626483917236328\n",
      "epoch: 0, iter: 65300, loss: 31.286836624145508\n",
      "epoch: 0, iter: 65400, loss: 30.73581314086914\n",
      "epoch: 0, iter: 65500, loss: 30.82906723022461\n",
      "epoch: 0, iter: 65600, loss: 30.992712020874023\n",
      "epoch: 0, iter: 65700, loss: 30.566394805908203\n",
      "epoch: 0, iter: 65800, loss: 30.99093246459961\n",
      "epoch: 0, iter: 65900, loss: 30.6799373626709\n",
      "epoch: 0, iter: 66000, loss: 30.729446411132812\n",
      "epoch: 0, iter: 66100, loss: 31.00832748413086\n",
      "epoch: 0, iter: 66200, loss: 31.38101577758789\n",
      "epoch: 0, iter: 66300, loss: 31.055740356445312\n",
      "epoch: 0, iter: 66400, loss: 31.26336669921875\n",
      "epoch: 0, iter: 66500, loss: 31.47425651550293\n",
      "epoch: 0, iter: 66600, loss: 30.855850219726562\n",
      "epoch: 0, iter: 66700, loss: 30.994140625\n",
      "epoch: 0, iter: 66800, loss: 31.158376693725586\n",
      "epoch: 0, iter: 66900, loss: 30.674720764160156\n",
      "epoch: 0, iter: 67000, loss: 30.442882537841797\n",
      "epoch: 0, iter: 67100, loss: 31.06387710571289\n",
      "epoch: 0, iter: 67200, loss: 30.45368194580078\n",
      "epoch: 0, iter: 67300, loss: 30.75461196899414\n",
      "epoch: 0, iter: 67400, loss: 30.79436492919922\n",
      "epoch: 0, iter: 67500, loss: 31.29925537109375\n",
      "epoch: 0, iter: 67600, loss: 31.080904006958008\n",
      "epoch: 0, iter: 67700, loss: 30.82245445251465\n",
      "epoch: 0, iter: 67800, loss: 31.2943115234375\n",
      "epoch: 0, iter: 67900, loss: 30.431425094604492\n",
      "epoch: 0, iter: 68000, loss: 31.297412872314453\n",
      "epoch: 0, iter: 68100, loss: 31.0037841796875\n",
      "epoch: 0, iter: 68200, loss: 31.116390228271484\n",
      "epoch: 0, iter: 68300, loss: 31.23482894897461\n",
      "epoch: 0, iter: 68400, loss: 31.004608154296875\n",
      "epoch: 0, iter: 68500, loss: 31.441688537597656\n",
      "epoch: 0, iter: 68600, loss: 31.066207885742188\n",
      "epoch: 0, iter: 68700, loss: 30.614906311035156\n",
      "epoch: 0, iter: 68800, loss: 31.376386642456055\n",
      "epoch: 0, iter: 68900, loss: 30.658260345458984\n",
      "epoch: 0, iter: 69000, loss: 31.0848388671875\n",
      "epoch: 0, iter: 69100, loss: 30.42531967163086\n",
      "epoch: 0, iter: 69200, loss: 30.667695999145508\n",
      "epoch: 0, iter: 69300, loss: 30.317691802978516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 69400, loss: 30.816993713378906\n",
      "epoch: 0, iter: 69500, loss: 30.307523727416992\n",
      "epoch: 0, iter: 69600, loss: 30.94533920288086\n",
      "epoch: 0, iter: 69700, loss: 30.840808868408203\n",
      "epoch: 0, iter: 69800, loss: 30.76001739501953\n",
      "epoch: 0, iter: 69900, loss: 30.81319808959961\n",
      "epoch: 0, iter: 70000, loss: 30.45636749267578\n",
      "epoch: 0, iter: 70100, loss: 30.786243438720703\n",
      "epoch: 0, iter: 70200, loss: 30.836938858032227\n",
      "epoch: 0, iter: 70300, loss: 30.81452178955078\n",
      "epoch: 0, iter: 70400, loss: 30.829416275024414\n",
      "epoch: 0, iter: 70500, loss: 30.64291763305664\n",
      "epoch: 0, iter: 70600, loss: 31.78078269958496\n",
      "epoch: 0, iter: 70700, loss: 30.614402770996094\n",
      "epoch: 0, iter: 70800, loss: 31.274394989013672\n",
      "epoch: 0, iter: 70900, loss: 30.765005111694336\n",
      "epoch: 0, iter: 71000, loss: 30.989028930664062\n",
      "epoch: 0, iter: 71100, loss: 31.00112533569336\n",
      "epoch: 0, iter: 71200, loss: 30.464740753173828\n",
      "epoch: 0, iter: 71300, loss: 30.848350524902344\n",
      "epoch: 0, iter: 71400, loss: 31.216331481933594\n",
      "epoch: 0, iter: 71500, loss: 30.824384689331055\n",
      "epoch: 0, iter: 71600, loss: 30.926025390625\n",
      "epoch: 0, iter: 71700, loss: 30.743213653564453\n",
      "epoch: 0, iter: 71800, loss: 30.8267765045166\n",
      "epoch: 0, iter: 71900, loss: 30.94784164428711\n",
      "epoch: 0, iter: 72000, loss: 31.128280639648438\n",
      "epoch: 0, iter: 72100, loss: 30.91042709350586\n",
      "epoch: 0, iter: 72200, loss: 31.019046783447266\n",
      "epoch: 0, iter: 72300, loss: 30.984928131103516\n",
      "epoch: 0, iter: 72400, loss: 31.180505752563477\n",
      "epoch: 0, iter: 72500, loss: 30.573802947998047\n",
      "epoch: 0, iter: 72600, loss: 31.01894760131836\n",
      "epoch: 0, iter: 72700, loss: 30.46668243408203\n",
      "epoch: 0, iter: 72800, loss: 30.741687774658203\n",
      "epoch: 0, iter: 72900, loss: 31.318370819091797\n",
      "epoch: 0, iter: 73000, loss: 31.04427719116211\n",
      "epoch: 0, iter: 73100, loss: 31.246623992919922\n",
      "epoch: 0, iter: 73200, loss: 30.76646614074707\n",
      "epoch: 0, iter: 73300, loss: 31.257722854614258\n",
      "epoch: 0, iter: 73400, loss: 31.26410484313965\n",
      "epoch: 0, iter: 73500, loss: 31.332019805908203\n",
      "epoch: 0, iter: 73600, loss: 30.61560821533203\n",
      "epoch: 0, iter: 73700, loss: 31.18964195251465\n",
      "epoch: 0, iter: 73800, loss: 31.707021713256836\n",
      "epoch: 0, iter: 73900, loss: 31.49124526977539\n",
      "epoch: 0, iter: 74000, loss: 30.72918128967285\n",
      "epoch: 0, iter: 74100, loss: 30.976696014404297\n",
      "epoch: 0, iter: 74200, loss: 30.834129333496094\n",
      "epoch: 0, iter: 74300, loss: 30.560712814331055\n",
      "epoch: 0, iter: 74400, loss: 31.111557006835938\n",
      "epoch: 0, iter: 74500, loss: 31.04186248779297\n",
      "epoch: 0, iter: 74600, loss: 31.272661209106445\n",
      "epoch: 0, iter: 74700, loss: 31.06555938720703\n",
      "epoch: 0, iter: 74800, loss: 31.021663665771484\n",
      "epoch: 0, iter: 74900, loss: 30.705562591552734\n",
      "epoch: 0, iter: 75000, loss: 31.081554412841797\n",
      "epoch: 0, iter: 75100, loss: 30.25119400024414\n",
      "epoch: 0, iter: 75200, loss: 31.131847381591797\n",
      "epoch: 0, iter: 75300, loss: 31.28846549987793\n",
      "epoch: 0, iter: 75400, loss: 30.345232009887695\n",
      "epoch: 0, iter: 75500, loss: 30.934406280517578\n",
      "epoch: 0, iter: 75600, loss: 30.777252197265625\n",
      "epoch: 0, iter: 75700, loss: 31.290422439575195\n",
      "epoch: 0, iter: 75800, loss: 30.77525520324707\n",
      "epoch: 0, iter: 75900, loss: 30.82712173461914\n",
      "epoch: 0, iter: 76000, loss: 30.15979766845703\n",
      "epoch: 0, iter: 76100, loss: 31.10176658630371\n",
      "epoch: 0, iter: 76200, loss: 30.881591796875\n",
      "epoch: 0, iter: 76300, loss: 30.92761993408203\n",
      "epoch: 0, iter: 76400, loss: 30.35842514038086\n",
      "epoch: 0, iter: 76500, loss: 31.141483306884766\n",
      "epoch: 0, iter: 76600, loss: 30.713130950927734\n",
      "epoch: 0, iter: 76700, loss: 30.73061180114746\n",
      "epoch: 0, iter: 76800, loss: 30.935062408447266\n",
      "epoch: 0, iter: 76900, loss: 30.93401336669922\n",
      "epoch: 0, iter: 77000, loss: 30.355422973632812\n",
      "epoch: 0, iter: 77100, loss: 30.823474884033203\n",
      "epoch: 0, iter: 77200, loss: 30.893571853637695\n",
      "epoch: 0, iter: 77300, loss: 30.908649444580078\n",
      "epoch: 0, iter: 77400, loss: 30.85500717163086\n",
      "epoch: 0, iter: 77500, loss: 31.24725341796875\n",
      "epoch: 0, iter: 77600, loss: 31.117351531982422\n",
      "epoch: 0, iter: 77700, loss: 31.06186294555664\n",
      "epoch: 0, iter: 77800, loss: 30.703962326049805\n",
      "epoch: 0, iter: 77900, loss: 31.223770141601562\n",
      "epoch: 0, iter: 78000, loss: 30.959918975830078\n",
      "epoch: 0, iter: 78100, loss: 30.338716506958008\n",
      "epoch: 0, iter: 78200, loss: 31.086162567138672\n",
      "epoch: 0, iter: 78300, loss: 30.634380340576172\n",
      "epoch: 0, iter: 78400, loss: 30.866703033447266\n",
      "epoch: 0, iter: 78500, loss: 30.27750015258789\n",
      "epoch: 0, iter: 78600, loss: 31.445148468017578\n",
      "epoch: 0, iter: 78700, loss: 30.81397247314453\n",
      "epoch: 0, iter: 78800, loss: 31.162731170654297\n",
      "epoch: 0, iter: 78900, loss: 30.78436279296875\n",
      "epoch: 0, iter: 79000, loss: 31.205917358398438\n",
      "epoch: 0, iter: 79100, loss: 30.747425079345703\n",
      "epoch: 0, iter: 79200, loss: 31.06232452392578\n",
      "epoch: 0, iter: 79300, loss: 31.23681640625\n",
      "epoch: 0, iter: 79400, loss: 30.804203033447266\n",
      "epoch: 0, iter: 79500, loss: 30.782386779785156\n",
      "epoch: 0, iter: 79600, loss: 31.464441299438477\n",
      "epoch: 0, iter: 79700, loss: 31.171653747558594\n",
      "epoch: 0, iter: 79800, loss: 31.141468048095703\n",
      "epoch: 0, iter: 79900, loss: 30.86945152282715\n",
      "epoch: 0, iter: 80000, loss: 30.656444549560547\n",
      "epoch: 0, iter: 80100, loss: 30.944732666015625\n",
      "epoch: 0, iter: 80200, loss: 30.68834686279297\n",
      "epoch: 0, iter: 80300, loss: 30.86358642578125\n",
      "epoch: 0, iter: 80400, loss: 30.74810218811035\n",
      "epoch: 0, iter: 80500, loss: 31.114765167236328\n",
      "epoch: 0, iter: 80600, loss: 30.753498077392578\n",
      "epoch: 0, iter: 80700, loss: 30.372905731201172\n",
      "epoch: 0, iter: 80800, loss: 30.586729049682617\n",
      "epoch: 0, iter: 80900, loss: 31.04208755493164\n",
      "epoch: 0, iter: 81000, loss: 30.828128814697266\n",
      "epoch: 0, iter: 81100, loss: 30.567119598388672\n",
      "epoch: 0, iter: 81200, loss: 30.44019889831543\n",
      "epoch: 0, iter: 81300, loss: 31.058818817138672\n",
      "epoch: 0, iter: 81400, loss: 31.258481979370117\n",
      "epoch: 0, iter: 81500, loss: 31.493385314941406\n",
      "epoch: 0, iter: 81600, loss: 31.339916229248047\n",
      "epoch: 0, iter: 81700, loss: 31.339115142822266\n",
      "epoch: 0, iter: 81800, loss: 31.311054229736328\n",
      "epoch: 0, iter: 81900, loss: 30.201679229736328\n",
      "epoch: 0, iter: 82000, loss: 30.802412033081055\n",
      "epoch: 0, iter: 82100, loss: 30.628320693969727\n",
      "epoch: 0, iter: 82200, loss: 30.483158111572266\n",
      "epoch: 0, iter: 82300, loss: 30.311115264892578\n",
      "epoch: 0, iter: 82400, loss: 30.988723754882812\n",
      "epoch: 0, iter: 82500, loss: 31.037324905395508\n",
      "epoch: 0, iter: 82600, loss: 31.418289184570312\n",
      "epoch: 0, iter: 82700, loss: 30.968481063842773\n",
      "epoch: 0, iter: 82800, loss: 30.56513214111328\n",
      "epoch: 0, iter: 82900, loss: 31.02338981628418\n",
      "epoch: 0, iter: 83000, loss: 31.226287841796875\n",
      "epoch: 0, iter: 83100, loss: 31.061504364013672\n",
      "epoch: 0, iter: 83200, loss: 31.021148681640625\n",
      "epoch: 0, iter: 83300, loss: 30.636011123657227\n",
      "epoch: 0, iter: 83400, loss: 30.79521369934082\n",
      "epoch: 0, iter: 83500, loss: 30.300968170166016\n",
      "epoch: 0, iter: 83600, loss: 30.659122467041016\n",
      "epoch: 0, iter: 83700, loss: 30.547718048095703\n",
      "epoch: 0, iter: 83800, loss: 30.355697631835938\n",
      "epoch: 0, iter: 83900, loss: 31.176389694213867\n",
      "epoch: 0, iter: 84000, loss: 30.667938232421875\n",
      "epoch: 0, iter: 84100, loss: 30.755659103393555\n",
      "epoch: 0, iter: 84200, loss: 30.89419174194336\n",
      "epoch: 0, iter: 84300, loss: 31.221542358398438\n",
      "epoch: 0, iter: 84400, loss: 30.576738357543945\n",
      "epoch: 0, iter: 84500, loss: 30.791484832763672\n",
      "epoch: 0, iter: 84600, loss: 31.042133331298828\n",
      "epoch: 0, iter: 84700, loss: 30.354415893554688\n",
      "epoch: 0, iter: 84800, loss: 30.7398681640625\n",
      "epoch: 0, iter: 84900, loss: 30.397762298583984\n",
      "epoch: 0, iter: 85000, loss: 30.44795036315918\n",
      "epoch: 0, iter: 85100, loss: 30.439237594604492\n",
      "epoch: 0, iter: 85200, loss: 30.64443588256836\n",
      "epoch: 0, iter: 85300, loss: 30.6994686126709\n",
      "epoch: 0, iter: 85400, loss: 30.751689910888672\n",
      "epoch: 0, iter: 85500, loss: 30.75162124633789\n",
      "epoch: 0, iter: 85600, loss: 30.907808303833008\n",
      "epoch: 0, iter: 85700, loss: 30.806232452392578\n",
      "epoch: 0, iter: 85800, loss: 30.58504867553711\n",
      "epoch: 0, iter: 85900, loss: 30.092628479003906\n",
      "epoch: 0, iter: 86000, loss: 31.62148666381836\n",
      "epoch: 0, iter: 86100, loss: 30.891319274902344\n",
      "epoch: 0, iter: 86200, loss: 30.86149024963379\n",
      "epoch: 0, iter: 86300, loss: 30.719192504882812\n",
      "epoch: 0, iter: 86400, loss: 30.89356231689453\n",
      "epoch: 0, iter: 86500, loss: 30.81019401550293\n",
      "epoch: 0, iter: 86600, loss: 31.236053466796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 86700, loss: 30.40748405456543\n",
      "epoch: 0, iter: 86800, loss: 30.44906234741211\n",
      "epoch: 0, iter: 86900, loss: 30.473594665527344\n",
      "epoch: 0, iter: 87000, loss: 30.700502395629883\n",
      "epoch: 0, iter: 87100, loss: 31.29935073852539\n",
      "epoch: 0, iter: 87200, loss: 30.496597290039062\n",
      "epoch: 0, iter: 87300, loss: 30.804603576660156\n",
      "epoch: 0, iter: 87400, loss: 30.715038299560547\n",
      "epoch: 0, iter: 87500, loss: 30.697669982910156\n",
      "epoch: 0, iter: 87600, loss: 31.246540069580078\n",
      "epoch: 0, iter: 87700, loss: 30.420351028442383\n",
      "epoch: 0, iter: 87800, loss: 30.751745223999023\n",
      "epoch: 0, iter: 87900, loss: 31.291839599609375\n",
      "epoch: 0, iter: 88000, loss: 30.60263442993164\n",
      "epoch: 0, iter: 88100, loss: 30.47844123840332\n",
      "epoch: 0, iter: 88200, loss: 30.767213821411133\n",
      "epoch: 0, iter: 88300, loss: 30.82451629638672\n",
      "epoch: 0, iter: 88400, loss: 31.189123153686523\n",
      "epoch: 0, iter: 88500, loss: 30.532522201538086\n",
      "epoch: 0, iter: 88600, loss: 30.30803871154785\n",
      "epoch: 0, iter: 88700, loss: 31.124361038208008\n",
      "epoch: 0, iter: 88800, loss: 30.52616310119629\n",
      "epoch: 0, iter: 88900, loss: 31.042076110839844\n",
      "epoch: 0, iter: 89000, loss: 30.20344352722168\n",
      "epoch: 0, iter: 89100, loss: 31.02791404724121\n",
      "epoch: 0, iter: 89200, loss: 30.58099365234375\n",
      "epoch: 0, iter: 89300, loss: 31.173372268676758\n",
      "epoch: 0, iter: 89400, loss: 30.765153884887695\n",
      "epoch: 0, iter: 89500, loss: 30.918743133544922\n",
      "epoch: 0, iter: 89600, loss: 31.259233474731445\n",
      "epoch: 0, iter: 89700, loss: 30.4522647857666\n",
      "epoch: 0, iter: 89800, loss: 31.159494400024414\n",
      "epoch: 0, iter: 89900, loss: 31.063404083251953\n",
      "epoch: 0, iter: 90000, loss: 30.869632720947266\n",
      "epoch: 0, iter: 90100, loss: 30.926593780517578\n",
      "epoch: 0, iter: 90200, loss: 30.455570220947266\n",
      "epoch: 0, iter: 90300, loss: 30.574127197265625\n",
      "epoch: 0, iter: 90400, loss: 30.819486618041992\n",
      "epoch: 0, iter: 90500, loss: 31.135086059570312\n",
      "epoch: 0, iter: 90600, loss: 30.72440528869629\n",
      "epoch: 0, iter: 90700, loss: 31.028133392333984\n",
      "epoch: 0, iter: 90800, loss: 30.742107391357422\n",
      "epoch: 0, iter: 90900, loss: 30.969228744506836\n",
      "epoch: 0, iter: 91000, loss: 30.526260375976562\n",
      "epoch: 0, iter: 91100, loss: 31.11067771911621\n",
      "epoch: 0, iter: 91200, loss: 31.039575576782227\n",
      "epoch: 0, iter: 91300, loss: 30.83376693725586\n",
      "epoch: 0, iter: 91400, loss: 30.924652099609375\n",
      "epoch: 0, iter: 91500, loss: 30.747825622558594\n",
      "epoch: 0, iter: 91600, loss: 30.74045181274414\n",
      "epoch: 0, iter: 91700, loss: 30.538719177246094\n",
      "epoch: 0, iter: 91800, loss: 30.515018463134766\n",
      "epoch: 0, iter: 91900, loss: 31.033782958984375\n",
      "epoch: 0, iter: 92000, loss: 30.666610717773438\n",
      "epoch: 0, iter: 92100, loss: 30.169403076171875\n",
      "epoch: 0, iter: 92200, loss: 30.81360626220703\n",
      "epoch: 0, iter: 92300, loss: 30.48513412475586\n",
      "epoch: 0, iter: 92400, loss: 30.952552795410156\n",
      "epoch: 0, iter: 92500, loss: 30.92270851135254\n",
      "epoch: 0, iter: 92600, loss: 30.913150787353516\n",
      "epoch: 0, iter: 92700, loss: 30.956729888916016\n",
      "epoch: 0, iter: 92800, loss: 30.923492431640625\n",
      "epoch: 0, iter: 92900, loss: 30.820240020751953\n",
      "epoch: 0, iter: 93000, loss: 30.806177139282227\n",
      "epoch: 0, iter: 93100, loss: 30.783329010009766\n",
      "epoch: 0, iter: 93200, loss: 30.810508728027344\n",
      "epoch: 0, iter: 93300, loss: 30.79157257080078\n",
      "epoch: 0, iter: 93400, loss: 30.942171096801758\n",
      "epoch: 0, iter: 93500, loss: 30.509502410888672\n",
      "epoch: 0, iter: 93600, loss: 30.521995544433594\n",
      "epoch: 0, iter: 93700, loss: 30.457801818847656\n",
      "epoch: 0, iter: 93800, loss: 31.03296661376953\n",
      "epoch: 0, iter: 93900, loss: 30.961811065673828\n",
      "epoch: 0, iter: 94000, loss: 31.02105140686035\n",
      "epoch: 0, iter: 94100, loss: 30.515138626098633\n",
      "epoch: 0, iter: 94200, loss: 30.86614990234375\n",
      "epoch: 0, iter: 94300, loss: 30.83415985107422\n",
      "epoch: 0, iter: 94400, loss: 30.496503829956055\n",
      "epoch: 0, iter: 94500, loss: 30.09665870666504\n",
      "epoch: 0, iter: 94600, loss: 30.280475616455078\n",
      "epoch: 0, iter: 94700, loss: 30.204376220703125\n",
      "epoch: 0, iter: 94800, loss: 30.82103729248047\n",
      "epoch: 0, iter: 94900, loss: 30.589731216430664\n",
      "epoch: 0, iter: 95000, loss: 30.553394317626953\n",
      "epoch: 0, iter: 95100, loss: 30.821800231933594\n",
      "epoch: 0, iter: 95200, loss: 30.660888671875\n",
      "epoch: 0, iter: 95300, loss: 30.564367294311523\n",
      "epoch: 0, iter: 95400, loss: 30.891679763793945\n",
      "epoch: 0, iter: 95500, loss: 30.556814193725586\n",
      "epoch: 0, iter: 95600, loss: 30.613862991333008\n",
      "epoch: 0, iter: 95700, loss: 31.04448890686035\n",
      "epoch: 0, iter: 95800, loss: 31.260719299316406\n",
      "epoch: 0, iter: 95900, loss: 30.75055694580078\n",
      "epoch: 0, iter: 96000, loss: 30.650100708007812\n",
      "epoch: 0, iter: 96100, loss: 30.862781524658203\n",
      "epoch: 0, iter: 96200, loss: 30.392404556274414\n",
      "epoch: 0, iter: 96300, loss: 31.002397537231445\n",
      "epoch: 0, iter: 96400, loss: 30.56821060180664\n",
      "epoch: 0, iter: 96500, loss: 30.746322631835938\n",
      "epoch: 0, iter: 96600, loss: 30.787586212158203\n",
      "epoch: 0, iter: 96700, loss: 30.721607208251953\n",
      "epoch: 0, iter: 96800, loss: 30.777442932128906\n",
      "epoch: 0, iter: 96900, loss: 30.837303161621094\n",
      "epoch: 0, iter: 97000, loss: 30.811994552612305\n",
      "epoch: 0, iter: 97100, loss: 31.0023193359375\n",
      "epoch: 0, iter: 97200, loss: 31.15359115600586\n",
      "epoch: 0, iter: 97300, loss: 30.43343162536621\n",
      "epoch: 0, iter: 97400, loss: 30.872173309326172\n",
      "epoch: 0, iter: 97500, loss: 30.938297271728516\n",
      "epoch: 0, iter: 97600, loss: 30.654165267944336\n",
      "epoch: 0, iter: 97700, loss: 30.550540924072266\n",
      "epoch: 0, iter: 97800, loss: 30.56627655029297\n",
      "epoch: 0, iter: 97900, loss: 30.902305603027344\n",
      "epoch: 0, iter: 98000, loss: 30.631389617919922\n",
      "epoch: 0, iter: 98100, loss: 31.10843276977539\n",
      "epoch: 0, iter: 98200, loss: 30.164403915405273\n",
      "epoch: 0, iter: 98300, loss: 30.755172729492188\n",
      "epoch: 0, iter: 98400, loss: 30.7115421295166\n",
      "epoch: 0, iter: 98500, loss: 31.20368766784668\n",
      "epoch: 0, iter: 98600, loss: 31.17707061767578\n",
      "epoch: 0, iter: 98700, loss: 30.532468795776367\n",
      "epoch: 0, iter: 98800, loss: 30.532047271728516\n",
      "epoch: 0, iter: 98900, loss: 31.152324676513672\n",
      "epoch: 0, iter: 99000, loss: 30.68151092529297\n",
      "epoch: 0, iter: 99100, loss: 30.742313385009766\n",
      "epoch: 0, iter: 99200, loss: 30.423973083496094\n",
      "epoch: 0, iter: 99300, loss: 30.777591705322266\n",
      "epoch: 0, iter: 99400, loss: 30.720081329345703\n",
      "epoch: 0, iter: 99500, loss: 30.63253402709961\n",
      "epoch: 0, iter: 99600, loss: 31.150541305541992\n",
      "epoch: 0, iter: 99700, loss: 30.285709381103516\n",
      "epoch: 0, iter: 99800, loss: 30.50328826904297\n",
      "epoch: 0, iter: 99900, loss: 30.849552154541016\n",
      "epoch: 0, iter: 100000, loss: 30.66472625732422\n",
      "epoch: 0, iter: 100100, loss: 30.542518615722656\n",
      "epoch: 0, iter: 100200, loss: 30.481548309326172\n",
      "epoch: 0, iter: 100300, loss: 30.641807556152344\n",
      "epoch: 0, iter: 100400, loss: 30.616722106933594\n",
      "epoch: 0, iter: 100500, loss: 31.43733024597168\n",
      "epoch: 0, iter: 100600, loss: 30.5592098236084\n",
      "epoch: 0, iter: 100700, loss: 30.64618682861328\n",
      "epoch: 0, iter: 100800, loss: 30.667667388916016\n",
      "epoch: 0, iter: 100900, loss: 30.57941436767578\n",
      "epoch: 0, iter: 101000, loss: 30.649484634399414\n",
      "epoch: 0, iter: 101100, loss: 30.343795776367188\n",
      "epoch: 0, iter: 101200, loss: 30.685834884643555\n",
      "epoch: 0, iter: 101300, loss: 30.57326316833496\n",
      "epoch: 0, iter: 101400, loss: 31.12020492553711\n",
      "epoch: 0, iter: 101500, loss: 30.61260414123535\n",
      "epoch: 0, iter: 101600, loss: 30.595487594604492\n",
      "epoch: 0, iter: 101700, loss: 30.627391815185547\n",
      "epoch: 0, iter: 101800, loss: 30.75408363342285\n",
      "epoch: 0, iter: 101900, loss: 30.808713912963867\n",
      "epoch: 0, iter: 102000, loss: 30.4384765625\n",
      "epoch: 0, iter: 102100, loss: 30.828664779663086\n",
      "epoch: 0, iter: 102200, loss: 30.415929794311523\n",
      "epoch: 0, iter: 102300, loss: 30.796133041381836\n",
      "epoch: 0, iter: 102400, loss: 30.121837615966797\n",
      "epoch: 0, iter: 102500, loss: 30.722368240356445\n",
      "epoch: 0, iter: 102600, loss: 30.579057693481445\n",
      "epoch: 0, iter: 102700, loss: 30.329822540283203\n",
      "epoch: 0, iter: 102800, loss: 31.22494888305664\n",
      "epoch: 0, iter: 102900, loss: 30.971097946166992\n",
      "epoch: 0, iter: 103000, loss: 30.638866424560547\n",
      "epoch: 0, iter: 103100, loss: 31.018417358398438\n",
      "epoch: 0, iter: 103200, loss: 30.179767608642578\n",
      "epoch: 0, iter: 103300, loss: 30.688016891479492\n",
      "epoch: 0, iter: 103400, loss: 30.428909301757812\n",
      "epoch: 0, iter: 103500, loss: 31.12614631652832\n",
      "epoch: 0, iter: 103600, loss: 30.53960609436035\n",
      "epoch: 0, iter: 103700, loss: 29.98431968688965\n",
      "epoch: 0, iter: 103800, loss: 30.476659774780273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 103900, loss: 30.674081802368164\n",
      "epoch: 0, iter: 104000, loss: 30.35460662841797\n",
      "epoch: 0, iter: 104100, loss: 30.83035659790039\n",
      "epoch: 0, iter: 104200, loss: 31.146326065063477\n",
      "epoch: 0, iter: 104300, loss: 30.680477142333984\n",
      "epoch: 0, iter: 104400, loss: 30.960525512695312\n",
      "epoch: 0, iter: 104500, loss: 30.79071807861328\n",
      "epoch: 0, iter: 104600, loss: 30.919540405273438\n",
      "epoch: 0, iter: 104700, loss: 30.426223754882812\n",
      "epoch: 0, iter: 104800, loss: 30.80300521850586\n",
      "epoch: 0, iter: 104900, loss: 30.74164390563965\n",
      "epoch: 0, iter: 105000, loss: 30.667709350585938\n",
      "epoch: 0, iter: 105100, loss: 30.866111755371094\n",
      "epoch: 0, iter: 105200, loss: 30.27899742126465\n",
      "epoch: 0, iter: 105300, loss: 30.889413833618164\n",
      "epoch: 0, iter: 105400, loss: 30.709369659423828\n",
      "epoch: 0, iter: 105500, loss: 30.997323989868164\n",
      "epoch: 0, iter: 105600, loss: 31.118188858032227\n",
      "epoch: 0, iter: 105700, loss: 30.66849136352539\n",
      "epoch: 0, iter: 105800, loss: 30.719955444335938\n",
      "epoch: 0, iter: 105900, loss: 31.02789306640625\n",
      "epoch: 0, iter: 106000, loss: 30.47199249267578\n",
      "epoch: 0, iter: 106100, loss: 30.85265350341797\n",
      "epoch: 0, iter: 106200, loss: 30.304967880249023\n",
      "epoch: 0, iter: 106300, loss: 30.969934463500977\n",
      "epoch: 0, iter: 106400, loss: 30.512161254882812\n",
      "epoch: 0, iter: 106500, loss: 30.36647605895996\n",
      "epoch: 0, iter: 106600, loss: 30.49534034729004\n",
      "epoch: 0, iter: 106700, loss: 31.232627868652344\n",
      "epoch: 0, iter: 106800, loss: 30.42694854736328\n",
      "epoch: 0, iter: 106900, loss: 30.94650650024414\n",
      "epoch: 0, iter: 107000, loss: 30.330978393554688\n",
      "epoch: 0, iter: 107100, loss: 30.698192596435547\n",
      "epoch: 0, iter: 107200, loss: 30.393573760986328\n",
      "epoch: 0, iter: 107300, loss: 30.65157699584961\n",
      "epoch: 0, iter: 107400, loss: 30.172378540039062\n",
      "epoch: 0, iter: 107500, loss: 31.19135284423828\n",
      "epoch: 0, iter: 107600, loss: 30.67481803894043\n",
      "epoch: 0, iter: 107700, loss: 30.59949493408203\n",
      "epoch: 0, iter: 107800, loss: 30.86219024658203\n",
      "epoch: 0, iter: 107900, loss: 30.102397918701172\n",
      "epoch: 0, iter: 108000, loss: 30.443866729736328\n",
      "epoch: 0, iter: 108100, loss: 30.522235870361328\n",
      "epoch: 0, iter: 108200, loss: 30.653244018554688\n",
      "epoch: 0, iter: 108300, loss: 30.687475204467773\n",
      "epoch: 0, iter: 108400, loss: 30.823524475097656\n",
      "epoch: 0, iter: 108500, loss: 30.56606101989746\n",
      "epoch: 0, iter: 108600, loss: 30.677146911621094\n",
      "epoch: 0, iter: 108700, loss: 30.84006690979004\n",
      "epoch: 0, iter: 108800, loss: 30.653076171875\n",
      "epoch: 0, iter: 108900, loss: 30.976402282714844\n",
      "epoch: 0, iter: 109000, loss: 30.386083602905273\n",
      "epoch: 0, iter: 109100, loss: 30.8797550201416\n",
      "epoch: 0, iter: 109200, loss: 30.63524627685547\n",
      "epoch: 0, iter: 109300, loss: 30.392316818237305\n",
      "epoch: 0, iter: 109400, loss: 30.84273910522461\n",
      "epoch: 0, iter: 109500, loss: 30.83037567138672\n",
      "epoch: 0, iter: 109600, loss: 30.466033935546875\n",
      "epoch: 0, iter: 109700, loss: 30.72401237487793\n",
      "epoch: 0, iter: 109800, loss: 31.084272384643555\n",
      "epoch: 0, iter: 109900, loss: 30.678966522216797\n",
      "epoch: 0, iter: 110000, loss: 30.59455108642578\n",
      "epoch: 0, iter: 110100, loss: 31.028013229370117\n",
      "epoch: 0, iter: 110200, loss: 30.671220779418945\n",
      "epoch: 0, iter: 110300, loss: 30.925827026367188\n",
      "epoch: 0, iter: 110400, loss: 30.798646926879883\n",
      "epoch: 0, iter: 110500, loss: 30.461101531982422\n",
      "epoch: 0, iter: 110600, loss: 30.09445571899414\n",
      "epoch: 0, iter: 110700, loss: 30.759567260742188\n",
      "epoch: 0, iter: 110800, loss: 30.808591842651367\n",
      "epoch: 0, iter: 110900, loss: 30.384937286376953\n",
      "epoch: 0, iter: 111000, loss: 30.650104522705078\n",
      "epoch: 0, iter: 111100, loss: 30.679203033447266\n",
      "epoch: 0, iter: 111200, loss: 31.01488494873047\n",
      "epoch: 0, iter: 111300, loss: 30.506637573242188\n",
      "epoch: 0, iter: 111400, loss: 30.94546890258789\n",
      "epoch: 0, iter: 111500, loss: 30.983997344970703\n",
      "epoch: 0, iter: 111600, loss: 30.23942756652832\n",
      "epoch: 0, iter: 111700, loss: 30.90601348876953\n",
      "epoch: 0, iter: 111800, loss: 30.20038604736328\n",
      "epoch: 0, iter: 111900, loss: 31.15056610107422\n",
      "epoch: 0, iter: 112000, loss: 30.593534469604492\n",
      "epoch: 0, iter: 112100, loss: 30.578472137451172\n",
      "epoch: 0, iter: 112200, loss: 30.95712661743164\n",
      "epoch: 0, iter: 112300, loss: 30.68983268737793\n",
      "epoch: 0, iter: 112400, loss: 30.77518081665039\n",
      "epoch: 0, iter: 112500, loss: 31.115793228149414\n",
      "epoch: 0, iter: 112600, loss: 30.864206314086914\n",
      "epoch: 0, iter: 112700, loss: 30.986652374267578\n",
      "epoch: 0, iter: 112800, loss: 30.9410400390625\n",
      "epoch: 0, iter: 112900, loss: 31.125595092773438\n",
      "epoch: 0, iter: 113000, loss: 30.48320770263672\n",
      "epoch: 0, iter: 113100, loss: 30.976619720458984\n",
      "epoch: 0, iter: 113200, loss: 31.22491455078125\n",
      "epoch: 0, iter: 113300, loss: 30.862648010253906\n",
      "epoch: 0, iter: 113400, loss: 30.952194213867188\n",
      "epoch: 0, iter: 113500, loss: 30.60572052001953\n",
      "epoch: 0, iter: 113600, loss: 30.647113800048828\n",
      "epoch: 0, iter: 113700, loss: 30.654592514038086\n",
      "epoch: 0, iter: 113800, loss: 30.3441162109375\n",
      "epoch: 0, iter: 113900, loss: 31.515335083007812\n",
      "epoch: 0, iter: 114000, loss: 30.43185043334961\n",
      "epoch: 0, iter: 114100, loss: 31.019607543945312\n",
      "epoch: 0, iter: 114200, loss: 30.714908599853516\n",
      "epoch: 0, iter: 114300, loss: 30.66822052001953\n",
      "epoch: 0, iter: 114400, loss: 30.59111785888672\n",
      "epoch: 0, iter: 114500, loss: 31.021148681640625\n",
      "epoch: 0, iter: 114600, loss: 29.970237731933594\n",
      "epoch: 0, iter: 114700, loss: 30.928258895874023\n",
      "epoch: 0, iter: 114800, loss: 31.255313873291016\n",
      "epoch: 0, iter: 114900, loss: 30.552276611328125\n",
      "epoch: 0, iter: 115000, loss: 30.73168182373047\n",
      "epoch: 0, iter: 115100, loss: 30.617666244506836\n",
      "epoch: 0, iter: 115200, loss: 30.962753295898438\n",
      "epoch: 0, iter: 115300, loss: 30.28232192993164\n",
      "epoch: 0, iter: 115400, loss: 30.36166000366211\n",
      "epoch: 0, iter: 115500, loss: 30.817123413085938\n",
      "epoch: 0, iter: 115600, loss: 30.59137725830078\n",
      "epoch: 0, iter: 115700, loss: 30.743289947509766\n",
      "epoch: 0, iter: 115800, loss: 31.026573181152344\n",
      "epoch: 0, iter: 115900, loss: 30.687023162841797\n",
      "epoch: 0, iter: 116000, loss: 30.509746551513672\n",
      "epoch: 0, iter: 116100, loss: 30.291982650756836\n",
      "epoch: 0, iter: 116200, loss: 30.568538665771484\n",
      "epoch: 0, iter: 116300, loss: 31.007749557495117\n",
      "epoch: 0, iter: 116400, loss: 30.51165771484375\n",
      "epoch: 0, iter: 116500, loss: 30.07297134399414\n",
      "epoch: 0, iter: 116600, loss: 30.475807189941406\n",
      "epoch: 0, iter: 116700, loss: 30.739227294921875\n",
      "epoch: 0, iter: 116800, loss: 30.545642852783203\n",
      "epoch: 0, iter: 116900, loss: 30.96780776977539\n",
      "epoch: 0, iter: 117000, loss: 31.00707244873047\n",
      "epoch: 0, iter: 117100, loss: 30.94534683227539\n",
      "epoch: 0, iter: 117200, loss: 30.447650909423828\n",
      "epoch: 0, iter: 117300, loss: 30.4835205078125\n",
      "epoch: 0, iter: 117400, loss: 30.447551727294922\n",
      "epoch: 0, iter: 117500, loss: 30.604694366455078\n",
      "epoch: 0, iter: 117600, loss: 30.73851776123047\n",
      "epoch: 0, iter: 117700, loss: 31.059396743774414\n",
      "epoch: 0, iter: 117800, loss: 30.361495971679688\n",
      "epoch: 0, iter: 117900, loss: 30.46902847290039\n",
      "epoch: 0, iter: 118000, loss: 30.343149185180664\n",
      "epoch: 0, iter: 118100, loss: 30.63619613647461\n",
      "epoch: 0, iter: 118200, loss: 30.748735427856445\n",
      "epoch: 0, iter: 118300, loss: 30.167072296142578\n",
      "epoch: 0, iter: 118400, loss: 30.436481475830078\n",
      "epoch: 0, iter: 118500, loss: 31.00385093688965\n",
      "epoch: 0, iter: 118600, loss: 30.667766571044922\n",
      "epoch: 0, iter: 118700, loss: 30.76891326904297\n",
      "epoch: 0, iter: 118800, loss: 30.629369735717773\n",
      "epoch: 0, iter: 118900, loss: 30.637237548828125\n",
      "epoch: 0, iter: 119000, loss: 30.323270797729492\n",
      "epoch: 0, iter: 119100, loss: 30.66899871826172\n",
      "epoch: 0, iter: 119200, loss: 30.521339416503906\n",
      "epoch: 0, iter: 119300, loss: 30.357139587402344\n",
      "epoch: 0, iter: 119400, loss: 31.160324096679688\n",
      "epoch: 0, iter: 119500, loss: 30.724796295166016\n",
      "epoch: 0, iter: 119600, loss: 30.74036407470703\n",
      "epoch: 1, iter: 0, loss: 30.71976089477539\n",
      "epoch: 1, iter: 100, loss: 30.084476470947266\n",
      "epoch: 1, iter: 200, loss: 30.41571617126465\n",
      "epoch: 1, iter: 300, loss: 30.397075653076172\n",
      "epoch: 1, iter: 400, loss: 30.662094116210938\n",
      "epoch: 1, iter: 500, loss: 30.710554122924805\n",
      "epoch: 1, iter: 600, loss: 30.15116310119629\n",
      "epoch: 1, iter: 700, loss: 30.084592819213867\n",
      "epoch: 1, iter: 800, loss: 30.378742218017578\n",
      "epoch: 1, iter: 900, loss: 30.54198455810547\n",
      "epoch: 1, iter: 1000, loss: 30.790851593017578\n",
      "epoch: 1, iter: 1100, loss: 30.87466812133789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, iter: 1200, loss: 30.90398406982422\n",
      "epoch: 1, iter: 1300, loss: 30.337127685546875\n",
      "epoch: 1, iter: 1400, loss: 30.025943756103516\n",
      "epoch: 1, iter: 1500, loss: 30.769142150878906\n",
      "epoch: 1, iter: 1600, loss: 30.90045928955078\n",
      "epoch: 1, iter: 1700, loss: 31.043075561523438\n",
      "epoch: 1, iter: 1800, loss: 30.984947204589844\n",
      "epoch: 1, iter: 1900, loss: 30.78077507019043\n",
      "epoch: 1, iter: 2000, loss: 30.581771850585938\n",
      "epoch: 1, iter: 2100, loss: 30.577415466308594\n",
      "epoch: 1, iter: 2200, loss: 30.466211318969727\n",
      "epoch: 1, iter: 2300, loss: 30.72731590270996\n",
      "epoch: 1, iter: 2400, loss: 30.815216064453125\n",
      "epoch: 1, iter: 2500, loss: 31.540935516357422\n",
      "epoch: 1, iter: 2600, loss: 31.125797271728516\n",
      "epoch: 1, iter: 2700, loss: 30.79547691345215\n",
      "epoch: 1, iter: 2800, loss: 30.748172760009766\n",
      "epoch: 1, iter: 2900, loss: 30.68405532836914\n",
      "epoch: 1, iter: 3000, loss: 30.88804054260254\n",
      "epoch: 1, iter: 3100, loss: 30.648780822753906\n",
      "epoch: 1, iter: 3200, loss: 30.037246704101562\n",
      "epoch: 1, iter: 3300, loss: 30.429903030395508\n",
      "epoch: 1, iter: 3400, loss: 30.83818817138672\n",
      "epoch: 1, iter: 3500, loss: 30.374473571777344\n",
      "epoch: 1, iter: 3600, loss: 31.16690444946289\n",
      "epoch: 1, iter: 3700, loss: 29.957595825195312\n",
      "epoch: 1, iter: 3800, loss: 30.451725006103516\n",
      "epoch: 1, iter: 3900, loss: 30.873655319213867\n",
      "epoch: 1, iter: 4000, loss: 30.50556182861328\n",
      "epoch: 1, iter: 4100, loss: 30.346282958984375\n",
      "epoch: 1, iter: 4200, loss: 30.669475555419922\n",
      "epoch: 1, iter: 4300, loss: 30.429424285888672\n",
      "epoch: 1, iter: 4400, loss: 30.089977264404297\n",
      "epoch: 1, iter: 4500, loss: 30.64828872680664\n",
      "epoch: 1, iter: 4600, loss: 30.600814819335938\n",
      "epoch: 1, iter: 4700, loss: 30.86286163330078\n",
      "epoch: 1, iter: 4800, loss: 30.375511169433594\n",
      "epoch: 1, iter: 4900, loss: 30.661550521850586\n",
      "epoch: 1, iter: 5000, loss: 30.580814361572266\n",
      "epoch: 1, iter: 5100, loss: 30.5135440826416\n",
      "epoch: 1, iter: 5200, loss: 30.838191986083984\n",
      "epoch: 1, iter: 5300, loss: 30.67116928100586\n",
      "epoch: 1, iter: 5400, loss: 30.31780242919922\n",
      "epoch: 1, iter: 5500, loss: 30.575822830200195\n",
      "epoch: 1, iter: 5600, loss: 30.958755493164062\n",
      "epoch: 1, iter: 5700, loss: 30.756614685058594\n",
      "epoch: 1, iter: 5800, loss: 30.32583999633789\n",
      "epoch: 1, iter: 5900, loss: 31.169904708862305\n",
      "epoch: 1, iter: 6000, loss: 30.336036682128906\n",
      "epoch: 1, iter: 6100, loss: 29.98763084411621\n",
      "epoch: 1, iter: 6200, loss: 30.61154556274414\n",
      "epoch: 1, iter: 6300, loss: 30.807186126708984\n",
      "epoch: 1, iter: 6400, loss: 30.253379821777344\n",
      "epoch: 1, iter: 6500, loss: 30.779769897460938\n",
      "epoch: 1, iter: 6600, loss: 30.621837615966797\n",
      "epoch: 1, iter: 6700, loss: 30.806385040283203\n",
      "epoch: 1, iter: 6800, loss: 30.825403213500977\n",
      "epoch: 1, iter: 6900, loss: 30.696931838989258\n",
      "epoch: 1, iter: 7000, loss: 30.674182891845703\n",
      "epoch: 1, iter: 7100, loss: 30.781997680664062\n",
      "epoch: 1, iter: 7200, loss: 30.526302337646484\n",
      "epoch: 1, iter: 7300, loss: 30.74518394470215\n",
      "epoch: 1, iter: 7400, loss: 30.54595184326172\n",
      "epoch: 1, iter: 7500, loss: 31.065046310424805\n",
      "epoch: 1, iter: 7600, loss: 30.338581085205078\n",
      "epoch: 1, iter: 7700, loss: 30.058631896972656\n",
      "epoch: 1, iter: 7800, loss: 30.662792205810547\n",
      "epoch: 1, iter: 7900, loss: 30.051612854003906\n",
      "epoch: 1, iter: 8000, loss: 30.190948486328125\n",
      "epoch: 1, iter: 8100, loss: 31.202163696289062\n",
      "epoch: 1, iter: 8200, loss: 30.35299301147461\n",
      "epoch: 1, iter: 8300, loss: 29.961734771728516\n",
      "epoch: 1, iter: 8400, loss: 30.732879638671875\n",
      "epoch: 1, iter: 8500, loss: 30.5893497467041\n",
      "epoch: 1, iter: 8600, loss: 30.764631271362305\n",
      "epoch: 1, iter: 8700, loss: 30.37439727783203\n",
      "epoch: 1, iter: 8800, loss: 30.54071044921875\n",
      "epoch: 1, iter: 8900, loss: 30.32478904724121\n",
      "epoch: 1, iter: 9000, loss: 30.278636932373047\n",
      "epoch: 1, iter: 9100, loss: 30.354413986206055\n",
      "epoch: 1, iter: 9200, loss: 30.54250717163086\n",
      "epoch: 1, iter: 9300, loss: 30.122350692749023\n",
      "epoch: 1, iter: 9400, loss: 30.67013931274414\n",
      "epoch: 1, iter: 9500, loss: 30.06004524230957\n",
      "epoch: 1, iter: 9600, loss: 30.67119026184082\n",
      "epoch: 1, iter: 9700, loss: 30.56114387512207\n",
      "epoch: 1, iter: 9800, loss: 29.947242736816406\n",
      "epoch: 1, iter: 9900, loss: 30.776628494262695\n",
      "epoch: 1, iter: 10000, loss: 30.734004974365234\n",
      "epoch: 1, iter: 10100, loss: 30.035778045654297\n",
      "epoch: 1, iter: 10200, loss: 30.3647403717041\n",
      "epoch: 1, iter: 10300, loss: 30.83330535888672\n",
      "epoch: 1, iter: 10400, loss: 31.039033889770508\n",
      "epoch: 1, iter: 10500, loss: 30.75676155090332\n",
      "epoch: 1, iter: 10600, loss: 30.30689811706543\n",
      "epoch: 1, iter: 10700, loss: 30.545822143554688\n",
      "epoch: 1, iter: 10800, loss: 30.858139038085938\n",
      "epoch: 1, iter: 10900, loss: 30.303916931152344\n",
      "epoch: 1, iter: 11000, loss: 30.384586334228516\n",
      "epoch: 1, iter: 11100, loss: 30.408023834228516\n",
      "epoch: 1, iter: 11200, loss: 31.292388916015625\n",
      "epoch: 1, iter: 11300, loss: 30.879085540771484\n",
      "epoch: 1, iter: 11400, loss: 30.118328094482422\n",
      "epoch: 1, iter: 11500, loss: 30.358238220214844\n",
      "epoch: 1, iter: 11600, loss: 30.517162322998047\n",
      "epoch: 1, iter: 11700, loss: 30.685375213623047\n",
      "epoch: 1, iter: 11800, loss: 30.730327606201172\n",
      "epoch: 1, iter: 11900, loss: 30.463890075683594\n",
      "epoch: 1, iter: 12000, loss: 30.709484100341797\n",
      "epoch: 1, iter: 12100, loss: 30.473541259765625\n",
      "epoch: 1, iter: 12200, loss: 29.984893798828125\n",
      "epoch: 1, iter: 12300, loss: 30.58772087097168\n",
      "epoch: 1, iter: 12400, loss: 31.13803482055664\n",
      "epoch: 1, iter: 12500, loss: 30.74394416809082\n",
      "epoch: 1, iter: 12600, loss: 30.910430908203125\n",
      "epoch: 1, iter: 12700, loss: 30.726810455322266\n",
      "epoch: 1, iter: 12800, loss: 30.963577270507812\n",
      "epoch: 1, iter: 12900, loss: 30.603824615478516\n",
      "epoch: 1, iter: 13000, loss: 30.57010269165039\n",
      "epoch: 1, iter: 13100, loss: 30.25127601623535\n",
      "epoch: 1, iter: 13200, loss: 30.410648345947266\n",
      "epoch: 1, iter: 13300, loss: 30.66110610961914\n",
      "epoch: 1, iter: 13400, loss: 31.023353576660156\n",
      "epoch: 1, iter: 13500, loss: 30.39820098876953\n",
      "epoch: 1, iter: 13600, loss: 30.6546630859375\n",
      "epoch: 1, iter: 13700, loss: 30.135181427001953\n",
      "epoch: 1, iter: 13800, loss: 30.546478271484375\n",
      "epoch: 1, iter: 13900, loss: 30.358701705932617\n",
      "epoch: 1, iter: 14000, loss: 30.345407485961914\n",
      "epoch: 1, iter: 14100, loss: 30.842164993286133\n",
      "epoch: 1, iter: 14200, loss: 30.34268569946289\n",
      "epoch: 1, iter: 14300, loss: 30.78016471862793\n",
      "epoch: 1, iter: 14400, loss: 30.938831329345703\n",
      "epoch: 1, iter: 14500, loss: 30.198352813720703\n",
      "epoch: 1, iter: 14600, loss: 30.838191986083984\n",
      "epoch: 1, iter: 14700, loss: 30.97863006591797\n",
      "epoch: 1, iter: 14800, loss: 30.236061096191406\n",
      "epoch: 1, iter: 14900, loss: 30.293725967407227\n",
      "epoch: 1, iter: 15000, loss: 29.784282684326172\n",
      "epoch: 1, iter: 15100, loss: 30.716968536376953\n",
      "epoch: 1, iter: 15200, loss: 30.627487182617188\n",
      "epoch: 1, iter: 15300, loss: 30.221832275390625\n",
      "epoch: 1, iter: 15400, loss: 30.637928009033203\n",
      "epoch: 1, iter: 15500, loss: 30.65829086303711\n",
      "epoch: 1, iter: 15600, loss: 30.437732696533203\n",
      "epoch: 1, iter: 15700, loss: 30.535686492919922\n",
      "epoch: 1, iter: 15800, loss: 29.98110008239746\n",
      "epoch: 1, iter: 15900, loss: 30.66077423095703\n",
      "epoch: 1, iter: 16000, loss: 30.437149047851562\n",
      "epoch: 1, iter: 16100, loss: 30.655405044555664\n",
      "epoch: 1, iter: 16200, loss: 30.56639289855957\n",
      "epoch: 1, iter: 16300, loss: 30.348554611206055\n",
      "epoch: 1, iter: 16400, loss: 30.99420738220215\n",
      "epoch: 1, iter: 16500, loss: 30.620601654052734\n",
      "epoch: 1, iter: 16600, loss: 29.82656478881836\n",
      "epoch: 1, iter: 16700, loss: 30.45382308959961\n",
      "epoch: 1, iter: 16800, loss: 30.344562530517578\n",
      "epoch: 1, iter: 16900, loss: 29.871368408203125\n",
      "epoch: 1, iter: 17000, loss: 30.283815383911133\n",
      "epoch: 1, iter: 17100, loss: 30.45245361328125\n",
      "epoch: 1, iter: 17200, loss: 30.79567527770996\n",
      "epoch: 1, iter: 17300, loss: 30.700302124023438\n",
      "epoch: 1, iter: 17400, loss: 30.542648315429688\n",
      "epoch: 1, iter: 17500, loss: 30.35318374633789\n",
      "epoch: 1, iter: 17600, loss: 30.54567527770996\n",
      "epoch: 1, iter: 17700, loss: 30.608285903930664\n",
      "epoch: 1, iter: 17800, loss: 30.65805435180664\n",
      "epoch: 1, iter: 17900, loss: 30.183956146240234\n",
      "epoch: 1, iter: 18000, loss: 30.15635871887207\n",
      "epoch: 1, iter: 18100, loss: 30.606294631958008\n",
      "epoch: 1, iter: 18200, loss: 30.881011962890625\n",
      "epoch: 1, iter: 18300, loss: 30.349987030029297\n",
      "epoch: 1, iter: 18400, loss: 30.053699493408203\n",
      "epoch: 1, iter: 18500, loss: 30.312557220458984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, iter: 18600, loss: 30.249128341674805\n",
      "epoch: 1, iter: 18700, loss: 30.850582122802734\n",
      "epoch: 1, iter: 18800, loss: 30.783145904541016\n",
      "epoch: 1, iter: 18900, loss: 30.792804718017578\n",
      "epoch: 1, iter: 19000, loss: 30.88478660583496\n",
      "epoch: 1, iter: 19100, loss: 30.52022933959961\n",
      "epoch: 1, iter: 19200, loss: 30.67708969116211\n",
      "epoch: 1, iter: 19300, loss: 30.645896911621094\n",
      "epoch: 1, iter: 19400, loss: 30.563983917236328\n",
      "epoch: 1, iter: 19500, loss: 30.33136558532715\n",
      "epoch: 1, iter: 19600, loss: 30.210552215576172\n",
      "epoch: 1, iter: 19700, loss: 30.53665542602539\n",
      "epoch: 1, iter: 19800, loss: 30.190975189208984\n",
      "epoch: 1, iter: 19900, loss: 30.286605834960938\n",
      "epoch: 1, iter: 20000, loss: 29.880535125732422\n",
      "epoch: 1, iter: 20100, loss: 30.23796844482422\n",
      "epoch: 1, iter: 20200, loss: 30.90981101989746\n",
      "epoch: 1, iter: 20300, loss: 30.482065200805664\n",
      "epoch: 1, iter: 20400, loss: 31.062692642211914\n",
      "epoch: 1, iter: 20500, loss: 30.388273239135742\n",
      "epoch: 1, iter: 20600, loss: 30.35875129699707\n",
      "epoch: 1, iter: 20700, loss: 30.453243255615234\n",
      "epoch: 1, iter: 20800, loss: 29.927560806274414\n",
      "epoch: 1, iter: 20900, loss: 30.110218048095703\n",
      "epoch: 1, iter: 21000, loss: 30.862079620361328\n",
      "epoch: 1, iter: 21100, loss: 31.03976821899414\n",
      "epoch: 1, iter: 21200, loss: 30.5425968170166\n",
      "epoch: 1, iter: 21300, loss: 30.3013916015625\n",
      "epoch: 1, iter: 21400, loss: 30.35097312927246\n",
      "epoch: 1, iter: 21500, loss: 30.136289596557617\n",
      "epoch: 1, iter: 21600, loss: 30.56905174255371\n",
      "epoch: 1, iter: 21700, loss: 30.230894088745117\n",
      "epoch: 1, iter: 21800, loss: 30.823776245117188\n",
      "epoch: 1, iter: 21900, loss: 30.509450912475586\n",
      "epoch: 1, iter: 22000, loss: 30.630184173583984\n",
      "epoch: 1, iter: 22100, loss: 30.714683532714844\n",
      "epoch: 1, iter: 22200, loss: 30.130035400390625\n",
      "epoch: 1, iter: 22300, loss: 30.73556137084961\n",
      "epoch: 1, iter: 22400, loss: 30.555038452148438\n",
      "epoch: 1, iter: 22500, loss: 30.831083297729492\n",
      "epoch: 1, iter: 22600, loss: 30.694549560546875\n",
      "epoch: 1, iter: 22700, loss: 30.537076950073242\n",
      "epoch: 1, iter: 22800, loss: 30.402812957763672\n",
      "epoch: 1, iter: 22900, loss: 29.504262924194336\n",
      "epoch: 1, iter: 23000, loss: 30.229658126831055\n",
      "epoch: 1, iter: 23100, loss: 30.31014633178711\n",
      "epoch: 1, iter: 23200, loss: 30.62055015563965\n",
      "epoch: 1, iter: 23300, loss: 30.05476951599121\n",
      "epoch: 1, iter: 23400, loss: 30.90252685546875\n",
      "epoch: 1, iter: 23500, loss: 30.488569259643555\n",
      "epoch: 1, iter: 23600, loss: 30.38129234313965\n",
      "epoch: 1, iter: 23700, loss: 30.038434982299805\n",
      "epoch: 1, iter: 23800, loss: 30.6844482421875\n",
      "epoch: 1, iter: 23900, loss: 30.62253761291504\n",
      "epoch: 1, iter: 24000, loss: 30.709623336791992\n",
      "epoch: 1, iter: 24100, loss: 30.030210494995117\n",
      "epoch: 1, iter: 24200, loss: 30.66024398803711\n",
      "epoch: 1, iter: 24300, loss: 29.85492706298828\n",
      "epoch: 1, iter: 24400, loss: 30.21064567565918\n",
      "epoch: 1, iter: 24500, loss: 30.202003479003906\n",
      "epoch: 1, iter: 24600, loss: 30.765026092529297\n",
      "epoch: 1, iter: 24700, loss: 30.27276611328125\n",
      "epoch: 1, iter: 24800, loss: 30.247133255004883\n",
      "epoch: 1, iter: 24900, loss: 30.656497955322266\n",
      "epoch: 1, iter: 25000, loss: 30.594457626342773\n",
      "epoch: 1, iter: 25100, loss: 30.82118034362793\n",
      "epoch: 1, iter: 25200, loss: 30.65415382385254\n",
      "epoch: 1, iter: 25300, loss: 30.638856887817383\n",
      "epoch: 1, iter: 25400, loss: 30.00921630859375\n",
      "epoch: 1, iter: 25500, loss: 30.586130142211914\n",
      "epoch: 1, iter: 25600, loss: 30.382646560668945\n",
      "epoch: 1, iter: 25700, loss: 30.584991455078125\n",
      "epoch: 1, iter: 25800, loss: 30.157238006591797\n",
      "epoch: 1, iter: 25900, loss: 30.934932708740234\n",
      "epoch: 1, iter: 26000, loss: 30.65876007080078\n",
      "epoch: 1, iter: 26100, loss: 30.643348693847656\n",
      "epoch: 1, iter: 26200, loss: 30.145687103271484\n",
      "epoch: 1, iter: 26300, loss: 30.918216705322266\n",
      "epoch: 1, iter: 26400, loss: 30.649883270263672\n",
      "epoch: 1, iter: 26500, loss: 30.940025329589844\n",
      "epoch: 1, iter: 26600, loss: 29.897096633911133\n",
      "epoch: 1, iter: 26700, loss: 30.697887420654297\n",
      "epoch: 1, iter: 26800, loss: 30.89467430114746\n",
      "epoch: 1, iter: 26900, loss: 30.36260986328125\n",
      "epoch: 1, iter: 27000, loss: 30.6573429107666\n",
      "epoch: 1, iter: 27100, loss: 30.578683853149414\n",
      "epoch: 1, iter: 27200, loss: 30.78690528869629\n",
      "epoch: 1, iter: 27300, loss: 30.54818344116211\n",
      "epoch: 1, iter: 27400, loss: 30.102054595947266\n",
      "epoch: 1, iter: 27500, loss: 30.823204040527344\n",
      "epoch: 1, iter: 27600, loss: 30.70966911315918\n",
      "epoch: 1, iter: 27700, loss: 30.398876190185547\n",
      "epoch: 1, iter: 27800, loss: 30.905155181884766\n",
      "epoch: 1, iter: 27900, loss: 30.361169815063477\n",
      "epoch: 1, iter: 28000, loss: 30.79294204711914\n",
      "epoch: 1, iter: 28100, loss: 30.57744026184082\n",
      "epoch: 1, iter: 28200, loss: 30.704370498657227\n",
      "epoch: 1, iter: 28300, loss: 30.382038116455078\n",
      "epoch: 1, iter: 28400, loss: 30.072372436523438\n",
      "epoch: 1, iter: 28500, loss: 30.39193344116211\n",
      "epoch: 1, iter: 28600, loss: 29.906646728515625\n",
      "epoch: 1, iter: 28700, loss: 30.60773468017578\n",
      "epoch: 1, iter: 28800, loss: 30.280689239501953\n",
      "epoch: 1, iter: 28900, loss: 31.06291961669922\n",
      "epoch: 1, iter: 29000, loss: 30.791269302368164\n",
      "epoch: 1, iter: 29100, loss: 30.533416748046875\n",
      "epoch: 1, iter: 29200, loss: 30.597640991210938\n",
      "epoch: 1, iter: 29300, loss: 30.532108306884766\n",
      "epoch: 1, iter: 29400, loss: 30.073139190673828\n",
      "epoch: 1, iter: 29500, loss: 30.60085678100586\n",
      "epoch: 1, iter: 29600, loss: 30.702144622802734\n",
      "epoch: 1, iter: 29700, loss: 30.458675384521484\n",
      "epoch: 1, iter: 29800, loss: 30.47015380859375\n",
      "epoch: 1, iter: 29900, loss: 30.357101440429688\n",
      "epoch: 1, iter: 30000, loss: 30.41065216064453\n",
      "epoch: 1, iter: 30100, loss: 30.565811157226562\n",
      "epoch: 1, iter: 30200, loss: 30.678964614868164\n",
      "epoch: 1, iter: 30300, loss: 30.58132553100586\n",
      "epoch: 1, iter: 30400, loss: 30.583648681640625\n",
      "epoch: 1, iter: 30500, loss: 30.269594192504883\n",
      "epoch: 1, iter: 30600, loss: 30.525785446166992\n",
      "epoch: 1, iter: 30700, loss: 30.638633728027344\n",
      "epoch: 1, iter: 30800, loss: 30.95821189880371\n",
      "epoch: 1, iter: 30900, loss: 30.81084442138672\n",
      "epoch: 1, iter: 31000, loss: 30.469165802001953\n",
      "epoch: 1, iter: 31100, loss: 29.994394302368164\n",
      "epoch: 1, iter: 31200, loss: 30.378917694091797\n",
      "epoch: 1, iter: 31300, loss: 30.90320587158203\n",
      "epoch: 1, iter: 31400, loss: 30.688461303710938\n",
      "epoch: 1, iter: 31500, loss: 30.29631233215332\n",
      "epoch: 1, iter: 31600, loss: 30.95793914794922\n",
      "epoch: 1, iter: 31700, loss: 30.01892852783203\n",
      "epoch: 1, iter: 31800, loss: 29.8748779296875\n",
      "epoch: 1, iter: 31900, loss: 30.708759307861328\n",
      "epoch: 1, iter: 32000, loss: 30.562759399414062\n",
      "epoch: 1, iter: 32100, loss: 30.24029541015625\n",
      "epoch: 1, iter: 32200, loss: 30.36374282836914\n",
      "epoch: 1, iter: 32300, loss: 30.586536407470703\n",
      "epoch: 1, iter: 32400, loss: 30.292903900146484\n",
      "epoch: 1, iter: 32500, loss: 30.448421478271484\n",
      "epoch: 1, iter: 32600, loss: 30.71620750427246\n",
      "epoch: 1, iter: 32700, loss: 30.753253936767578\n",
      "epoch: 1, iter: 32800, loss: 30.531173706054688\n",
      "epoch: 1, iter: 32900, loss: 30.823711395263672\n",
      "epoch: 1, iter: 33000, loss: 30.26165771484375\n",
      "epoch: 1, iter: 33100, loss: 30.81259536743164\n",
      "epoch: 1, iter: 33200, loss: 30.621124267578125\n",
      "epoch: 1, iter: 33300, loss: 30.089847564697266\n",
      "epoch: 1, iter: 33400, loss: 30.624435424804688\n",
      "epoch: 1, iter: 33500, loss: 30.695846557617188\n",
      "epoch: 1, iter: 33600, loss: 30.70018768310547\n",
      "epoch: 1, iter: 33700, loss: 30.959918975830078\n",
      "epoch: 1, iter: 33800, loss: 30.803050994873047\n",
      "epoch: 1, iter: 33900, loss: 30.811561584472656\n",
      "epoch: 1, iter: 34000, loss: 30.28903579711914\n",
      "epoch: 1, iter: 34100, loss: 30.469711303710938\n",
      "epoch: 1, iter: 34200, loss: 30.561294555664062\n",
      "epoch: 1, iter: 34300, loss: 30.045684814453125\n",
      "epoch: 1, iter: 34400, loss: 31.105083465576172\n",
      "epoch: 1, iter: 34500, loss: 30.61907958984375\n",
      "epoch: 1, iter: 34600, loss: 30.30289649963379\n",
      "epoch: 1, iter: 34700, loss: 30.084026336669922\n",
      "epoch: 1, iter: 34800, loss: 30.359699249267578\n",
      "epoch: 1, iter: 34900, loss: 30.657379150390625\n",
      "epoch: 1, iter: 35000, loss: 30.89235496520996\n",
      "epoch: 1, iter: 35100, loss: 30.247615814208984\n",
      "epoch: 1, iter: 35200, loss: 30.898717880249023\n",
      "epoch: 1, iter: 35300, loss: 30.361560821533203\n",
      "epoch: 1, iter: 35400, loss: 30.549724578857422\n",
      "epoch: 1, iter: 35500, loss: 30.428794860839844\n",
      "epoch: 1, iter: 35600, loss: 31.001323699951172\n",
      "epoch: 1, iter: 35700, loss: 30.831218719482422\n",
      "epoch: 1, iter: 35800, loss: 30.39156723022461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, iter: 35900, loss: 30.534183502197266\n",
      "epoch: 1, iter: 36000, loss: 30.009206771850586\n",
      "epoch: 1, iter: 36100, loss: 30.621532440185547\n",
      "epoch: 1, iter: 36200, loss: 30.682458877563477\n",
      "epoch: 1, iter: 36300, loss: 30.842975616455078\n",
      "epoch: 1, iter: 36400, loss: 30.65481185913086\n",
      "epoch: 1, iter: 36500, loss: 30.222368240356445\n",
      "epoch: 1, iter: 36600, loss: 30.546770095825195\n",
      "epoch: 1, iter: 36700, loss: 30.72589874267578\n",
      "epoch: 1, iter: 36800, loss: 30.210983276367188\n",
      "epoch: 1, iter: 36900, loss: 30.662126541137695\n",
      "epoch: 1, iter: 37000, loss: 30.339113235473633\n",
      "epoch: 1, iter: 37100, loss: 30.632240295410156\n",
      "epoch: 1, iter: 37200, loss: 30.11248779296875\n",
      "epoch: 1, iter: 37300, loss: 30.81224822998047\n",
      "epoch: 1, iter: 37400, loss: 29.901453018188477\n",
      "epoch: 1, iter: 37500, loss: 30.180368423461914\n",
      "epoch: 1, iter: 37600, loss: 30.85427474975586\n",
      "epoch: 1, iter: 37700, loss: 31.092266082763672\n",
      "epoch: 1, iter: 37800, loss: 30.42523956298828\n",
      "epoch: 1, iter: 37900, loss: 30.025497436523438\n",
      "epoch: 1, iter: 38000, loss: 31.233394622802734\n",
      "epoch: 1, iter: 38100, loss: 30.466449737548828\n",
      "epoch: 1, iter: 38200, loss: 31.082149505615234\n",
      "epoch: 1, iter: 38300, loss: 30.843427658081055\n",
      "epoch: 1, iter: 38400, loss: 30.546100616455078\n",
      "epoch: 1, iter: 38500, loss: 30.45345687866211\n",
      "epoch: 1, iter: 38600, loss: 30.36328125\n",
      "epoch: 1, iter: 38700, loss: 29.913246154785156\n",
      "epoch: 1, iter: 38800, loss: 30.311359405517578\n",
      "epoch: 1, iter: 38900, loss: 30.76343536376953\n",
      "epoch: 1, iter: 39000, loss: 30.35335922241211\n",
      "epoch: 1, iter: 39100, loss: 30.678966522216797\n",
      "epoch: 1, iter: 39200, loss: 30.192338943481445\n",
      "epoch: 1, iter: 39300, loss: 30.365577697753906\n",
      "epoch: 1, iter: 39400, loss: 30.844362258911133\n",
      "epoch: 1, iter: 39500, loss: 30.680213928222656\n",
      "epoch: 1, iter: 39600, loss: 30.342863082885742\n",
      "epoch: 1, iter: 39700, loss: 29.921775817871094\n",
      "epoch: 1, iter: 39800, loss: 30.139253616333008\n",
      "epoch: 1, iter: 39900, loss: 30.47818946838379\n",
      "epoch: 1, iter: 40000, loss: 30.493207931518555\n",
      "epoch: 1, iter: 40100, loss: 30.654876708984375\n",
      "epoch: 1, iter: 40200, loss: 30.61440658569336\n",
      "epoch: 1, iter: 40300, loss: 30.723045349121094\n",
      "epoch: 1, iter: 40400, loss: 30.44856834411621\n",
      "epoch: 1, iter: 40500, loss: 30.478519439697266\n",
      "epoch: 1, iter: 40600, loss: 30.392662048339844\n",
      "epoch: 1, iter: 40700, loss: 30.666072845458984\n",
      "epoch: 1, iter: 40800, loss: 30.484989166259766\n",
      "epoch: 1, iter: 40900, loss: 30.105268478393555\n",
      "epoch: 1, iter: 41000, loss: 29.99415397644043\n",
      "epoch: 1, iter: 41100, loss: 30.767990112304688\n",
      "epoch: 1, iter: 41200, loss: 30.718128204345703\n",
      "epoch: 1, iter: 41300, loss: 30.601335525512695\n",
      "epoch: 1, iter: 41400, loss: 30.753076553344727\n",
      "epoch: 1, iter: 41500, loss: 30.129112243652344\n",
      "epoch: 1, iter: 41600, loss: 30.227069854736328\n",
      "epoch: 1, iter: 41700, loss: 30.806419372558594\n",
      "epoch: 1, iter: 41800, loss: 30.051218032836914\n",
      "epoch: 1, iter: 41900, loss: 30.765771865844727\n",
      "epoch: 1, iter: 42000, loss: 30.4988956451416\n",
      "epoch: 1, iter: 42100, loss: 30.10416603088379\n",
      "epoch: 1, iter: 42200, loss: 30.591827392578125\n",
      "epoch: 1, iter: 42300, loss: 30.570707321166992\n",
      "epoch: 1, iter: 42400, loss: 30.023117065429688\n",
      "epoch: 1, iter: 42500, loss: 30.362548828125\n",
      "epoch: 1, iter: 42600, loss: 30.176319122314453\n",
      "epoch: 1, iter: 42700, loss: 30.61092758178711\n",
      "epoch: 1, iter: 42800, loss: 29.832416534423828\n",
      "epoch: 1, iter: 42900, loss: 30.178211212158203\n",
      "epoch: 1, iter: 43000, loss: 30.168420791625977\n",
      "epoch: 1, iter: 43100, loss: 29.925151824951172\n",
      "epoch: 1, iter: 43200, loss: 30.41265296936035\n",
      "epoch: 1, iter: 43300, loss: 30.28765869140625\n",
      "epoch: 1, iter: 43400, loss: 30.62026023864746\n",
      "epoch: 1, iter: 43500, loss: 30.99013900756836\n",
      "epoch: 1, iter: 43600, loss: 30.929609298706055\n",
      "epoch: 1, iter: 43700, loss: 30.823291778564453\n",
      "epoch: 1, iter: 43800, loss: 30.119524002075195\n",
      "epoch: 1, iter: 43900, loss: 30.2744140625\n",
      "epoch: 1, iter: 44000, loss: 30.486738204956055\n",
      "epoch: 1, iter: 44100, loss: 30.12997055053711\n",
      "epoch: 1, iter: 44200, loss: 30.797054290771484\n",
      "epoch: 1, iter: 44300, loss: 30.641361236572266\n",
      "epoch: 1, iter: 44400, loss: 30.490985870361328\n",
      "epoch: 1, iter: 44500, loss: 30.41492462158203\n",
      "epoch: 1, iter: 44600, loss: 30.606060028076172\n",
      "epoch: 1, iter: 44700, loss: 30.497875213623047\n",
      "epoch: 1, iter: 44800, loss: 29.77224349975586\n",
      "epoch: 1, iter: 44900, loss: 30.329437255859375\n",
      "epoch: 1, iter: 45000, loss: 30.304889678955078\n",
      "epoch: 1, iter: 45100, loss: 30.172521591186523\n",
      "epoch: 1, iter: 45200, loss: 30.658302307128906\n",
      "epoch: 1, iter: 45300, loss: 30.446048736572266\n",
      "epoch: 1, iter: 45400, loss: 30.81130599975586\n",
      "epoch: 1, iter: 45500, loss: 30.238563537597656\n",
      "epoch: 1, iter: 45600, loss: 30.122278213500977\n",
      "epoch: 1, iter: 45700, loss: 30.542957305908203\n",
      "epoch: 1, iter: 45800, loss: 30.439804077148438\n",
      "epoch: 1, iter: 45900, loss: 29.919742584228516\n",
      "epoch: 1, iter: 46000, loss: 30.570688247680664\n",
      "epoch: 1, iter: 46100, loss: 30.857337951660156\n",
      "epoch: 1, iter: 46200, loss: 30.517024993896484\n",
      "epoch: 1, iter: 46300, loss: 31.09164810180664\n",
      "epoch: 1, iter: 46400, loss: 30.703323364257812\n",
      "epoch: 1, iter: 46500, loss: 30.29987907409668\n",
      "epoch: 1, iter: 46600, loss: 30.740859985351562\n",
      "epoch: 1, iter: 46700, loss: 30.184553146362305\n",
      "epoch: 1, iter: 46800, loss: 30.483491897583008\n",
      "epoch: 1, iter: 46900, loss: 30.226741790771484\n",
      "epoch: 1, iter: 47000, loss: 30.586692810058594\n",
      "epoch: 1, iter: 47100, loss: 30.430950164794922\n",
      "epoch: 1, iter: 47200, loss: 30.62150001525879\n",
      "epoch: 1, iter: 47300, loss: 30.379398345947266\n",
      "epoch: 1, iter: 47400, loss: 30.399940490722656\n",
      "epoch: 1, iter: 47500, loss: 30.06713104248047\n",
      "epoch: 1, iter: 47600, loss: 30.37035369873047\n",
      "epoch: 1, iter: 47700, loss: 30.453266143798828\n",
      "epoch: 1, iter: 47800, loss: 30.016239166259766\n",
      "epoch: 1, iter: 47900, loss: 30.51116943359375\n",
      "epoch: 1, iter: 48000, loss: 30.34925651550293\n",
      "epoch: 1, iter: 48100, loss: 30.16802978515625\n",
      "epoch: 1, iter: 48200, loss: 30.546751022338867\n",
      "epoch: 1, iter: 48300, loss: 30.845993041992188\n",
      "epoch: 1, iter: 48400, loss: 30.66857147216797\n",
      "epoch: 1, iter: 48500, loss: 30.31498146057129\n",
      "epoch: 1, iter: 48600, loss: 30.277156829833984\n",
      "epoch: 1, iter: 48700, loss: 30.659896850585938\n",
      "epoch: 1, iter: 48800, loss: 30.39663314819336\n",
      "epoch: 1, iter: 48900, loss: 29.994380950927734\n",
      "epoch: 1, iter: 49000, loss: 30.440895080566406\n",
      "epoch: 1, iter: 49100, loss: 30.592939376831055\n",
      "epoch: 1, iter: 49200, loss: 30.38857650756836\n",
      "epoch: 1, iter: 49300, loss: 30.766071319580078\n",
      "epoch: 1, iter: 49400, loss: 30.5540771484375\n",
      "epoch: 1, iter: 49500, loss: 30.12232208251953\n",
      "epoch: 1, iter: 49600, loss: 30.188823699951172\n",
      "epoch: 1, iter: 49700, loss: 30.215091705322266\n",
      "epoch: 1, iter: 49800, loss: 29.968233108520508\n",
      "epoch: 1, iter: 49900, loss: 30.395769119262695\n",
      "epoch: 1, iter: 50000, loss: 30.209590911865234\n",
      "epoch: 1, iter: 50100, loss: 30.12603187561035\n",
      "epoch: 1, iter: 50200, loss: 30.60074234008789\n",
      "epoch: 1, iter: 50300, loss: 30.120281219482422\n",
      "epoch: 1, iter: 50400, loss: 30.830970764160156\n",
      "epoch: 1, iter: 50500, loss: 30.79220199584961\n",
      "epoch: 1, iter: 50600, loss: 30.29473114013672\n",
      "epoch: 1, iter: 50700, loss: 30.431468963623047\n",
      "epoch: 1, iter: 50800, loss: 30.489946365356445\n",
      "epoch: 1, iter: 50900, loss: 30.104167938232422\n",
      "epoch: 1, iter: 51000, loss: 30.648094177246094\n",
      "epoch: 1, iter: 51100, loss: 30.348785400390625\n",
      "epoch: 1, iter: 51200, loss: 30.42391586303711\n",
      "epoch: 1, iter: 51300, loss: 30.017990112304688\n",
      "epoch: 1, iter: 51400, loss: 30.511844635009766\n",
      "epoch: 1, iter: 51500, loss: 30.405412673950195\n",
      "epoch: 1, iter: 51600, loss: 30.21644401550293\n",
      "epoch: 1, iter: 51700, loss: 30.217966079711914\n",
      "epoch: 1, iter: 51800, loss: 29.97515869140625\n",
      "epoch: 1, iter: 51900, loss: 30.135143280029297\n",
      "epoch: 1, iter: 52000, loss: 30.754287719726562\n",
      "epoch: 1, iter: 52100, loss: 30.32957649230957\n",
      "epoch: 1, iter: 52200, loss: 30.30259132385254\n",
      "epoch: 1, iter: 52300, loss: 30.639665603637695\n",
      "epoch: 1, iter: 52400, loss: 30.345426559448242\n",
      "epoch: 1, iter: 52500, loss: 30.079452514648438\n",
      "epoch: 1, iter: 52600, loss: 30.16004180908203\n",
      "epoch: 1, iter: 52700, loss: 30.13892364501953\n",
      "epoch: 1, iter: 52800, loss: 30.47982406616211\n",
      "epoch: 1, iter: 52900, loss: 30.206497192382812\n",
      "epoch: 1, iter: 53000, loss: 29.924617767333984\n",
      "epoch: 1, iter: 53100, loss: 30.546581268310547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, iter: 53200, loss: 30.619110107421875\n",
      "epoch: 1, iter: 53300, loss: 30.695589065551758\n",
      "epoch: 1, iter: 53400, loss: 30.62221908569336\n",
      "epoch: 1, iter: 53500, loss: 30.03057861328125\n",
      "epoch: 1, iter: 53600, loss: 30.39617156982422\n",
      "epoch: 1, iter: 53700, loss: 30.148765563964844\n",
      "epoch: 1, iter: 53800, loss: 30.24462127685547\n",
      "epoch: 1, iter: 53900, loss: 30.461177825927734\n",
      "epoch: 1, iter: 54000, loss: 30.368053436279297\n",
      "epoch: 1, iter: 54100, loss: 30.626056671142578\n",
      "epoch: 1, iter: 54200, loss: 30.74512481689453\n",
      "epoch: 1, iter: 54300, loss: 30.458711624145508\n",
      "epoch: 1, iter: 54400, loss: 29.78676414489746\n",
      "epoch: 1, iter: 54500, loss: 30.59987449645996\n",
      "epoch: 1, iter: 54600, loss: 30.543113708496094\n",
      "epoch: 1, iter: 54700, loss: 30.33462905883789\n",
      "epoch: 1, iter: 54800, loss: 30.524120330810547\n",
      "epoch: 1, iter: 54900, loss: 30.575603485107422\n",
      "epoch: 1, iter: 55000, loss: 30.370426177978516\n",
      "epoch: 1, iter: 55100, loss: 30.73145294189453\n",
      "epoch: 1, iter: 55200, loss: 30.255538940429688\n",
      "epoch: 1, iter: 55300, loss: 30.428817749023438\n",
      "epoch: 1, iter: 55400, loss: 30.22988510131836\n",
      "epoch: 1, iter: 55500, loss: 30.502872467041016\n",
      "epoch: 1, iter: 55600, loss: 30.08055305480957\n",
      "epoch: 1, iter: 55700, loss: 30.302066802978516\n",
      "epoch: 1, iter: 55800, loss: 30.339754104614258\n",
      "epoch: 1, iter: 55900, loss: 29.600872039794922\n",
      "epoch: 1, iter: 56000, loss: 30.24374008178711\n",
      "epoch: 1, iter: 56100, loss: 30.11583709716797\n",
      "epoch: 1, iter: 56200, loss: 30.621238708496094\n",
      "epoch: 1, iter: 56300, loss: 30.37043571472168\n",
      "epoch: 1, iter: 56400, loss: 30.826026916503906\n",
      "epoch: 1, iter: 56500, loss: 30.327388763427734\n",
      "epoch: 1, iter: 56600, loss: 30.757307052612305\n",
      "epoch: 1, iter: 56700, loss: 30.288070678710938\n",
      "epoch: 1, iter: 56800, loss: 30.66473388671875\n",
      "epoch: 1, iter: 56900, loss: 30.30825424194336\n",
      "epoch: 1, iter: 57000, loss: 30.176441192626953\n",
      "epoch: 1, iter: 57100, loss: 30.7973690032959\n",
      "epoch: 1, iter: 57200, loss: 30.631603240966797\n",
      "epoch: 1, iter: 57300, loss: 30.396804809570312\n",
      "epoch: 1, iter: 57400, loss: 30.604751586914062\n",
      "epoch: 1, iter: 57500, loss: 30.072208404541016\n",
      "epoch: 1, iter: 57600, loss: 30.576889038085938\n",
      "epoch: 1, iter: 57700, loss: 29.751842498779297\n",
      "epoch: 1, iter: 57800, loss: 30.23952865600586\n",
      "epoch: 1, iter: 57900, loss: 30.422683715820312\n",
      "epoch: 1, iter: 58000, loss: 30.36802101135254\n",
      "epoch: 1, iter: 58100, loss: 30.25998306274414\n",
      "epoch: 1, iter: 58200, loss: 30.733386993408203\n",
      "epoch: 1, iter: 58300, loss: 30.03611183166504\n",
      "epoch: 1, iter: 58400, loss: 30.051931381225586\n",
      "epoch: 1, iter: 58500, loss: 30.255859375\n",
      "epoch: 1, iter: 58600, loss: 30.349075317382812\n",
      "epoch: 1, iter: 58700, loss: 30.490022659301758\n",
      "epoch: 1, iter: 58800, loss: 29.895767211914062\n",
      "epoch: 1, iter: 58900, loss: 30.343841552734375\n",
      "epoch: 1, iter: 59000, loss: 29.878780364990234\n",
      "epoch: 1, iter: 59100, loss: 30.06745147705078\n",
      "epoch: 1, iter: 59200, loss: 30.575366973876953\n",
      "epoch: 1, iter: 59300, loss: 30.557769775390625\n",
      "epoch: 1, iter: 59400, loss: 30.41614532470703\n",
      "epoch: 1, iter: 59500, loss: 30.298063278198242\n",
      "epoch: 1, iter: 59600, loss: 30.048051834106445\n",
      "epoch: 1, iter: 59700, loss: 29.51980209350586\n",
      "epoch: 1, iter: 59800, loss: 30.701759338378906\n",
      "epoch: 1, iter: 59900, loss: 30.59857177734375\n",
      "epoch: 1, iter: 60000, loss: 30.406383514404297\n",
      "epoch: 1, iter: 60100, loss: 30.360877990722656\n",
      "epoch: 1, iter: 60200, loss: 30.02536392211914\n",
      "epoch: 1, iter: 60300, loss: 31.065441131591797\n",
      "epoch: 1, iter: 60400, loss: 30.21371078491211\n",
      "epoch: 1, iter: 60500, loss: 30.09156036376953\n",
      "epoch: 1, iter: 60600, loss: 30.622190475463867\n",
      "epoch: 1, iter: 60700, loss: 30.287872314453125\n",
      "epoch: 1, iter: 60800, loss: 29.89988136291504\n",
      "epoch: 1, iter: 60900, loss: 30.170978546142578\n",
      "epoch: 1, iter: 61000, loss: 30.213167190551758\n",
      "epoch: 1, iter: 61100, loss: 30.696163177490234\n",
      "epoch: 1, iter: 61200, loss: 30.213130950927734\n",
      "epoch: 1, iter: 61300, loss: 30.619121551513672\n",
      "epoch: 1, iter: 61400, loss: 30.844022750854492\n",
      "epoch: 1, iter: 61500, loss: 30.927425384521484\n",
      "epoch: 1, iter: 61600, loss: 30.72637367248535\n",
      "epoch: 1, iter: 61700, loss: 30.747426986694336\n",
      "epoch: 1, iter: 61800, loss: 30.471406936645508\n",
      "epoch: 1, iter: 61900, loss: 30.636348724365234\n",
      "epoch: 1, iter: 62000, loss: 30.072975158691406\n",
      "epoch: 1, iter: 62100, loss: 30.782869338989258\n",
      "epoch: 1, iter: 62200, loss: 30.029664993286133\n",
      "epoch: 1, iter: 62300, loss: 30.51092529296875\n",
      "epoch: 1, iter: 62400, loss: 30.311748504638672\n",
      "epoch: 1, iter: 62500, loss: 30.518484115600586\n",
      "epoch: 1, iter: 62600, loss: 30.65242576599121\n",
      "epoch: 1, iter: 62700, loss: 30.485313415527344\n",
      "epoch: 1, iter: 62800, loss: 30.229999542236328\n",
      "epoch: 1, iter: 62900, loss: 29.936382293701172\n",
      "epoch: 1, iter: 63000, loss: 30.02027702331543\n",
      "epoch: 1, iter: 63100, loss: 30.017343521118164\n",
      "epoch: 1, iter: 63200, loss: 30.61794090270996\n",
      "epoch: 1, iter: 63300, loss: 29.971817016601562\n",
      "epoch: 1, iter: 63400, loss: 30.833267211914062\n",
      "epoch: 1, iter: 63500, loss: 30.054908752441406\n",
      "epoch: 1, iter: 63600, loss: 29.924406051635742\n",
      "epoch: 1, iter: 63700, loss: 30.57235336303711\n",
      "epoch: 1, iter: 63800, loss: 30.430988311767578\n",
      "epoch: 1, iter: 63900, loss: 30.316932678222656\n",
      "epoch: 1, iter: 64000, loss: 30.620389938354492\n",
      "epoch: 1, iter: 64100, loss: 30.13488006591797\n",
      "epoch: 1, iter: 64200, loss: 29.872180938720703\n",
      "epoch: 1, iter: 64300, loss: 30.79427719116211\n",
      "epoch: 1, iter: 64400, loss: 30.37900733947754\n",
      "epoch: 1, iter: 64500, loss: 30.660730361938477\n",
      "epoch: 1, iter: 64600, loss: 30.501157760620117\n",
      "epoch: 1, iter: 64700, loss: 30.775814056396484\n",
      "epoch: 1, iter: 64800, loss: 30.48233413696289\n",
      "epoch: 1, iter: 64900, loss: 30.054603576660156\n",
      "epoch: 1, iter: 65000, loss: 29.740375518798828\n",
      "epoch: 1, iter: 65100, loss: 30.477035522460938\n",
      "epoch: 1, iter: 65200, loss: 29.91646385192871\n",
      "epoch: 1, iter: 65300, loss: 30.423057556152344\n",
      "epoch: 1, iter: 65400, loss: 30.477693557739258\n",
      "epoch: 1, iter: 65500, loss: 30.30628204345703\n",
      "epoch: 1, iter: 65600, loss: 30.201324462890625\n",
      "epoch: 1, iter: 65700, loss: 30.767969131469727\n",
      "epoch: 1, iter: 65800, loss: 30.409069061279297\n",
      "epoch: 1, iter: 65900, loss: 30.265090942382812\n",
      "epoch: 1, iter: 66000, loss: 30.127723693847656\n",
      "epoch: 1, iter: 66100, loss: 30.606708526611328\n",
      "epoch: 1, iter: 66200, loss: 30.471176147460938\n",
      "epoch: 1, iter: 66300, loss: 30.613712310791016\n",
      "epoch: 1, iter: 66400, loss: 29.98552131652832\n",
      "epoch: 1, iter: 66500, loss: 30.32158851623535\n",
      "epoch: 1, iter: 66600, loss: 30.453197479248047\n",
      "epoch: 1, iter: 66700, loss: 29.90326499938965\n",
      "epoch: 1, iter: 66800, loss: 30.394325256347656\n",
      "epoch: 1, iter: 66900, loss: 30.78533935546875\n",
      "epoch: 1, iter: 67000, loss: 30.571752548217773\n",
      "epoch: 1, iter: 67100, loss: 30.212188720703125\n",
      "epoch: 1, iter: 67200, loss: 30.85505485534668\n",
      "epoch: 1, iter: 67300, loss: 30.1098575592041\n",
      "epoch: 1, iter: 67400, loss: 30.522518157958984\n",
      "epoch: 1, iter: 67500, loss: 30.089340209960938\n",
      "epoch: 1, iter: 67600, loss: 30.84244155883789\n",
      "epoch: 1, iter: 67700, loss: 30.80004119873047\n",
      "epoch: 1, iter: 67800, loss: 30.64930534362793\n",
      "epoch: 1, iter: 67900, loss: 30.291921615600586\n",
      "epoch: 1, iter: 68000, loss: 30.423831939697266\n",
      "epoch: 1, iter: 68100, loss: 30.560779571533203\n",
      "epoch: 1, iter: 68200, loss: 30.638477325439453\n",
      "epoch: 1, iter: 68300, loss: 30.694150924682617\n",
      "epoch: 1, iter: 68400, loss: 30.03447723388672\n",
      "epoch: 1, iter: 68500, loss: 30.392335891723633\n",
      "epoch: 1, iter: 68600, loss: 30.001930236816406\n",
      "epoch: 1, iter: 68700, loss: 30.011764526367188\n",
      "epoch: 1, iter: 68800, loss: 30.828174591064453\n",
      "epoch: 1, iter: 68900, loss: 30.107025146484375\n",
      "epoch: 1, iter: 69000, loss: 30.551959991455078\n",
      "epoch: 1, iter: 69100, loss: 30.692428588867188\n",
      "epoch: 1, iter: 69200, loss: 30.402936935424805\n",
      "epoch: 1, iter: 69300, loss: 30.523664474487305\n",
      "epoch: 1, iter: 69400, loss: 30.493492126464844\n",
      "epoch: 1, iter: 69500, loss: 30.627094268798828\n",
      "epoch: 1, iter: 69600, loss: 30.150224685668945\n",
      "epoch: 1, iter: 69700, loss: 30.477584838867188\n",
      "epoch: 1, iter: 69800, loss: 30.546428680419922\n",
      "epoch: 1, iter: 69900, loss: 30.831485748291016\n",
      "epoch: 1, iter: 70000, loss: 30.604358673095703\n",
      "epoch: 1, iter: 70100, loss: 30.015853881835938\n",
      "epoch: 1, iter: 70200, loss: 30.155261993408203\n",
      "epoch: 1, iter: 70300, loss: 30.271242141723633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, iter: 70400, loss: 30.96818733215332\n",
      "epoch: 1, iter: 70500, loss: 30.504425048828125\n",
      "epoch: 1, iter: 70600, loss: 30.785526275634766\n",
      "epoch: 1, iter: 70700, loss: 30.771575927734375\n",
      "epoch: 1, iter: 70800, loss: 30.684459686279297\n",
      "epoch: 1, iter: 70900, loss: 30.338008880615234\n",
      "epoch: 1, iter: 71000, loss: 30.76706886291504\n",
      "epoch: 1, iter: 71100, loss: 30.35271453857422\n",
      "epoch: 1, iter: 71200, loss: 29.788108825683594\n",
      "epoch: 1, iter: 71300, loss: 30.233728408813477\n",
      "epoch: 1, iter: 71400, loss: 30.482433319091797\n",
      "epoch: 1, iter: 71500, loss: 30.675006866455078\n",
      "epoch: 1, iter: 71600, loss: 30.30660057067871\n",
      "epoch: 1, iter: 71700, loss: 30.658329010009766\n",
      "epoch: 1, iter: 71800, loss: 29.85631561279297\n",
      "epoch: 1, iter: 71900, loss: 30.80324935913086\n",
      "epoch: 1, iter: 72000, loss: 30.16228675842285\n",
      "epoch: 1, iter: 72100, loss: 30.215011596679688\n",
      "epoch: 1, iter: 72200, loss: 30.666141510009766\n",
      "epoch: 1, iter: 72300, loss: 30.553688049316406\n",
      "epoch: 1, iter: 72400, loss: 30.20686912536621\n",
      "epoch: 1, iter: 72500, loss: 30.288558959960938\n",
      "epoch: 1, iter: 72600, loss: 30.18096923828125\n",
      "epoch: 1, iter: 72700, loss: 30.64044761657715\n",
      "epoch: 1, iter: 72800, loss: 30.473434448242188\n",
      "epoch: 1, iter: 72900, loss: 29.88823699951172\n",
      "epoch: 1, iter: 73000, loss: 30.25019645690918\n",
      "epoch: 1, iter: 73100, loss: 29.863170623779297\n",
      "epoch: 1, iter: 73200, loss: 30.166748046875\n",
      "epoch: 1, iter: 73300, loss: 30.725994110107422\n",
      "epoch: 1, iter: 73400, loss: 30.02410125732422\n",
      "epoch: 1, iter: 73500, loss: 30.185930252075195\n",
      "epoch: 1, iter: 73600, loss: 30.254220962524414\n",
      "epoch: 1, iter: 73700, loss: 30.17119026184082\n",
      "epoch: 1, iter: 73800, loss: 30.473569869995117\n",
      "epoch: 1, iter: 73900, loss: 30.69680404663086\n",
      "epoch: 1, iter: 74000, loss: 30.557207107543945\n",
      "epoch: 1, iter: 74100, loss: 30.059045791625977\n",
      "epoch: 1, iter: 74200, loss: 30.404443740844727\n",
      "epoch: 1, iter: 74300, loss: 30.293209075927734\n",
      "epoch: 1, iter: 74400, loss: 31.04666519165039\n",
      "epoch: 1, iter: 74500, loss: 30.537853240966797\n",
      "epoch: 1, iter: 74600, loss: 30.14253044128418\n",
      "epoch: 1, iter: 74700, loss: 30.385608673095703\n",
      "epoch: 1, iter: 74800, loss: 30.261737823486328\n",
      "epoch: 1, iter: 74900, loss: 30.596092224121094\n",
      "epoch: 1, iter: 75000, loss: 29.99132537841797\n",
      "epoch: 1, iter: 75100, loss: 30.885414123535156\n",
      "epoch: 1, iter: 75200, loss: 30.418027877807617\n",
      "epoch: 1, iter: 75300, loss: 30.440265655517578\n",
      "epoch: 1, iter: 75400, loss: 30.416439056396484\n",
      "epoch: 1, iter: 75500, loss: 30.335128784179688\n",
      "epoch: 1, iter: 75600, loss: 30.54311752319336\n",
      "epoch: 1, iter: 75700, loss: 31.165184020996094\n",
      "epoch: 1, iter: 75800, loss: 30.365535736083984\n",
      "epoch: 1, iter: 75900, loss: 30.21904754638672\n",
      "epoch: 1, iter: 76000, loss: 30.563140869140625\n",
      "epoch: 1, iter: 76100, loss: 30.618183135986328\n",
      "epoch: 1, iter: 76200, loss: 30.21186065673828\n",
      "epoch: 1, iter: 76300, loss: 30.3516845703125\n",
      "epoch: 1, iter: 76400, loss: 30.484100341796875\n",
      "epoch: 1, iter: 76500, loss: 30.766510009765625\n",
      "epoch: 1, iter: 76600, loss: 30.56455421447754\n",
      "epoch: 1, iter: 76700, loss: 30.44977569580078\n",
      "epoch: 1, iter: 76800, loss: 30.277992248535156\n",
      "epoch: 1, iter: 76900, loss: 30.614948272705078\n",
      "epoch: 1, iter: 77000, loss: 30.41794204711914\n",
      "epoch: 1, iter: 77100, loss: 30.25243377685547\n",
      "epoch: 1, iter: 77200, loss: 29.74472427368164\n",
      "epoch: 1, iter: 77300, loss: 30.376310348510742\n",
      "epoch: 1, iter: 77400, loss: 30.428274154663086\n",
      "epoch: 1, iter: 77500, loss: 30.163471221923828\n",
      "epoch: 1, iter: 77600, loss: 30.531705856323242\n",
      "epoch: 1, iter: 77700, loss: 30.867721557617188\n",
      "epoch: 1, iter: 77800, loss: 30.33768653869629\n",
      "epoch: 1, iter: 77900, loss: 31.057348251342773\n",
      "epoch: 1, iter: 78000, loss: 30.687105178833008\n",
      "epoch: 1, iter: 78100, loss: 30.697765350341797\n",
      "epoch: 1, iter: 78200, loss: 30.09571647644043\n",
      "epoch: 1, iter: 78300, loss: 30.085580825805664\n",
      "epoch: 1, iter: 78400, loss: 30.9189453125\n",
      "epoch: 1, iter: 78500, loss: 30.134489059448242\n",
      "epoch: 1, iter: 78600, loss: 30.495742797851562\n",
      "epoch: 1, iter: 78700, loss: 30.67190170288086\n",
      "epoch: 1, iter: 78800, loss: 31.026447296142578\n",
      "epoch: 1, iter: 78900, loss: 30.24030113220215\n",
      "epoch: 1, iter: 79000, loss: 29.979076385498047\n",
      "epoch: 1, iter: 79100, loss: 30.784435272216797\n",
      "epoch: 1, iter: 79200, loss: 30.663742065429688\n",
      "epoch: 1, iter: 79300, loss: 30.054664611816406\n",
      "epoch: 1, iter: 79400, loss: 30.544418334960938\n",
      "epoch: 1, iter: 79500, loss: 29.99365234375\n",
      "epoch: 1, iter: 79600, loss: 30.38893699645996\n",
      "epoch: 1, iter: 79700, loss: 30.548925399780273\n",
      "epoch: 1, iter: 79800, loss: 30.720918655395508\n",
      "epoch: 1, iter: 79900, loss: 30.381385803222656\n",
      "epoch: 1, iter: 80000, loss: 30.595354080200195\n",
      "epoch: 1, iter: 80100, loss: 30.71897315979004\n",
      "epoch: 1, iter: 80200, loss: 30.317108154296875\n",
      "epoch: 1, iter: 80300, loss: 29.789274215698242\n",
      "epoch: 1, iter: 80400, loss: 30.720569610595703\n",
      "epoch: 1, iter: 80500, loss: 30.358280181884766\n",
      "epoch: 1, iter: 80600, loss: 30.824844360351562\n",
      "epoch: 1, iter: 80700, loss: 30.128623962402344\n",
      "epoch: 1, iter: 80800, loss: 30.72553825378418\n",
      "epoch: 1, iter: 80900, loss: 30.288164138793945\n",
      "epoch: 1, iter: 81000, loss: 30.95085906982422\n",
      "epoch: 1, iter: 81100, loss: 30.63821029663086\n",
      "epoch: 1, iter: 81200, loss: 30.50347900390625\n",
      "epoch: 1, iter: 81300, loss: 30.411775588989258\n",
      "epoch: 1, iter: 81400, loss: 30.30382537841797\n",
      "epoch: 1, iter: 81500, loss: 29.94291877746582\n",
      "epoch: 1, iter: 81600, loss: 30.41714859008789\n",
      "epoch: 1, iter: 81700, loss: 30.399728775024414\n",
      "epoch: 1, iter: 81800, loss: 30.490629196166992\n",
      "epoch: 1, iter: 81900, loss: 30.412330627441406\n",
      "epoch: 1, iter: 82000, loss: 30.275249481201172\n",
      "epoch: 1, iter: 82100, loss: 30.205364227294922\n",
      "epoch: 1, iter: 82200, loss: 30.4394474029541\n",
      "epoch: 1, iter: 82300, loss: 31.011600494384766\n",
      "epoch: 1, iter: 82400, loss: 30.382787704467773\n",
      "epoch: 1, iter: 82500, loss: 29.64706039428711\n",
      "epoch: 1, iter: 82600, loss: 30.58237075805664\n",
      "epoch: 1, iter: 82700, loss: 30.498210906982422\n",
      "epoch: 1, iter: 82800, loss: 30.6154842376709\n",
      "epoch: 1, iter: 82900, loss: 30.543020248413086\n",
      "epoch: 1, iter: 83000, loss: 30.390304565429688\n",
      "epoch: 1, iter: 83100, loss: 30.12454605102539\n",
      "epoch: 1, iter: 83200, loss: 30.450273513793945\n",
      "epoch: 1, iter: 83300, loss: 30.081462860107422\n",
      "epoch: 1, iter: 83400, loss: 30.793701171875\n",
      "epoch: 1, iter: 83500, loss: 30.26671600341797\n",
      "epoch: 1, iter: 83600, loss: 30.383638381958008\n",
      "epoch: 1, iter: 83700, loss: 30.6439208984375\n",
      "epoch: 1, iter: 83800, loss: 30.86395263671875\n",
      "epoch: 1, iter: 83900, loss: 30.488706588745117\n",
      "epoch: 1, iter: 84000, loss: 30.212804794311523\n",
      "epoch: 1, iter: 84100, loss: 30.66278648376465\n",
      "epoch: 1, iter: 84200, loss: 30.51062774658203\n",
      "epoch: 1, iter: 84300, loss: 30.12716293334961\n",
      "epoch: 1, iter: 84400, loss: 30.677043914794922\n",
      "epoch: 1, iter: 84500, loss: 30.323936462402344\n",
      "epoch: 1, iter: 84600, loss: 30.323476791381836\n",
      "epoch: 1, iter: 84700, loss: 30.475780487060547\n",
      "epoch: 1, iter: 84800, loss: 30.571584701538086\n",
      "epoch: 1, iter: 84900, loss: 30.09720230102539\n",
      "epoch: 1, iter: 85000, loss: 30.480140686035156\n",
      "epoch: 1, iter: 85100, loss: 30.699230194091797\n",
      "epoch: 1, iter: 85200, loss: 30.004032135009766\n",
      "epoch: 1, iter: 85300, loss: 30.038061141967773\n",
      "epoch: 1, iter: 85400, loss: 30.491418838500977\n",
      "epoch: 1, iter: 85500, loss: 30.528207778930664\n",
      "epoch: 1, iter: 85600, loss: 30.81427574157715\n",
      "epoch: 1, iter: 85700, loss: 30.261869430541992\n",
      "epoch: 1, iter: 85800, loss: 30.520851135253906\n",
      "epoch: 1, iter: 85900, loss: 30.493820190429688\n",
      "epoch: 1, iter: 86000, loss: 30.442163467407227\n",
      "epoch: 1, iter: 86100, loss: 30.215885162353516\n",
      "epoch: 1, iter: 86200, loss: 30.147193908691406\n",
      "epoch: 1, iter: 86300, loss: 30.58879280090332\n",
      "epoch: 1, iter: 86400, loss: 30.201282501220703\n",
      "epoch: 1, iter: 86500, loss: 30.25585174560547\n",
      "epoch: 1, iter: 86600, loss: 30.385948181152344\n",
      "epoch: 1, iter: 86700, loss: 30.921295166015625\n",
      "epoch: 1, iter: 86800, loss: 30.23479652404785\n",
      "epoch: 1, iter: 86900, loss: 30.109973907470703\n",
      "epoch: 1, iter: 87000, loss: 30.305240631103516\n",
      "epoch: 1, iter: 87100, loss: 29.782211303710938\n",
      "epoch: 1, iter: 87200, loss: 30.46324920654297\n",
      "epoch: 1, iter: 87300, loss: 30.0627384185791\n",
      "epoch: 1, iter: 87400, loss: 30.20705795288086\n",
      "epoch: 1, iter: 87500, loss: 30.809871673583984\n",
      "epoch: 1, iter: 87600, loss: 30.254135131835938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, iter: 87700, loss: 30.229537963867188\n",
      "epoch: 1, iter: 87800, loss: 30.521480560302734\n",
      "epoch: 1, iter: 87900, loss: 29.76840591430664\n",
      "epoch: 1, iter: 88000, loss: 30.632104873657227\n",
      "epoch: 1, iter: 88100, loss: 30.671722412109375\n",
      "epoch: 1, iter: 88200, loss: 30.387523651123047\n",
      "epoch: 1, iter: 88300, loss: 30.784847259521484\n",
      "epoch: 1, iter: 88400, loss: 30.54539680480957\n",
      "epoch: 1, iter: 88500, loss: 30.189746856689453\n",
      "epoch: 1, iter: 88600, loss: 30.59088897705078\n",
      "epoch: 1, iter: 88700, loss: 29.246814727783203\n",
      "epoch: 1, iter: 88800, loss: 30.34463119506836\n",
      "epoch: 1, iter: 88900, loss: 30.282146453857422\n",
      "epoch: 1, iter: 89000, loss: 30.648700714111328\n",
      "epoch: 1, iter: 89100, loss: 29.976829528808594\n",
      "epoch: 1, iter: 89200, loss: 30.621397018432617\n",
      "epoch: 1, iter: 89300, loss: 30.41439437866211\n",
      "epoch: 1, iter: 89400, loss: 30.325531005859375\n",
      "epoch: 1, iter: 89500, loss: 30.507482528686523\n",
      "epoch: 1, iter: 89600, loss: 30.216299057006836\n",
      "epoch: 1, iter: 89700, loss: 30.315385818481445\n",
      "epoch: 1, iter: 89800, loss: 30.097015380859375\n",
      "epoch: 1, iter: 89900, loss: 30.283824920654297\n",
      "epoch: 1, iter: 90000, loss: 30.476903915405273\n",
      "epoch: 1, iter: 90100, loss: 29.94590950012207\n",
      "epoch: 1, iter: 90200, loss: 30.447214126586914\n",
      "epoch: 1, iter: 90300, loss: 30.473705291748047\n",
      "epoch: 1, iter: 90400, loss: 30.01671600341797\n",
      "epoch: 1, iter: 90500, loss: 30.73041343688965\n",
      "epoch: 1, iter: 90600, loss: 30.212846755981445\n",
      "epoch: 1, iter: 90700, loss: 30.350200653076172\n",
      "epoch: 1, iter: 90800, loss: 30.874622344970703\n",
      "epoch: 1, iter: 90900, loss: 30.90667724609375\n",
      "epoch: 1, iter: 91000, loss: 30.046588897705078\n",
      "epoch: 1, iter: 91100, loss: 30.42009735107422\n",
      "epoch: 1, iter: 91200, loss: 30.142778396606445\n",
      "epoch: 1, iter: 91300, loss: 30.386520385742188\n",
      "epoch: 1, iter: 91400, loss: 30.63840103149414\n",
      "epoch: 1, iter: 91500, loss: 30.450397491455078\n",
      "epoch: 1, iter: 91600, loss: 30.257083892822266\n",
      "epoch: 1, iter: 91700, loss: 30.523834228515625\n",
      "epoch: 1, iter: 91800, loss: 30.38585662841797\n",
      "epoch: 1, iter: 91900, loss: 30.398906707763672\n",
      "epoch: 1, iter: 92000, loss: 30.495532989501953\n",
      "epoch: 1, iter: 92100, loss: 30.764480590820312\n",
      "epoch: 1, iter: 92200, loss: 31.174219131469727\n",
      "epoch: 1, iter: 92300, loss: 30.067462921142578\n",
      "epoch: 1, iter: 92400, loss: 30.47202491760254\n",
      "epoch: 1, iter: 92500, loss: 30.729660034179688\n",
      "epoch: 1, iter: 92600, loss: 30.50928497314453\n",
      "epoch: 1, iter: 92700, loss: 30.120441436767578\n",
      "epoch: 1, iter: 92800, loss: 30.651212692260742\n",
      "epoch: 1, iter: 92900, loss: 30.084659576416016\n",
      "epoch: 1, iter: 93000, loss: 30.80708885192871\n",
      "epoch: 1, iter: 93100, loss: 30.155174255371094\n",
      "epoch: 1, iter: 93200, loss: 30.146373748779297\n",
      "epoch: 1, iter: 93300, loss: 30.492340087890625\n",
      "epoch: 1, iter: 93400, loss: 30.961393356323242\n",
      "epoch: 1, iter: 93500, loss: 31.05960464477539\n",
      "epoch: 1, iter: 93600, loss: 30.083404541015625\n",
      "epoch: 1, iter: 93700, loss: 30.568946838378906\n",
      "epoch: 1, iter: 93800, loss: 30.264833450317383\n",
      "epoch: 1, iter: 93900, loss: 30.401939392089844\n",
      "epoch: 1, iter: 94000, loss: 30.180458068847656\n",
      "epoch: 1, iter: 94100, loss: 30.47286605834961\n",
      "epoch: 1, iter: 94200, loss: 30.709009170532227\n",
      "epoch: 1, iter: 94300, loss: 30.436840057373047\n",
      "epoch: 1, iter: 94400, loss: 30.57064437866211\n",
      "epoch: 1, iter: 94500, loss: 30.41219711303711\n",
      "epoch: 1, iter: 94600, loss: 30.61756134033203\n",
      "epoch: 1, iter: 94700, loss: 30.14129066467285\n",
      "epoch: 1, iter: 94800, loss: 30.433563232421875\n",
      "epoch: 1, iter: 94900, loss: 30.318397521972656\n",
      "epoch: 1, iter: 95000, loss: 29.81243324279785\n",
      "epoch: 1, iter: 95100, loss: 30.05388832092285\n",
      "epoch: 1, iter: 95200, loss: 30.816423416137695\n",
      "epoch: 1, iter: 95300, loss: 30.437177658081055\n",
      "epoch: 1, iter: 95400, loss: 29.961917877197266\n",
      "epoch: 1, iter: 95500, loss: 30.09284782409668\n",
      "epoch: 1, iter: 95600, loss: 30.18915557861328\n",
      "epoch: 1, iter: 95700, loss: 30.89215850830078\n",
      "epoch: 1, iter: 95800, loss: 30.075687408447266\n",
      "epoch: 1, iter: 95900, loss: 30.321868896484375\n",
      "epoch: 1, iter: 96000, loss: 30.436111450195312\n",
      "epoch: 1, iter: 96100, loss: 29.969547271728516\n",
      "epoch: 1, iter: 96200, loss: 30.254974365234375\n",
      "epoch: 1, iter: 96300, loss: 30.351795196533203\n",
      "epoch: 1, iter: 96400, loss: 30.72763442993164\n",
      "epoch: 1, iter: 96500, loss: 30.073829650878906\n",
      "epoch: 1, iter: 96600, loss: 30.39920425415039\n",
      "epoch: 1, iter: 96700, loss: 30.678916931152344\n",
      "epoch: 1, iter: 96800, loss: 30.285789489746094\n",
      "epoch: 1, iter: 96900, loss: 30.270381927490234\n",
      "epoch: 1, iter: 97000, loss: 30.68354034423828\n",
      "epoch: 1, iter: 97100, loss: 30.485258102416992\n",
      "epoch: 1, iter: 97200, loss: 30.11686134338379\n",
      "epoch: 1, iter: 97300, loss: 30.644187927246094\n",
      "epoch: 1, iter: 97400, loss: 30.664400100708008\n",
      "epoch: 1, iter: 97500, loss: 30.338041305541992\n",
      "epoch: 1, iter: 97600, loss: 30.422292709350586\n",
      "epoch: 1, iter: 97700, loss: 30.754013061523438\n",
      "epoch: 1, iter: 97800, loss: 30.10204315185547\n",
      "epoch: 1, iter: 97900, loss: 30.366539001464844\n",
      "epoch: 1, iter: 98000, loss: 30.20590591430664\n",
      "epoch: 1, iter: 98100, loss: 30.843257904052734\n",
      "epoch: 1, iter: 98200, loss: 30.321510314941406\n",
      "epoch: 1, iter: 98300, loss: 30.418893814086914\n",
      "epoch: 1, iter: 98400, loss: 30.455001831054688\n",
      "epoch: 1, iter: 98500, loss: 29.71235466003418\n",
      "epoch: 1, iter: 98600, loss: 30.093402862548828\n",
      "epoch: 1, iter: 98700, loss: 30.79747772216797\n",
      "epoch: 1, iter: 98800, loss: 30.443763732910156\n",
      "epoch: 1, iter: 98900, loss: 30.298097610473633\n",
      "epoch: 1, iter: 99000, loss: 30.284221649169922\n",
      "epoch: 1, iter: 99100, loss: 30.528270721435547\n",
      "epoch: 1, iter: 99200, loss: 30.697399139404297\n",
      "epoch: 1, iter: 99300, loss: 30.293010711669922\n",
      "epoch: 1, iter: 99400, loss: 30.4996395111084\n",
      "epoch: 1, iter: 99500, loss: 30.236623764038086\n",
      "epoch: 1, iter: 99600, loss: 30.239166259765625\n",
      "epoch: 1, iter: 99700, loss: 30.58979034423828\n",
      "epoch: 1, iter: 99800, loss: 30.824676513671875\n",
      "epoch: 1, iter: 99900, loss: 30.61844825744629\n",
      "epoch: 1, iter: 100000, loss: 30.29178237915039\n",
      "epoch: 1, iter: 100100, loss: 29.88930892944336\n",
      "epoch: 1, iter: 100200, loss: 30.002145767211914\n",
      "epoch: 1, iter: 100300, loss: 30.435691833496094\n",
      "epoch: 1, iter: 100400, loss: 30.521583557128906\n",
      "epoch: 1, iter: 100500, loss: 30.097061157226562\n",
      "epoch: 1, iter: 100600, loss: 30.56513023376465\n",
      "epoch: 1, iter: 100700, loss: 30.031604766845703\n",
      "epoch: 1, iter: 100800, loss: 30.384531021118164\n",
      "epoch: 1, iter: 100900, loss: 30.20012664794922\n",
      "epoch: 1, iter: 101000, loss: 30.219533920288086\n",
      "epoch: 1, iter: 101100, loss: 30.647844314575195\n",
      "epoch: 1, iter: 101200, loss: 30.448135375976562\n",
      "epoch: 1, iter: 101300, loss: 30.470500946044922\n",
      "epoch: 1, iter: 101400, loss: 29.993839263916016\n",
      "epoch: 1, iter: 101500, loss: 30.0854549407959\n",
      "epoch: 1, iter: 101600, loss: 30.294275283813477\n",
      "epoch: 1, iter: 101700, loss: 30.052858352661133\n",
      "epoch: 1, iter: 101800, loss: 30.796279907226562\n",
      "epoch: 1, iter: 101900, loss: 30.53958511352539\n",
      "epoch: 1, iter: 102000, loss: 30.630123138427734\n",
      "epoch: 1, iter: 102100, loss: 30.682836532592773\n",
      "epoch: 1, iter: 102200, loss: 29.730995178222656\n",
      "epoch: 1, iter: 102300, loss: 30.382749557495117\n",
      "epoch: 1, iter: 102400, loss: 30.215496063232422\n",
      "epoch: 1, iter: 102500, loss: 30.531749725341797\n",
      "epoch: 1, iter: 102600, loss: 31.043684005737305\n",
      "epoch: 1, iter: 102700, loss: 29.985801696777344\n",
      "epoch: 1, iter: 102800, loss: 30.136932373046875\n",
      "epoch: 1, iter: 102900, loss: 30.292919158935547\n",
      "epoch: 1, iter: 103000, loss: 30.863548278808594\n",
      "epoch: 1, iter: 103100, loss: 30.401748657226562\n",
      "epoch: 1, iter: 103200, loss: 30.450828552246094\n",
      "epoch: 1, iter: 103300, loss: 30.411664962768555\n",
      "epoch: 1, iter: 103400, loss: 30.897216796875\n",
      "epoch: 1, iter: 103500, loss: 30.427873611450195\n",
      "epoch: 1, iter: 103600, loss: 30.487380981445312\n",
      "epoch: 1, iter: 103700, loss: 30.27271270751953\n",
      "epoch: 1, iter: 103800, loss: 30.20075225830078\n",
      "epoch: 1, iter: 103900, loss: 29.80130386352539\n",
      "epoch: 1, iter: 104000, loss: 31.112564086914062\n",
      "epoch: 1, iter: 104100, loss: 30.745281219482422\n",
      "epoch: 1, iter: 104200, loss: 30.295024871826172\n",
      "epoch: 1, iter: 104300, loss: 30.577394485473633\n",
      "epoch: 1, iter: 104400, loss: 30.463895797729492\n",
      "epoch: 1, iter: 104500, loss: 30.232112884521484\n",
      "epoch: 1, iter: 104600, loss: 29.716297149658203\n",
      "epoch: 1, iter: 104700, loss: 30.406368255615234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, iter: 104800, loss: 30.385835647583008\n",
      "epoch: 1, iter: 104900, loss: 30.136550903320312\n",
      "epoch: 1, iter: 105000, loss: 29.920372009277344\n",
      "epoch: 1, iter: 105100, loss: 30.32604217529297\n",
      "epoch: 1, iter: 105200, loss: 30.486291885375977\n",
      "epoch: 1, iter: 105300, loss: 30.22525405883789\n",
      "epoch: 1, iter: 105400, loss: 30.65369415283203\n",
      "epoch: 1, iter: 105500, loss: 30.271739959716797\n",
      "epoch: 1, iter: 105600, loss: 30.71205711364746\n",
      "epoch: 1, iter: 105700, loss: 30.560075759887695\n",
      "epoch: 1, iter: 105800, loss: 30.604328155517578\n",
      "epoch: 1, iter: 105900, loss: 30.546695709228516\n",
      "epoch: 1, iter: 106000, loss: 30.05081558227539\n",
      "epoch: 1, iter: 106100, loss: 30.21908187866211\n",
      "epoch: 1, iter: 106200, loss: 30.654855728149414\n",
      "epoch: 1, iter: 106300, loss: 30.81117057800293\n",
      "epoch: 1, iter: 106400, loss: 30.75257110595703\n",
      "epoch: 1, iter: 106500, loss: 30.158058166503906\n",
      "epoch: 1, iter: 106600, loss: 30.74936294555664\n",
      "epoch: 1, iter: 106700, loss: 30.405668258666992\n",
      "epoch: 1, iter: 106800, loss: 30.338356018066406\n",
      "epoch: 1, iter: 106900, loss: 30.46122169494629\n",
      "epoch: 1, iter: 107000, loss: 29.690387725830078\n",
      "epoch: 1, iter: 107100, loss: 30.371356964111328\n",
      "epoch: 1, iter: 107200, loss: 30.02121353149414\n",
      "epoch: 1, iter: 107300, loss: 30.443504333496094\n",
      "epoch: 1, iter: 107400, loss: 30.57487678527832\n",
      "epoch: 1, iter: 107500, loss: 30.085647583007812\n",
      "epoch: 1, iter: 107600, loss: 29.704914093017578\n",
      "epoch: 1, iter: 107700, loss: 29.9122257232666\n",
      "epoch: 1, iter: 107800, loss: 30.45331573486328\n",
      "epoch: 1, iter: 107900, loss: 30.749374389648438\n",
      "epoch: 1, iter: 108000, loss: 30.747760772705078\n",
      "epoch: 1, iter: 108100, loss: 30.54541778564453\n",
      "epoch: 1, iter: 108200, loss: 30.495006561279297\n",
      "epoch: 1, iter: 108300, loss: 29.831071853637695\n",
      "epoch: 1, iter: 108400, loss: 29.96259307861328\n",
      "epoch: 1, iter: 108500, loss: 30.6137638092041\n",
      "epoch: 1, iter: 108600, loss: 29.999027252197266\n",
      "epoch: 1, iter: 108700, loss: 30.35601806640625\n",
      "epoch: 1, iter: 108800, loss: 30.614337921142578\n",
      "epoch: 1, iter: 108900, loss: 30.217201232910156\n",
      "epoch: 1, iter: 109000, loss: 30.285484313964844\n",
      "epoch: 1, iter: 109100, loss: 30.202625274658203\n",
      "epoch: 1, iter: 109200, loss: 30.525060653686523\n",
      "epoch: 1, iter: 109300, loss: 29.106718063354492\n",
      "epoch: 1, iter: 109400, loss: 30.262989044189453\n",
      "epoch: 1, iter: 109500, loss: 29.804912567138672\n",
      "epoch: 1, iter: 109600, loss: 29.823543548583984\n",
      "epoch: 1, iter: 109700, loss: 30.148094177246094\n",
      "epoch: 1, iter: 109800, loss: 30.545133590698242\n",
      "epoch: 1, iter: 109900, loss: 30.489261627197266\n",
      "epoch: 1, iter: 110000, loss: 30.16781997680664\n",
      "epoch: 1, iter: 110100, loss: 30.288387298583984\n",
      "epoch: 1, iter: 110200, loss: 30.20047950744629\n",
      "epoch: 1, iter: 110300, loss: 30.444766998291016\n",
      "epoch: 1, iter: 110400, loss: 30.524490356445312\n",
      "epoch: 1, iter: 110500, loss: 30.247175216674805\n",
      "epoch: 1, iter: 110600, loss: 30.329240798950195\n",
      "epoch: 1, iter: 110700, loss: 30.130420684814453\n",
      "epoch: 1, iter: 110800, loss: 30.31850814819336\n",
      "epoch: 1, iter: 110900, loss: 30.483060836791992\n",
      "epoch: 1, iter: 111000, loss: 29.993938446044922\n",
      "epoch: 1, iter: 111100, loss: 30.3347225189209\n",
      "epoch: 1, iter: 111200, loss: 30.348278045654297\n",
      "epoch: 1, iter: 111300, loss: 29.696823120117188\n",
      "epoch: 1, iter: 111400, loss: 30.16875648498535\n",
      "epoch: 1, iter: 111500, loss: 30.40314292907715\n",
      "epoch: 1, iter: 111600, loss: 30.234846115112305\n",
      "epoch: 1, iter: 111700, loss: 30.610750198364258\n",
      "epoch: 1, iter: 111800, loss: 30.579683303833008\n",
      "epoch: 1, iter: 111900, loss: 29.867555618286133\n",
      "epoch: 1, iter: 112000, loss: 30.184326171875\n",
      "epoch: 1, iter: 112100, loss: 30.227378845214844\n",
      "epoch: 1, iter: 112200, loss: 30.43674087524414\n",
      "epoch: 1, iter: 112300, loss: 30.272258758544922\n",
      "epoch: 1, iter: 112400, loss: 29.78339385986328\n",
      "epoch: 1, iter: 112500, loss: 30.40838050842285\n",
      "epoch: 1, iter: 112600, loss: 30.40868377685547\n",
      "epoch: 1, iter: 112700, loss: 30.687152862548828\n",
      "epoch: 1, iter: 112800, loss: 30.434242248535156\n",
      "epoch: 1, iter: 112900, loss: 30.393218994140625\n",
      "epoch: 1, iter: 113000, loss: 30.8359375\n",
      "epoch: 1, iter: 113100, loss: 30.642681121826172\n",
      "epoch: 1, iter: 113200, loss: 30.609024047851562\n",
      "epoch: 1, iter: 113300, loss: 30.28709602355957\n",
      "epoch: 1, iter: 113400, loss: 30.597427368164062\n",
      "epoch: 1, iter: 113500, loss: 30.40489387512207\n",
      "epoch: 1, iter: 113600, loss: 30.72698974609375\n",
      "epoch: 1, iter: 113700, loss: 30.28914451599121\n",
      "epoch: 1, iter: 113800, loss: 30.332096099853516\n",
      "epoch: 1, iter: 113900, loss: 30.480213165283203\n",
      "epoch: 1, iter: 114000, loss: 29.936847686767578\n",
      "epoch: 1, iter: 114100, loss: 30.5711669921875\n",
      "epoch: 1, iter: 114200, loss: 30.514476776123047\n",
      "epoch: 1, iter: 114300, loss: 29.705303192138672\n",
      "epoch: 1, iter: 114400, loss: 30.573406219482422\n",
      "epoch: 1, iter: 114500, loss: 30.43136215209961\n",
      "epoch: 1, iter: 114600, loss: 29.98093032836914\n",
      "epoch: 1, iter: 114700, loss: 30.22266960144043\n",
      "epoch: 1, iter: 114800, loss: 29.84975242614746\n",
      "epoch: 1, iter: 114900, loss: 30.21660614013672\n",
      "epoch: 1, iter: 115000, loss: 30.376880645751953\n",
      "epoch: 1, iter: 115100, loss: 30.12816619873047\n",
      "epoch: 1, iter: 115200, loss: 30.200393676757812\n",
      "epoch: 1, iter: 115300, loss: 30.53132438659668\n",
      "epoch: 1, iter: 115400, loss: 30.36357307434082\n",
      "epoch: 1, iter: 115500, loss: 30.302425384521484\n",
      "epoch: 1, iter: 115600, loss: 30.22951316833496\n",
      "epoch: 1, iter: 115700, loss: 30.043315887451172\n",
      "epoch: 1, iter: 115800, loss: 30.193492889404297\n",
      "epoch: 1, iter: 115900, loss: 30.30460548400879\n",
      "epoch: 1, iter: 116000, loss: 29.922672271728516\n",
      "epoch: 1, iter: 116100, loss: 30.495025634765625\n",
      "epoch: 1, iter: 116200, loss: 30.22774314880371\n",
      "epoch: 1, iter: 116300, loss: 30.005340576171875\n",
      "epoch: 1, iter: 116400, loss: 30.410961151123047\n",
      "epoch: 1, iter: 116500, loss: 30.28975486755371\n",
      "epoch: 1, iter: 116600, loss: 30.293073654174805\n",
      "epoch: 1, iter: 116700, loss: 30.982093811035156\n",
      "epoch: 1, iter: 116800, loss: 30.369665145874023\n",
      "epoch: 1, iter: 116900, loss: 30.21316909790039\n",
      "epoch: 1, iter: 117000, loss: 30.301511764526367\n",
      "epoch: 1, iter: 117100, loss: 30.589641571044922\n",
      "epoch: 1, iter: 117200, loss: 30.33188819885254\n",
      "epoch: 1, iter: 117300, loss: 30.25206756591797\n",
      "epoch: 1, iter: 117400, loss: 30.291683197021484\n",
      "epoch: 1, iter: 117500, loss: 30.6595458984375\n",
      "epoch: 1, iter: 117600, loss: 30.335670471191406\n",
      "epoch: 1, iter: 117700, loss: 29.98577117919922\n",
      "epoch: 1, iter: 117800, loss: 30.293041229248047\n",
      "epoch: 1, iter: 117900, loss: 30.267391204833984\n",
      "epoch: 1, iter: 118000, loss: 30.156648635864258\n",
      "epoch: 1, iter: 118100, loss: 30.49829864501953\n",
      "epoch: 1, iter: 118200, loss: 30.363662719726562\n",
      "epoch: 1, iter: 118300, loss: 30.476348876953125\n",
      "epoch: 1, iter: 118400, loss: 30.41768455505371\n",
      "epoch: 1, iter: 118500, loss: 30.194602966308594\n",
      "epoch: 1, iter: 118600, loss: 29.869232177734375\n",
      "epoch: 1, iter: 118700, loss: 30.120712280273438\n",
      "epoch: 1, iter: 118800, loss: 30.276317596435547\n",
      "epoch: 1, iter: 118900, loss: 30.30522918701172\n",
      "epoch: 1, iter: 119000, loss: 30.096656799316406\n",
      "epoch: 1, iter: 119100, loss: 30.12363624572754\n",
      "epoch: 1, iter: 119200, loss: 30.317134857177734\n",
      "epoch: 1, iter: 119300, loss: 30.43222427368164\n",
      "epoch: 1, iter: 119400, loss: 29.87285041809082\n",
      "epoch: 1, iter: 119500, loss: 30.065616607666016\n",
      "epoch: 1, iter: 119600, loss: 30.569969177246094\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "for e in range(NUM_EPOCHS):\n",
    "    # 前面看看取batch是多么的方便，一句话就可以搞定\n",
    "    for i, (input_labels, pos_labels, neg_labels) in enumerate(dataloader):\n",
    "\n",
    "        # 先保证都是longTensor\n",
    "        input_labels = input_labels.long()\n",
    "        pos_labels = pos_labels.long()\n",
    "        neg_labels = neg_labels.long()\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            input_labels = input_labels.cuda()\n",
    "            pos_labels = pos_labels.cuda()\n",
    "            neg_labels = neg_labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = model(input_labels, pos_labels, neg_labels).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 打印损失\n",
    "        if i % 100 == 0:\n",
    "            with open(LOG_FILE, \"a\") as fout:\n",
    "                fout.write(\"epoch: {}, iter: {}, loss: {}\\n\".format(e, i, loss.item()))\n",
    "                print(\"epoch: {}, iter: {}, loss: {}\".format(e, i, loss.item()))\n",
    "\n",
    "    # 保存参数\n",
    "    embedding_weights = model.input_embeddings()\n",
    "    np.save(\"embedding-{}\".format(EMBEDDING_SIZE), embedding_weights)\n",
    "    torch.save(model.state_dict(), \"embedding-{}.th\".format(EMBEDDING_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88d80e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 之后需要再次使用嵌入矩阵时，可以直接导入\n",
    "model.load_state_dict(torch.load(\"embedding-{}.th\".format(EMBEDDING_SIZE)))\n",
    "\n",
    "# 我们要的是这个权重\n",
    "embedding_weights = model.input_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae97386",
   "metadata": {},
   "source": [
    "## 模型的测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518368d3",
   "metadata": {},
   "source": [
    "### 寻找最近邻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3df9aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good ['good', 'bad', 'perfect', 'hard', 'truth', 'alone', 'really', 'money', 'heart', 'doing']\n",
      "fresh ['fresh', 'grain', 'waste', 'sized', 'lighter', 'minimal', 'noise', 'clean', 'fiber', 'cooling']\n",
      "monster ['monster', 'giant', 'robot', 'clown', 'snake', 'demon', 'bird', 'hammer', 'triangle', 'rod']\n",
      "green ['green', 'blue', 'yellow', 'white', 'cross', 'orange', 'red', 'black', 'mountain', 'snow']\n",
      "like ['like', 'etc', 'unlike', 'similarly', 'soft', 'fish', 'rich', 'eat', 'whereas', 'sounds']\n",
      "america ['america', 'korea', 'africa', 'india', 'australia', 'turkey', 'pakistan', 'argentina', 'europe', 'asia']\n",
      "chicago ['chicago', 'boston', 'texas', 'illinois', 'massachusetts', 'london', 'florida', 'berkeley', 'toronto', 'indiana']\n",
      "work ['work', 'writing', 'writings', 'marx', 'speech', 'vision', 'philosophical', 'job', 'appearance', 'genre']\n",
      "computer ['computer', 'digital', 'software', 'electronic', 'graphics', 'video', 'audio', 'hardware', 'computers', 'program']\n",
      "language ['language', 'alphabet', 'languages', 'arabic', 'pronunciation', 'grammar', 'dialect', 'programming', 'spoken', 'spelling']\n"
     ]
    }
   ],
   "source": [
    "def find_nearest(word):\n",
    "    index = word_to_idx[word]\n",
    "    embedding = embedding_weights[index]\n",
    "    cos_dis = np.array([scipy.spatial.distance.cosine(e, embedding) for e in embedding_weights])\n",
    "    return [idx_to_word[i] for i in cos_dis.argsort()[:10]]\n",
    "\n",
    "# 找和下面几个单词相近的单词：\n",
    "for word in [\"good\", \"fresh\", \"monster\", \"green\", \"like\", \"america\", \"chicago\", \"work\", \"computer\", \"language\"]:\n",
    "    print(word, find_nearest(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bad37c1",
   "metadata": {},
   "source": [
    "可以发现与good类似的有bad，perfect，与green有关的有blue，yellow，white这些颜色，与America有关的都是一些国家的一些词，效果不错"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dffa8d",
   "metadata": {},
   "source": [
    "### 单词之间关系的类比推理\n",
    "\n",
    "词嵌入有一个很好的特性，就是它能帮助实现类比推理。\n",
    "\n",
    "加入提出一个问题，男人对应女人，则king对应什么？能否有一种算法可以自动推导出这种关系。\n",
    "<img style=\"float: center;\" src=\"images/6.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16a0816c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king\n",
      "henry\n",
      "charles\n",
      "pope\n",
      "queen\n",
      "iii\n",
      "edward\n",
      "elizabeth\n",
      "prince\n",
      "alexander\n",
      "iv\n",
      "constantine\n",
      "james\n",
      "frederick\n",
      "louis\n",
      "joseph\n",
      "albert\n",
      "mary\n",
      "sir\n",
      "vii\n"
     ]
    }
   ],
   "source": [
    "man_idx = word_to_idx[\"man\"] \n",
    "king_idx = word_to_idx[\"king\"] \n",
    "woman_idx = word_to_idx[\"woman\"]\n",
    "embedding = embedding_weights[woman_idx] - embedding_weights[man_idx] + embedding_weights[king_idx]\n",
    "cos_dis = np.array([scipy.spatial.distance.cosine(e, embedding) for e in embedding_weights])\n",
    "for i in cos_dis.argsort()[:20]:\n",
    "    print(idx_to_word[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc86a280",
   "metadata": {},
   "source": [
    "可以看到国王对应上面的这些，里面也有queen，伊丽莎白等"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sEMG",
   "language": "python",
   "name": "semg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
