{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b9174c",
   "metadata": {},
   "source": [
    "# Tensorboard简介与安装\n",
    "\n",
    "Tensorboard：TensorFlow中强大的可视化工具，支持标量，图像，文本，音频，视频和Embedding等多种数据可视化：\n",
    "<img style=\"float: center;\" src=\"images/140.png\" width=\"70%\">\n",
    "\n",
    "运行机制：先从Python脚本中记录可视化的数据，然后生成eventfile文件存储到硬盘，最后从终端运行Tensorboard，打开Web页面，读取存储的eventfile在web页面上进行数据的可视化。\n",
    "<img style=\"float: center;\" src=\"images/141.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11d581e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编写python脚本文件，记录可视化数据\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 创建一个writer，记录想要的可视化数据\n",
    "writer = SummaryWriter(comment='test_tensorboard')\n",
    "\n",
    "for x in range(100):\n",
    "\n",
    "    writer.add_scalar('y=2x', x * 2, x)\n",
    "    writer.add_scalar('y=pow(2, x)',  2 ** x, x)\n",
    "    \n",
    "    writer.add_scalars('data/scalar_group', {\"xsinx\": x * np.sin(x),\n",
    "                                             \"xcosx\": x * np.cos(x),\n",
    "                                             \"arctanx\": np.arctan(x)}, x)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407de9d5",
   "metadata": {},
   "source": [
    "运行结束后，可以发现当前文件夹下有一个runs：\n",
    "<img style=\"float: center;\" src=\"images/142.png\" width=\"70%\">\n",
    "\n",
    "回到终端，输入tensorboard读取这个event files：\n",
    "<img style=\"float: center;\" src=\"images/143.png\" width=\"70%\">\n",
    "\n",
    "点击链接进入tensorboard的界面：\n",
    "<img style=\"float: center;\" src=\"images/144.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbb3d96",
   "metadata": {},
   "source": [
    "# Tensorboard基本使用\n",
    "\n",
    "准确率和损失的可视化，参数数据的分布及参数梯度的可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c8f011",
   "metadata": {},
   "source": [
    "## SummaryWriter\n",
    "\n",
    "提供创建event file的高级接口\n",
    "\n",
    "```python\n",
    "class SummaryWriter(object):\n",
    "    def __init__(self, log_dir=None, comment='', purge_step=None, max_queue=10, flush_secs=120, filename_suffix='')\n",
    "```\n",
    "- log_dir：event file输出文件夹，如果不设置，就创建一个runs\n",
    "- comment：不指定log_dir时，文件夹后缀\n",
    "- filename_suffix：event file文件夹后缀\n",
    "\n",
    "先不指定log_dir：\n",
    "<img style=\"float: center;\" src=\"images/145.png\" width=\"70%\">\n",
    "\n",
    "指定log_dir，发现comment就不起作用：\n",
    "<img style=\"float: center;\" src=\"images/146.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8ac24f",
   "metadata": {},
   "source": [
    "### add_scalar()/add_scalars()\n",
    "\n",
    "记录标量\n",
    "\n",
    "add_scalar(tag, scalar_value, global_step=None, walltime=None)\n",
    "\n",
    "add_scalars(main_tag, tag_scalar_dict, global_step=None, walltime=None)\n",
    "\n",
    "- tag：图像的标签名，图的唯一标识，就是图的标题\n",
    "- scalar_value：要记录的标量，可以理解为y轴\n",
    "- global_step：x轴\n",
    "\n",
    "注意：scalar_value的局限性就是它只能画一条线，但是往往模型训练的时候想监控训练集和验证集的曲线对比情况，那时候这个不能用了。\n",
    "\n",
    "add_scalars()：\n",
    "- main_tag：该图的标签\n",
    "- tag_scalar_dict：key是变量tag（类似于每条曲线的标签），value是变量的值（等同于上面的scalar_value，但可以多个线）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bba21ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_scalar('y=2x', x * 2, x)\n",
    "writer.add_scalar('y=pow(2, x)',  2 ** x, x)\n",
    "    \n",
    "writer.add_scalars('data/scalar_group', {\"xsinx\": x * np.sin(x),\n",
    "                                         \"xcosx\": x * np.cos(x),\n",
    "                                         \"arctanx\": np.arctan(x)}, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80cca1e",
   "metadata": {},
   "source": [
    "结果：\n",
    "<img style=\"float: center;\" src=\"images/147.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd25eb7",
   "metadata": {},
   "source": [
    "### add_histogram()\n",
    "\n",
    "统计直方图与多分位数直线图，对参数的分布以及梯度的分布非常有用\n",
    "\n",
    "add_histogram(tag, values, global_step=None, bins='tensorflow', walltime=None)\n",
    "\n",
    "- tag：图像的标签名字，图的唯一标识\n",
    "- values：统计的参数\n",
    "- global_step：y轴\n",
    "- bins：取直方图的bins\n",
    "\n",
    "<img style=\"float: center;\" src=\"images/148.png\" width=\"70%\">\n",
    "\n",
    "Tensorboard中的结果：\n",
    "<img style=\"float: center;\" src=\"images/149.png\" width=\"70%\">\n",
    "\n",
    "Tensorboard中的多分位折线图（可以观察每个数据方差的变化）：\n",
    "<img style=\"float: center;\" src=\"images/150.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1125df",
   "metadata": {},
   "source": [
    "### 模型训练监控\n",
    "\n",
    "采用上面两个方法进行模型训练过程中loss和acc的监控和参数的分布以及参数对应的梯度的一个分布，在具体模型训练中如何使用？\n",
    "\n",
    "首先在训练中构建一个SummaryWriter：\n",
    "<img style=\"float: center;\" src=\"images/151.png\" width=\"70%\">\n",
    "\n",
    "如何绘制训练过程中的损失，正确率变化曲线以及参数的分布及它们权重的分布：\n",
    "<img style=\"float: center;\" src=\"images/152.png\" width=\"70%\">\n",
    "\n",
    "绘制验证集上的损失和正确率的曲线变化图像：\n",
    "<img style=\"float: center;\" src=\"images/153.png\" width=\"70%\">\n",
    "\n",
    "最后的结果：\n",
    "<img style=\"float: center;\" src=\"images/154.png\" width=\"70%\">\n",
    "\n",
    "上述是模型训练过程中学习曲线ed可视化，下面看看参数的分布直方图：\n",
    "<img style=\"float: center;\" src=\"images/155.png\" width=\"70%\">\n",
    "\n",
    "以上就是如何用SummaryWriter去构建event file的一个路径，设置路径，然后add_scalar和add_histogram方法。\n",
    "\n",
    "采用这两个方法可以监控模型训练过程中训练集和验证集loss曲线及准确率曲线对比，还有模型参数的数据分布以及每个epoch梯度更新的一个分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48973f41",
   "metadata": {},
   "source": [
    "## Tensorboard图像可视化方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15216f90",
   "metadata": {},
   "source": [
    "### add_image()\n",
    "\n",
    "记录图像\n",
    "\n",
    "add_image(tag, img_tensor, global_step=None, walltime=None, dataformats='CHW')\n",
    "\n",
    "- tag：图像标签名，图的唯一标识\n",
    "- img_tensor：图像数据，注意尺度（如果图片像素值为0-1，则默认会在这个基础上\\*255来可视化，因为图片都是0-255，如果像素值有大于1的，则机器就会认为是0-255范围，不做任何改动）\n",
    "- global_step：x轴\n",
    "- dataformats：数据形式（CHW，HWC，HW灰度图）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b474847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "writer = SummaryWriter(comment='test_your_comment', filename_suffix=\"_test_your_filename_suffix\")\n",
    "\n",
    "# img 1，random\n",
    "fake_img = torch.randn(3, 512, 512) # CHW\n",
    "writer.add_image(\"fake_img\", fake_img, 1)\n",
    "time.sleep(1)\n",
    "\n",
    "# img 2，ones\n",
    "# 这个全1， 没有大于1的，所以机器会先乘以255然后显示\n",
    "fake_img = torch.ones(3, 512, 512)   \n",
    "writer.add_image(\"fake_img\", fake_img, 2)\n",
    "time.sleep(1)\n",
    "\n",
    "# img 3，1.1\n",
    "# 这个像素都大于1， 所以默认不处理\n",
    "fake_img = torch.ones(3, 512, 512) * 1.1\n",
    "writer.add_image(\"fake_img\", fake_img, 3)\n",
    "time.sleep(1)\n",
    "\n",
    "# img 4，HW\n",
    "# 灰度图像\n",
    "fake_img = torch.rand(512, 512)\n",
    "writer.add_image(\"fake_img\", fake_img, 4, dataformats=\"HW\")\n",
    "time.sleep(1)\n",
    "\n",
    "# img 5，HWC\n",
    "# 演示一下dataformats\n",
    "fake_img = torch.rand(512, 512, 3)\n",
    "writer.add_image(\"fake_img\", fake_img, 5, dataformats=\"HWC\")\n",
    "time.sleep(1)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa3bc50",
   "metadata": {},
   "source": [
    "看一下效果：\n",
    "<img style=\"float: center;\" src=\"images/156.png\" width=\"70%\">\n",
    "\n",
    "上面的图片中可视化了5张图片，但是显示的时候，需要拖动去一次次地显示每一张图片，这样就无法同时对比，如果想从一个界面里同时显示多张图片？则需要用到下面地方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc820e",
   "metadata": {},
   "source": [
    "### torchvision.utils.make_grid\n",
    "\n",
    "制作网格图像\n",
    "\n",
    "make_grid(tensor, nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0)\n",
    "\n",
    "- tensor：图像数据，B\\*CHW形式，B表示图片个数\n",
    "- nrow：行数（列数自动计算），根据上面指定地B来计算列数\n",
    "- padding：图像间距（像素单位）\n",
    "- normalize：是否将像素值标准化，视觉像素0-255，因此如果像素值是0-1地数，则将这个设置为True，就会把像素值映射到0-255之间，设置为False，则不变。（这里的标准化是针对视觉像素正常范围来讲）\n",
    "- range：标准化范围，舍弃一些过大或者过小的像素，例如一张图片的像素值范围[-1000,2000]，如果指定这里的标准化范围是[-600, 500]，则会先把图片像素值规范到这个指定区间，小于-600的用-600表示，大于500的用500表示，然后在进行标准化到0-255\n",
    "- scale_each：是否单张图维度标准化（有的图像可能尺度不一样，如果设置False，是从整个大张量上进行标准化）\n",
    "- pad_value：padding的像素值（网格线的颜色，通常默认0）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e680a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11792/1705208070.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# train_dir = \"path to your training data\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtransform_compose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRMBDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform_compose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "writer = SummaryWriter(comment='test_your_comment', filename_suffix=\"_test_your_filename_suffix\")\n",
    "\n",
    "split_dir = os.path.join(\"..\", \"05数据读取机制\", \"data\", \"rmb_split\")\n",
    "train_dir = os.path.join(split_dir, \"train\")\n",
    "# train_dir = \"path to your training data\"\n",
    "\n",
    "transform_compose = transforms.Compose([transforms.Resize((32, 64)), transforms.ToTensor()])\n",
    "train_data = RMBDataset(data_dir=train_dir, transform=transform_compose)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
    "data_batch, label_batch = next(iter(train_loader))\n",
    "\n",
    "img_grid = vutils.make_grid(data_batch, nrow=4, normalize=True, scale_each=True)\n",
    "# img_grid = vutils.make_grid(data_batch, nrow=4, normalize=False, scale_each=False)\n",
    "writer.add_image(\"input img\", img_grid, 0)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c62ac5",
   "metadata": {},
   "source": [
    "可以看到效果：\n",
    "<img style=\"float: center;\" src=\"images/157.png\" width=\"70%\">\n",
    "\n",
    "add_image结合make_grid的使用方法比较实用，可以对数据进行一个基本的审查，快速的检查训练数据样本之间是否有交叉，这些样本的标签是否是正确的。（这样审查数据集就比较快了）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0a5372",
   "metadata": {},
   "source": [
    "### add_graph()\n",
    "\n",
    "可视化模型计算图\n",
    "\n",
    "add_graph(model, input_to_model=None, verbose=False)\n",
    "\n",
    "- model：模型（需要是nn.Module）\n",
    "- input_to_model：输出给模型的数据\n",
    "- verbose：是否打印计算图结构信息\n",
    "\n",
    "计算图显示效果：\n",
    "<img style=\"float: center;\" src=\"images/158.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b2cb74b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LeNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11792/3349496898.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfake_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mlenet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLeNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlenet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_img\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 这是可视化LeNet的计算图\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LeNet' is not defined"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(comment='test_your_comment', filename_suffix=\"_test_your_filename_suffix\")\n",
    "\n",
    "# 模型\n",
    "fake_img = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "lenet = LeNet(classes=2)\n",
    "\n",
    "writer.add_graph(lenet, fake_img)  # 这是可视化LeNet的计算图\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb968b3e",
   "metadata": {},
   "source": [
    "### torchsummary\n",
    "\n",
    "查看模型信息，便于调试，打印模型输入输出的shape以及参数总量\n",
    "\n",
    "summary(model, input_size, batch_size=-1, device='cuda')\n",
    "\n",
    "- model：pytorch模型\n",
    "- input_size：模型输入size\n",
    "- batch_size：batch大小\n",
    "- device：cuda或cpu\n",
    "\n",
    "<img style=\"float: center;\" src=\"images/159.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb8887",
   "metadata": {},
   "source": [
    "# hook函数与CAM可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee15f00",
   "metadata": {},
   "source": [
    "## hook函数\n",
    "\n",
    "Hook函数机制：不改变模型的主体，实现额外功能，像一个挂件和挂钩。\n",
    "\n",
    "为何需要这个东西？与PyTorch计算图机制有关，动态图的运算过程中，运算结束后，一些中间变量会被释放掉（比如特征图，非叶子节点的梯度）。但是往往需要提取这些中间变量，这时候可以用hook函数在前向/反向传播的时候，挂上一个额外的函数，通过这个额外的函数去获取这些可能被释放掉而后面又想用的这些中间变量，甚至可以通过hook函数去改变中间变量的梯度。\n",
    "\n",
    "PyTorch提供四种hook函数：\n",
    "- torch.Tensor.register_hook(hook)：针对tensor\n",
    "- torch.nn.Module.register_forward_hook：后面这三个针对Module\n",
    "- torch.nn.Module.register_forward_pre_hook\n",
    "- torch.nn.Module.register_backward_hook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea6881",
   "metadata": {},
   "source": [
    "## hook函数与特征图提取"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3737318d",
   "metadata": {},
   "source": [
    "### torch.Tensor.register_hook\n",
    "\n",
    "张量的hook函数，注册一个**反向传播**的hook函数（只有在反向传播的时候某些中间叶子节点的梯度才会被释放掉，才需要使用hook函数去保留一些中间变量的信息）\n",
    "\n",
    "可以理解成一个钩子，用这个钩子挂一些函数到计算图上，然后去完成一些额外的功能。\n",
    "\n",
    "可以发现允许挂的函数只有一个输入参数，不返回或者返回张量\n",
    "- hook(grad)->Tensor or None\n",
    "\n",
    "注册（挂上）：\n",
    "<img style=\"float: center;\" src=\"images/160.png\" width=\"70%\">\n",
    "\n",
    "这个图在反向传播结束后，非叶子节点的梯度会被释放掉，即这里的a，b梯度，则如何保留住呢？\n",
    "\n",
    "之前有一个retain_grad()方法，可以保留中间节点的梯度，其实这里hook也可以保留住梯度：\n",
    "<img style=\"float: center;\" src=\"images/161.png\" width=\"70%\">\n",
    "\n",
    "hook函数不仅仅可以保留梯度，还可以做其他的功能。例如在反向传播中改变叶子节点w的梯度：\n",
    "<img style=\"float: center;\" src=\"images/162.png\" width=\"70%\">\n",
    "\n",
    "可以看到，通过钩子的方式在计算图上挂函数然后去完成一些功能还是很方便的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d423fcba",
   "metadata": {},
   "source": [
    "### Module.register_forward_pre_hook\n",
    "\n",
    "注册module的前向传播**前**的hook函数，允许挂的函数结构：\n",
    "- hook(module, input)->None\n",
    "\n",
    "因为它是挂在前向传播前的函数，所以这里接收参数就没有output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3d7a99",
   "metadata": {},
   "source": [
    "### Module.register_forward_hook\n",
    "\n",
    "注册module的前向传播hook函数，他的函数定义方法如下：\n",
    "- hook(module, input, output)->None\n",
    "  - 这个钩子允许挂的函数有3个输入\n",
    "  - module：当前网络层\n",
    "  - input：当前网络层的输入数据\n",
    "  - output：当前网络层的输出数据\n",
    "\n",
    "通常使用这个函数在前向传播中获取卷积输出的一个特征图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af099da",
   "metadata": {},
   "source": [
    "### Module.register_backward_hook\n",
    "\n",
    "注册module反向传播的hook函数\n",
    "- hook(module, grad_input, grad_output)->Tensor or None\n",
    "\n",
    "挂在反向传播后，因此当前的输入有三个参数，后两个是grad_input和grad_output（当前网络层输入梯度数据和输出梯度数据）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09211381",
   "metadata": {},
   "source": [
    "### 钩子函数调用机制\n",
    "\n",
    "需求：有一张图片，通过两个卷积核提取特征，之后通过池化得到最后值。\n",
    "\n",
    "如果是单传的前向传播，则传完后通过卷积之后的特征图就会被释放掉，那如何进行保留这些特征图并且后期可以用Tensorboard进行可视化呢？\n",
    "<img style=\"float: center;\" src=\"images/163.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cc0373",
   "metadata": {},
   "source": [
    "这时候可以采用前向传播hook函数来获取中间的这个特征图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52b48e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([1, 2, 1, 1])\n",
      "output value: tensor([[[[ 9.]],\n",
      "\n",
      "         [[18.]]]], grad_fn=<MaxPool2DWithIndicesBackward0>)\n",
      "\n",
      "feature maps shape: torch.Size([1, 2, 2, 2])\n",
      "output value: tensor([[[[ 9.,  9.],\n",
      "          [ 9.,  9.]],\n",
      "\n",
      "         [[18., 18.],\n",
      "          [18., 18.]]]], grad_fn=<ThnnConv2DBackward0>)\n",
      "\n",
      "input shape: torch.Size([1, 1, 4, 4])\n",
      "input value: (tensor([[[[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]]]]),)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 定义我们的网络， 这里只有卷积核池化两个操作\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 2, 3)  # 1张图片， 2个卷积核， 3*3的\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        return x\n",
    "\n",
    "# 下面定义前向传播的hook函数\n",
    "def forward_hook(module, data_input, data_output):\n",
    "    fmap_block.append(data_output)\n",
    "    input_block.append(data_input)\n",
    "\n",
    "# 网络初始化\n",
    "net = Net()\n",
    "# 按照上面的图进行卷积层的网络初始化\n",
    "net.conv1.weight[0].detach().fill_(1)\n",
    "net.conv1.weight[1].detach().fill_(2)\n",
    "net.conv1.bias.data.detach().zero_()\n",
    "\n",
    "# 弄一个钩子挂上函数\n",
    "fmap_block = list()   # 保存特征图\n",
    "input_block = list()\n",
    "# 这句话就把函数用钩子挂在了conv1上面，进行conv1输出的获取\n",
    "net.conv1.register_forward_hook(forward_hook)\n",
    "\n",
    "# 下面初始化一个输入\n",
    "fake_img = torch.ones((1, 1, 4, 4))   # 根据上面图片初始化\n",
    "output = net(fake_img)   # 前向传播\n",
    "\n",
    "# 先不用反向传播，我们输出特征图看看\n",
    "print(\"output shape: {}\\noutput value: {}\\n\".format(output.shape, output))\n",
    "print(\"feature maps shape: {}\\noutput value: {}\\n\".format(fmap_block[0].shape, fmap_block[0]))\n",
    "print(\"input shape: {}\\ninput value: {}\".format(input_block[0][0].shape, input_block[0]))\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaa9ef9",
   "metadata": {},
   "source": [
    "可以看结果：\n",
    "<img style=\"float: center;\" src=\"images/164.png\" width=\"70%\">\n",
    "\n",
    "工作原理：\n",
    "\n",
    "在output=net(fake_img)前打上断点，然后debug，步入，进入Module的\\_\\_call\\_\\_函数，这里调用前向传播函数：\n",
    "<img style=\"float: center;\" src=\"images/165.png\" width=\"70%\">\n",
    "\n",
    "这里再一次步入，跳到自己写的前向传播函数里，这里第一个子模块就是卷积模块（就是放钩子的地方），再一次步入：\n",
    "<img style=\"float: center;\" src=\"images/166.png\" width=\"70%\">\n",
    "\n",
    "又回到Module的\\_\\_call\\_\\_函数，因为子模块也是继承的Module（因为这里不仅是完成前向传播，第一个子模块是放了一个钩子的，所以\\_\\_call\\_\\_函数不止完成forward）：\n",
    "<img style=\"float: center;\" src=\"images/167.png\" width=\"70%\">\n",
    "\n",
    "前向传播后，获得了中间特征图，但这一次有一个钩子放在这里，那么获取了中间特征图之后，不会返回，而是去执行钩子函数：\n",
    "<img style=\"float: center;\" src=\"images/168.png\" width=\"70%\">\n",
    "\n",
    "在hook_result = hook(self, input, result)这一行再次步入，发现跳到我们自定义的hook函数中：\n",
    "<img style=\"float: center;\" src=\"images/169.png\" width=\"70%\">\n",
    "\n",
    "这样就完成了中间图的存储。\n",
    "\n",
    "上面的hook函数运行机制都是在\\_\\_call\\_\\_函数中完成（这也是Python代码高级的一个地方），它实现了一些hook机制，提供了一些额外的实现别的功能的一些接口。\n",
    "\n",
    "简而言之：\n",
    "- 首先在定义网络的时候，调用父类Module的\\_\\_init\\_\\_函数对模块进行初始化，当然这里的模块不仅指的最后的大网络，每个小的子模块也是如此，这个初始化的过程中是完成了8个参数字典的初始化。\n",
    "- 在模型调用的时候，其实是在执行Module的\\_\\_call\\_\\_函数，这个函数其实是完成4部分的工作：\n",
    "  - 前向传播之前的hook函数\n",
    "  - 前向传播的hook函数\n",
    "  - forward_hooks函数\n",
    "  - 反向传播的hooks函数\n",
    "  \n",
    "以上就是PyTorch中hook函数的一个运行机制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f041757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_pre_hook input:(tensor([[[[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]]]]),)\n",
      "backward hook input:(None, tensor([[[[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]]]]), tensor([0.5000, 0.5000]))\n",
      "backward hook output:(tensor([[[[0.5000, 0.0000],\n",
      "          [0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5000, 0.0000],\n",
      "          [0.0000, 0.0000]]]]),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Huris\\anaconda3\\envs\\sEMG\\lib\\site-packages\\torch\\nn\\modules\\module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 2, 3)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        return x\n",
    "\n",
    "def forward_hook(module, data_input, data_output):\n",
    "    fmap_block.append(data_output)\n",
    "    input_block.append(data_input)\n",
    "\n",
    "def forward_pre_hook(module, data_input):\n",
    "    print(\"forward_pre_hook input:{}\".format(data_input))\n",
    "\n",
    "def backward_hook(module, grad_input, grad_output):\n",
    "    print(\"backward hook input:{}\".format(grad_input))\n",
    "    print(\"backward hook output:{}\".format(grad_output))\n",
    "\n",
    "# 初始化网络\n",
    "net = Net()\n",
    "net.conv1.weight[0].detach().fill_(1)\n",
    "net.conv1.weight[1].detach().fill_(2)\n",
    "net.conv1.bias.data.detach().zero_()\n",
    "\n",
    "# 注册hook\n",
    "fmap_block = list()\n",
    "input_block = list()\n",
    "net.conv1.register_forward_hook(forward_hook)\n",
    "net.conv1.register_forward_pre_hook(forward_pre_hook)\n",
    "net.conv1.register_backward_hook(backward_hook)\n",
    "\n",
    "# inference\n",
    "fake_img = torch.ones((1, 1, 4, 4))   # batch size * channel * H * W\n",
    "output = net(fake_img)\n",
    "\n",
    "loss_fnc = nn.L1Loss()\n",
    "target = torch.randn_like(output)\n",
    "loss = loss_fnc(target, output)\n",
    "loss.backward()\n",
    "\n",
    "# 观察\n",
    "# print(\"output shape: {}\\noutput value: {}\\n\".format(output.shape, output))\n",
    "# print(\"feature maps shape: {}\\noutput value: {}\\n\".format(fmap_block[0].shape, fmap_block[0]))\n",
    "# print(\"input shape: {}\\ninput value: {}\".format(input_block[0][0].shape, input_block[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a928f8",
   "metadata": {},
   "source": [
    "这里加了另外两个hook函数，然后把最后的输出注释，观察三个hook函数的运行顺序：\n",
    "<img style=\"float: center;\" src=\"images/170.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d5da9d",
   "metadata": {},
   "source": [
    "### 总结\n",
    "\n",
    "hook机制：计算图上挂一些钩子，钩子上挂一些函数，在不改变模型或者计算图的主体下，实现一些额外的功能，比如保存一些中间变量。\n",
    "\n",
    "主要有四个hook函数：\n",
    "- 第一个针对Tensor：挂在反向传播之后，用于保留中间节点的梯度或者改变一些梯度等\n",
    "- 另外三个针对Module，根据挂的位置不同分为三个：\n",
    "  - 挂在前向传播前的：这个接收的参数没有输出，一般用来查看输入数据的信息\n",
    "  - 挂在前向传播后的：这个接收的参数就是输入和输出，一般用来存储中间特征图的信息\n",
    "  - 挂在反向传播后的：查看梯度信息\n",
    "\n",
    "hook机制的运行原理：主要在Module的\\_\\_call\\_\\_函数中，这里完成四块功能，先看有没有前向传播的钩子，然后前向传播，然后前向传播后的钩子，然后反向传播钩子。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95674489",
   "metadata": {},
   "source": [
    "## CAM可视化\n",
    "\n",
    "CAM（class activation map）：类激活图，分析卷积神经网络，当卷积神经网络得到输出后，可以分析网络是关注图像的哪些部分而得到的这个结果。\n",
    "\n",
    "可以分析出网络是否学习到了图片中物体本身的特征信息：\n",
    "<img style=\"float: center;\" src=\"images/171.png\" width=\"70%\">\n",
    "\n",
    "网络最后输出是澳大利亚犬种，则网络从图像中看到什么东西才确定是这一个类呢？\n",
    "\n",
    "这里可以通过CAM算法进行可视化，结果就是下面的图像，红色的就是网络重点关注的，在这个结果中可以发现，这个网络重点关注了狗的头部，然后判断是这样一个犬种。\n",
    "\n",
    "CAM的基本思想：它会对网络的最后一个特征图进行加权求和，就可以得到一个注意力机制，就是卷积神经网络更关注于什么地方：\n",
    "<img style=\"float: center;\" src=\"images/172.png\" width=\"70%\">\n",
    "\n",
    "可以发现实验中网络在预测是飞机的时候，其实关注的不是飞机本身，而是飞机周围的天空，发现一片蓝色，所以网络就预测是飞机。\n",
    "\n",
    "预测汽车的时候，如果把汽车缩小，周围出现了大片蓝色，就发现网络把车也预测成了飞机。（最后一张图，竟然还预测出一个船，这个可能是因为底部的左边是蓝色，右边不是蓝色，所以网络认为这个是船）\n",
    "\n",
    "这说明网络根本没有在学习物体本身，而是光关注物体周围的环境。\n",
    "\n",
    "通过Grad-CAM可视化可以分析卷积神经网络学习到的特征是否真的是好的，是否真的在学习物体本身。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c2ee62",
   "metadata": {},
   "source": [
    "# 思维导图\n",
    "\n",
    "<img style=\"float: center;\" src=\"images/173.png\" width=\"70%\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sEMG",
   "language": "python",
   "name": "semg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
