{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "318513b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca877cb",
   "metadata": {},
   "source": [
    "# 权值初始化\n",
    "\n",
    "网络模型搭建后，对网络中权重进行合适的初始化非常重要。\n",
    "- 初始化正好在模型的最优解附近，则模型训练速度会非常快。\n",
    "- 初始化离最优解远，则模型需要更多次迭代，可能会引发梯度消失或爆炸。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35e2b80",
   "metadata": {},
   "source": [
    "## 梯度消失和爆炸\n",
    "\n",
    "<img style=\"float: center;\" src=\"images/79.png\" width=\"70%\">\n",
    "\n",
    "要计算$W_2$梯度，根据链式法则：$H_2=H_1\\times W_2$\n",
    "\n",
    "$\\triangle W_2=\\frac{\\partial Loss}{\\partial W_2}=\\frac{\\partial Loss}{\\partial out}\\times \\frac{\\partial out}{\\partial H_2}\\times \\frac{\\partial H_2}{\\partial W_2}=\\frac{\\partial Loss}{\\partial out}\\times \\frac{\\partial out}{\\partial H_2}\\times H_1$\n",
    "\n",
    "可以发现$W_2$梯度求解过程中会用到上一层神经元输出值$H_1$，若$H_1$的输出值非常小，则$W_2$的梯度也会非常小（梯度消失），尤其当网络层非常多的时候，连乘一个非常小的数，会导致越乘越小。而当$H_1$非常大的时候（梯度爆炸）。\n",
    "\n",
    "$H_1 \\rightarrow 0 \\Rightarrow \\triangle W_2 \\rightarrow 0$\n",
    "\n",
    "$H_1 \\rightarrow \\infty \\Rightarrow \\triangle W_2 \\rightarrow \\infty$\n",
    "\n",
    "一旦发生梯度消失或爆炸，模型就无法训练，要想避免这个现象，需要**控制网络输出层的尺度范围，不能让它太大或太小**，这就需要合理的**初始化权重**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "481b4a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立100层多层感知机，每一层256个神经元\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, neural_num, layers):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(neural_num, neural_num, bias=False)\n",
    "                                     for i in range(layers)])\n",
    "        self.neural_num = neural_num\n",
    "    \n",
    "    # 正向传播\n",
    "    def forward(self, x):\n",
    "        for i, linear in enumerate(self.linears):\n",
    "            x = linear(x)\n",
    "        \n",
    "            print(f\"layer:{i},std:{x.std()}\")\n",
    "\n",
    "            if torch.isnan(x.std()):\n",
    "                print(f\"output is nan in {i} layers\")\n",
    "                break\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    # 权值初始化，使用标准正态分布\n",
    "    def initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c269ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:0,std:15.944011688232422\n",
      "layer:1,std:255.11569213867188\n",
      "layer:2,std:4016.758544921875\n",
      "layer:3,std:64151.5234375\n",
      "layer:4,std:1039510.125\n",
      "layer:5,std:16374433.0\n",
      "layer:6,std:263322816.0\n",
      "layer:7,std:4190569728.0\n",
      "layer:8,std:67863425024.0\n",
      "layer:9,std:1070481801216.0\n",
      "layer:10,std:16919611572224.0\n",
      "layer:11,std:275770756825088.0\n",
      "layer:12,std:4517903479078912.0\n",
      "layer:13,std:7.369505890946253e+16\n",
      "layer:14,std:1.1669860450324972e+18\n",
      "layer:15,std:1.821879882059717e+19\n",
      "layer:16,std:2.91014902543194e+20\n",
      "layer:17,std:4.665675452235282e+21\n",
      "layer:18,std:7.621574055228135e+22\n",
      "layer:19,std:1.211707098629305e+24\n",
      "layer:20,std:1.9111977476024693e+25\n",
      "layer:21,std:3.043657431929855e+26\n",
      "layer:22,std:4.9322685894834766e+27\n",
      "layer:23,std:7.822334209640582e+28\n",
      "layer:24,std:1.2538825974158207e+30\n",
      "layer:25,std:2.0024991819955308e+31\n",
      "layer:26,std:3.1725463099290994e+32\n",
      "layer:27,std:5.203591204483248e+33\n",
      "layer:28,std:8.078508999111262e+34\n",
      "layer:29,std:1.3377619780819773e+36\n",
      "layer:30,std:nan\n",
      "output is nan in 30 layers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8903e+37, -2.4083e+36,  4.2697e+37,  ...,  6.3164e+37,\n",
       "          3.7192e+37, -2.8457e+37],\n",
       "        [-1.3344e+36, -3.5256e+37,  2.1467e+36,  ...,  2.5005e+37,\n",
       "          1.8009e+37, -4.6022e+37],\n",
       "        [-1.8832e+36,  1.3759e+37,  2.7584e+35,  ...,  1.0284e+37,\n",
       "          1.6108e+37,  6.3711e+35],\n",
       "        ...,\n",
       "        [-1.1908e+37,  5.5315e+36, -9.7927e+36,  ..., -5.2890e+36,\n",
       "         -2.2129e+37,  8.1288e+36],\n",
       "        [ 1.8008e+36,  4.1029e+36,  1.8122e+37,  ...,  3.9453e+37,\n",
       "         -1.4130e+37, -1.4482e+36],\n",
       "        [-1.8667e+37,  9.6412e+36, -1.7507e+36,  ..., -1.3098e+37,\n",
       "          1.6047e+37,  1.5941e+37]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_nums = 100\n",
    "neural_nums = 256\n",
    "batch_size = 16\n",
    "\n",
    "net = MLP(neural_nums, layer_nums)\n",
    "net.initialize()\n",
    "\n",
    "inputs = torch.randn((batch_size, neural_nums))\n",
    "\n",
    "output = net(inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aaf5ec",
   "metadata": {},
   "source": [
    "在30层左右，网络的输出成为nan，导致后续输出值过大。\n",
    "\n",
    "如果进行反向传播，根据上面的权重推导公式，当值为nan，反向传播时这些权重无法进行更新，会发生梯度爆炸现象。\n",
    "\n",
    "有时候在训练网络时，**最后结果全是nan的原因，可能就是权重初始化不当导致的**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf62be2a",
   "metadata": {},
   "source": [
    "**为啥权重初始化不当会影响网络输出？**\n",
    "\n",
    "可以推导$D(XY)$方差公式：\n",
    "\n",
    "借助三个基本公式：\n",
    "- $E(XY)=E(X)E(Y)$\n",
    "- $D(X)=E(X^2)-[E(X)]^2$\n",
    "- $D(X+Y)=D(X)+D(Y)$\n",
    "\n",
    "则：\n",
    "\n",
    "$D(XY)$\n",
    "\n",
    "$=E[XY-E(XY)]^2$\n",
    "\n",
    "$=E(X^2Y^2)-2XYE(XY)+E^2(XY)$\n",
    "\n",
    "$=E(X^2)E(Y^2)-2E^2(X)E^2(Y)+E^2(X)E^2(Y)$\n",
    "\n",
    "$=E(X^2)E(Y^2)-E^2(X)E^2(Y)$\n",
    "\n",
    "$=(D(X)+[E(X)]^2)(D(Y)+[E(Y)]^2)-E(X^2)E(Y^2)-E^2(X)E^2(Y)$\n",
    "\n",
    "$=D(X)D(Y)+D(X)[E(Y)]^2+D(Y)[E(X)]^2$\n",
    "\n",
    "若$E(X)=0,E(Y)=0,则D(XY)=D(X)D(Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb027dd1",
   "metadata": {},
   "source": [
    "则以下网络：\n",
    "<img style=\"float: center;\" src=\"images/79.png\" width=\"70%\">\n",
    "\n",
    "第一层第一个神经元方差：\n",
    "\n",
    "$H_{11}=\\sum^n_{i=0}X_i*W_{1i}$\n",
    "\n",
    "$D(H_{11})=\\sum^n_{i=0}D(X_i)*D(W_{1i})=n*(1*1)=n$\n",
    "\n",
    "$std(H_{11})=\\sqrt{D(H_{11})}=\\sqrt(n)$\n",
    "\n",
    "此处，输入数据的权重都初始化为均值为0，方差为1的标准正态，经过一个网络层发现方差扩大了n倍。（上面用了100个网络层，则方差会指数增长，因此出现输出层方差为nan的情况）\n",
    "\n",
    "**如何解决呢？**\n",
    "\n",
    "让网络层的输出方差保持尺度不变即可。\n",
    "\n",
    "根据公式，$D(H_{11})=\\sum^n_{i=0}D(X_i)*D(W_{1i})=n*(1*1)=n$，发现每一层的输出方差与每一层神经元个数、前一层输出方差、本层权重有关，如果想让方差尺度不变，可以让每一层输出方差为1，即$D(H_{11})=1$，这样后面多层相乘，尺度不变。\n",
    "\n",
    "由于神经元个数无法改变，前一层的输出方差是1，因此只能改变本层权重方差：\n",
    "\n",
    "$D(H_1)=n\\times D(X)\\times D(W)=1$\n",
    "\n",
    "$D(W)=\\frac{1}{n} \\Rightarrow std(W)=\\sqrt{\\frac{1}{n}}$\n",
    "\n",
    "即，在权重初始化时，方差如果为$\\sqrt{1}{n}$的话，每一层的输入方差都是1，这样方差就不会导致nan的情况发生。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab32363",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, neural_num, layers):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(neural_num, neural_num, bias=False)\n",
    "                                     for i in range(layers)])\n",
    "        self.neural_num = neural_num\n",
    "    \n",
    "    # 正向传播\n",
    "    def forward(self, x):\n",
    "        for i, linear in enumerate(self.linears):\n",
    "            x = linear(x)\n",
    "        \n",
    "            print(f\"layer:{i},std:{x.std()}\")\n",
    "\n",
    "            if torch.isnan(x.std()):\n",
    "                print(f\"output is nan in {i} layers\")\n",
    "                break\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    # 权值初始化，使用标准正态分布\n",
    "    def initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                # 改变初始化std\n",
    "                # nn.init.normal_(m.weight.data)\n",
    "                nn.init.normal_(m.weight.data, std=np.sqrt(1/self.neural_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cefeb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:0,std:1.0278830528259277\n",
      "layer:1,std:1.0181204080581665\n",
      "layer:2,std:1.014767050743103\n",
      "layer:3,std:1.0146775245666504\n",
      "layer:4,std:1.0123896598815918\n",
      "layer:5,std:1.0262004137039185\n",
      "layer:6,std:1.0095330476760864\n",
      "layer:7,std:1.027438759803772\n",
      "layer:8,std:1.019274115562439\n",
      "layer:9,std:1.0268949270248413\n",
      "layer:10,std:1.0337014198303223\n",
      "layer:11,std:1.0398966073989868\n",
      "layer:12,std:1.04704749584198\n",
      "layer:13,std:1.072679042816162\n",
      "layer:14,std:1.0385937690734863\n",
      "layer:15,std:1.0226327180862427\n",
      "layer:16,std:1.0111712217330933\n",
      "layer:17,std:1.0268144607543945\n",
      "layer:18,std:1.0496608018875122\n",
      "layer:19,std:1.0328172445297241\n",
      "layer:20,std:1.0183610916137695\n",
      "layer:21,std:1.0026816129684448\n",
      "layer:22,std:0.9916945099830627\n",
      "layer:23,std:1.0056698322296143\n",
      "layer:24,std:1.0347695350646973\n",
      "layer:25,std:1.0429946184158325\n",
      "layer:26,std:1.071308970451355\n",
      "layer:27,std:1.0872653722763062\n",
      "layer:28,std:1.0766782760620117\n",
      "layer:29,std:1.035771369934082\n",
      "layer:30,std:1.0315487384796143\n",
      "layer:31,std:1.0274670124053955\n",
      "layer:32,std:1.0075932741165161\n",
      "layer:33,std:1.0161364078521729\n",
      "layer:34,std:1.0095645189285278\n",
      "layer:35,std:1.012191891670227\n",
      "layer:36,std:0.9916255474090576\n",
      "layer:37,std:0.9746937155723572\n",
      "layer:38,std:0.9767629504203796\n",
      "layer:39,std:0.9953874945640564\n",
      "layer:40,std:1.0100027322769165\n",
      "layer:41,std:1.0300137996673584\n",
      "layer:42,std:1.0218418836593628\n",
      "layer:43,std:1.0125041007995605\n",
      "layer:44,std:1.0436031818389893\n",
      "layer:45,std:1.0331271886825562\n",
      "layer:46,std:1.0608720779418945\n",
      "layer:47,std:1.077950119972229\n",
      "layer:48,std:1.0727808475494385\n",
      "layer:49,std:1.0953997373580933\n",
      "layer:50,std:1.0797842741012573\n",
      "layer:51,std:1.0404611825942993\n",
      "layer:52,std:1.0841727256774902\n",
      "layer:53,std:1.1070277690887451\n",
      "layer:54,std:1.115551233291626\n",
      "layer:55,std:1.066311240196228\n",
      "layer:56,std:1.0817170143127441\n",
      "layer:57,std:1.09152352809906\n",
      "layer:58,std:1.0926786661148071\n",
      "layer:59,std:1.1082924604415894\n",
      "layer:60,std:1.0973674058914185\n",
      "layer:61,std:1.1131070852279663\n",
      "layer:62,std:1.1269800662994385\n",
      "layer:63,std:1.105078935623169\n",
      "layer:64,std:1.11933434009552\n",
      "layer:65,std:1.107673168182373\n",
      "layer:66,std:1.0577236413955688\n",
      "layer:67,std:1.0925084352493286\n",
      "layer:68,std:1.0222309827804565\n",
      "layer:69,std:0.9999899864196777\n",
      "layer:70,std:1.0062836408615112\n",
      "layer:71,std:0.9985812902450562\n",
      "layer:72,std:0.9506823420524597\n",
      "layer:73,std:0.8901276588439941\n",
      "layer:74,std:0.9016197323799133\n",
      "layer:75,std:0.8844452500343323\n",
      "layer:76,std:0.9308058619499207\n",
      "layer:77,std:0.9354996681213379\n",
      "layer:78,std:0.9386720657348633\n",
      "layer:79,std:0.9390097260475159\n",
      "layer:80,std:0.9343779683113098\n",
      "layer:81,std:0.9169354438781738\n",
      "layer:82,std:0.9285328984260559\n",
      "layer:83,std:0.8952236175537109\n",
      "layer:84,std:0.880452573299408\n",
      "layer:85,std:0.8694000244140625\n",
      "layer:86,std:0.8554130792617798\n",
      "layer:87,std:0.9070701003074646\n",
      "layer:88,std:0.9113261103630066\n",
      "layer:89,std:0.947542667388916\n",
      "layer:90,std:0.9413160085678101\n",
      "layer:91,std:0.9766713976860046\n",
      "layer:92,std:0.9569346308708191\n",
      "layer:93,std:0.9222800731658936\n",
      "layer:94,std:0.9066488742828369\n",
      "layer:95,std:0.9520770311355591\n",
      "layer:96,std:0.9955665469169617\n",
      "layer:97,std:0.988004207611084\n",
      "layer:98,std:0.9774875044822693\n",
      "layer:99,std:0.9819864630699158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9680,  4.9377,  0.5148,  ..., -0.0078, -2.6069, -0.9856],\n",
       "        [-0.5244, -0.2836,  0.5604,  ...,  0.3125,  0.6122,  0.4675],\n",
       "        [ 0.7246,  1.0515,  0.3562,  ...,  0.1150, -0.6337, -0.5806],\n",
       "        ...,\n",
       "        [-0.8396,  0.0318, -0.2757,  ...,  0.1789, -0.0826, -0.3895],\n",
       "        [ 0.2004,  1.5627,  0.3905,  ...,  0.3986, -0.7640,  0.3204],\n",
       "        [-0.1645, -2.7014, -0.2713,  ..., -0.1793,  1.4589,  0.7029]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_nums = 100\n",
    "neural_nums = 256\n",
    "batch_size = 16\n",
    "\n",
    "net = MLP(neural_nums, layer_nums)\n",
    "net.initialize()\n",
    "\n",
    "inputs = torch.randn((batch_size, neural_nums))\n",
    "\n",
    "output = net(inputs)\n",
    "output\n",
    "# 可以看到结果不会出现nan的情况了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1987a02",
   "metadata": {},
   "source": [
    "**采用恰当的权值初始化方法，可以实现多层神经网络的输出值尺度维持在一定范围内，这样反向传播的时候，有利于缓解梯度消失或爆炸**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc2f0f1",
   "metadata": {},
   "source": [
    "当然上面的网络只是线性网络，当存在激活函数时，方差会越来越小，也可能会发生梯度消失现象，这就需要其他的初始化方法。\n",
    "\n",
    "<img style=\"float: center;\" src=\"images/80.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135d4d13",
   "metadata": {},
   "source": [
    "## Xavier初始化\n",
    "\n",
    "**方差一致性：**保持数据尺度维持在恰当的范围，通常方差为1\n",
    "\n",
    "2010年，Xavier发表一篇文章《Understanding the difficulty of training deep feedforward neural networks》，详细探讨有激活函数时，如何进行权重初始化（运用方差一致性原则），但是这里考虑的是**饱和激活函数**（sigmoid，tanh）。\n",
    "\n",
    "推导公式如下：\n",
    "\n",
    "$n_i * D(W) = 1$\n",
    "\n",
    "$n_{i+1} * D(W) = 1$\n",
    "\n",
    "$\\Rightarrow D(W) = \\frac{2}{n_i+n_{i+1}}$\n",
    "\n",
    "这里$n_i, n_{i+1}$分别代表输入层和输出层的神经元个数。\n",
    "\n",
    "Xavier采用均匀分布对权重进行初始化，均匀分布上下限：\n",
    "\n",
    "$W\\sim U[-a, a]$\n",
    "\n",
    "$D(W)=\\frac{(-a-a)^2}{12}=\\frac{(2a)^2}{12}=\\frac{a^2}{3}$\n",
    "\n",
    "综合上面两个$D(W)$公式，可得：\n",
    "\n",
    "$\\frac{2}{n_i+n_{i+1}}=\\frac{a^2}{3} \\Rightarrow a=\\frac{\\sqrt{6}}{\\sqrt{n_i+n{i+1}}}$\n",
    "\n",
    "$W \\sim U\\left[-\\frac{\\sqrt{6}}{\\sqrt{n_i+n{i+1}}}, \\frac{\\sqrt{6}}{\\sqrt{n_i+n{i+1}}}\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba16c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, neural_num, layers):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(neural_num, neural_num, bias=False)\n",
    "                                     for i in range(layers)])\n",
    "        self.neural_num = neural_num\n",
    "    \n",
    "    # 正向传播\n",
    "    def forward(self, x):\n",
    "        for i, linear in enumerate(self.linears):\n",
    "            x = linear(x)\n",
    "            x = torch.tanh(x)\n",
    "        \n",
    "            print(f\"layer:{i},std:{x.std()}\")\n",
    "\n",
    "            if torch.isnan(x.std()):\n",
    "                print(f\"output is nan in {i} layers\")\n",
    "                break\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    # 权值初始化，使用标准正态分布\n",
    "    def initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                # Xavier初始化权重\n",
    "                # nn.init.calculate_gain(nonlinearity, param=None)\n",
    "                # nonlinearity: 激活函数名称，如tanh\n",
    "                # param: 激活函数参数，如Leaky ReLU的negative_slop\n",
    "                # 计算激活函数的方差变化尺度\n",
    "                # 方差变化尺度=输入数据方差/经过激活函数后输出数据方差\n",
    "                tanh_gain = nn.init.calculate_gain('tanh')\n",
    "                nn.init.xavier_uniform_(m.weight.data, gain=tanh_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d662fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:0,std:0.7597724795341492\n",
      "layer:1,std:0.691631019115448\n",
      "layer:2,std:0.6674433350563049\n",
      "layer:3,std:0.6625684499740601\n",
      "layer:4,std:0.6591121554374695\n",
      "layer:5,std:0.6541376113891602\n",
      "layer:6,std:0.657918393611908\n",
      "layer:7,std:0.6530606746673584\n",
      "layer:8,std:0.6525726914405823\n",
      "layer:9,std:0.6433029770851135\n",
      "layer:10,std:0.6500066518783569\n",
      "layer:11,std:0.6507823467254639\n",
      "layer:12,std:0.6547849774360657\n",
      "layer:13,std:0.6571223735809326\n",
      "layer:14,std:0.659264862537384\n",
      "layer:15,std:0.6672247648239136\n",
      "layer:16,std:0.6492877006530762\n",
      "layer:17,std:0.6394469738006592\n",
      "layer:18,std:0.6479735374450684\n",
      "layer:19,std:0.6470638513565063\n",
      "layer:20,std:0.6510664224624634\n",
      "layer:21,std:0.6546648740768433\n",
      "layer:22,std:0.65529865026474\n",
      "layer:23,std:0.6478891968727112\n",
      "layer:24,std:0.6474164724349976\n",
      "layer:25,std:0.6427276730537415\n",
      "layer:26,std:0.6494070887565613\n",
      "layer:27,std:0.6561998128890991\n",
      "layer:28,std:0.6532543301582336\n",
      "layer:29,std:0.661830484867096\n",
      "layer:30,std:0.6557857394218445\n",
      "layer:31,std:0.6537904739379883\n",
      "layer:32,std:0.656227707862854\n",
      "layer:33,std:0.6506802439689636\n",
      "layer:34,std:0.6496101021766663\n",
      "layer:35,std:0.6557678580284119\n",
      "layer:36,std:0.6500595808029175\n",
      "layer:37,std:0.6521593332290649\n",
      "layer:38,std:0.651553213596344\n",
      "layer:39,std:0.6466150879859924\n",
      "layer:40,std:0.6510568261146545\n",
      "layer:41,std:0.654788076877594\n",
      "layer:42,std:0.6466552019119263\n",
      "layer:43,std:0.6537609696388245\n",
      "layer:44,std:0.6563645601272583\n",
      "layer:45,std:0.6501073837280273\n",
      "layer:46,std:0.6501938700675964\n",
      "layer:47,std:0.6432957053184509\n",
      "layer:48,std:0.6485128402709961\n",
      "layer:49,std:0.6536414623260498\n",
      "layer:50,std:0.654007077217102\n",
      "layer:51,std:0.6447455883026123\n",
      "layer:52,std:0.649342954158783\n",
      "layer:53,std:0.6522145867347717\n",
      "layer:54,std:0.6490111351013184\n",
      "layer:55,std:0.6514325141906738\n",
      "layer:56,std:0.6511735320091248\n",
      "layer:57,std:0.6418863534927368\n",
      "layer:58,std:0.6421419978141785\n",
      "layer:59,std:0.6516016721725464\n",
      "layer:60,std:0.6509488821029663\n",
      "layer:61,std:0.651262104511261\n",
      "layer:62,std:0.6476594805717468\n",
      "layer:63,std:0.6444791555404663\n",
      "layer:64,std:0.6441951394081116\n",
      "layer:65,std:0.64732825756073\n",
      "layer:66,std:0.6515068411827087\n",
      "layer:67,std:0.6505234241485596\n",
      "layer:68,std:0.6547790765762329\n",
      "layer:69,std:0.6515485048294067\n",
      "layer:70,std:0.6432332992553711\n",
      "layer:71,std:0.6411123275756836\n",
      "layer:72,std:0.650750458240509\n",
      "layer:73,std:0.6591715216636658\n",
      "layer:74,std:0.6538078188896179\n",
      "layer:75,std:0.6560581922531128\n",
      "layer:76,std:0.6525248289108276\n",
      "layer:77,std:0.6512402892112732\n",
      "layer:78,std:0.6582953929901123\n",
      "layer:79,std:0.650678277015686\n",
      "layer:80,std:0.6488704681396484\n",
      "layer:81,std:0.6515300273895264\n",
      "layer:82,std:0.6494359970092773\n",
      "layer:83,std:0.6486290693283081\n",
      "layer:84,std:0.6540784239768982\n",
      "layer:85,std:0.6551514267921448\n",
      "layer:86,std:0.648684561252594\n",
      "layer:87,std:0.6476866006851196\n",
      "layer:88,std:0.660025954246521\n",
      "layer:89,std:0.6497408747673035\n",
      "layer:90,std:0.6534948348999023\n",
      "layer:91,std:0.66326504945755\n",
      "layer:92,std:0.6596845984458923\n",
      "layer:93,std:0.6552887558937073\n",
      "layer:94,std:0.6470004916191101\n",
      "layer:95,std:0.6516390442848206\n",
      "layer:96,std:0.6514608860015869\n",
      "layer:97,std:0.6517776250839233\n",
      "layer:98,std:0.6443884968757629\n",
      "layer:99,std:0.6506366729736328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1929, -0.9175,  0.6204,  ...,  0.7386,  0.1075, -0.3891],\n",
       "        [-0.3442,  0.8802,  0.1398,  ..., -0.0068, -0.4867, -0.9939],\n",
       "        [-0.5447, -0.8563, -0.9602,  ...,  0.4901,  0.7336,  0.7447],\n",
       "        ...,\n",
       "        [ 0.0184, -0.7887, -0.6479,  ...,  0.7249,  0.4065, -0.9407],\n",
       "        [-0.7349,  0.9036,  0.7570,  ..., -0.7527,  0.1232,  0.7407],\n",
       "        [ 0.2886,  0.6682, -0.8228,  ...,  0.8385, -0.5707, -0.5666]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_nums = 100\n",
    "neural_nums = 256\n",
    "batch_size = 16\n",
    "\n",
    "net = MLP(neural_nums, layer_nums)\n",
    "net.initialize()\n",
    "\n",
    "inputs = torch.randn((batch_size, neural_nums))\n",
    "\n",
    "output = net(inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0648e40",
   "metadata": {},
   "source": [
    "2012年AlexNet出现后，非饱和函数ReLU也用到了神经网络中，然而Xavier初始化对ReLU失效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc965446",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, neural_num, layers):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(neural_num, neural_num, bias=False)\n",
    "                                     for i in range(layers)])\n",
    "        self.neural_num = neural_num\n",
    "    \n",
    "    # 正向传播\n",
    "    def forward(self, x):\n",
    "        for i, linear in enumerate(self.linears):\n",
    "            x = linear(x)\n",
    "            x = torch.relu(x)\n",
    "        \n",
    "            print(f\"layer:{i},std:{x.std()}\")\n",
    "\n",
    "            if torch.isnan(x.std()):\n",
    "                print(f\"output is nan in {i} layers\")\n",
    "                break\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    # 权值初始化，使用标准正态分布\n",
    "    def initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                # Xavier初始化权重\n",
    "                # nn.init.calculate_gain(nonlinearity, param=None)\n",
    "                # nonlinearity: 激活函数名称，如tanh\n",
    "                # param: 激活函数参数，如Leaky ReLU的negative_slop\n",
    "                # 计算激活函数的方差变化尺度\n",
    "                # 方差变化尺度=输入数据方差/经过激活函数后输出数据方差\n",
    "                relu_gain = nn.init.calculate_gain('relu')\n",
    "                nn.init.xavier_uniform_(m.weight.data, gain=relu_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a829a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:0,std:0.8272078633308411\n",
      "layer:1,std:0.8287857174873352\n",
      "layer:2,std:0.8225235342979431\n",
      "layer:3,std:0.8669309020042419\n",
      "layer:4,std:0.8629841208457947\n",
      "layer:5,std:0.9074069857597351\n",
      "layer:6,std:0.8765947222709656\n",
      "layer:7,std:0.8703077435493469\n",
      "layer:8,std:0.8116634488105774\n",
      "layer:9,std:0.8748800158500671\n",
      "layer:10,std:0.9287486672401428\n",
      "layer:11,std:1.0342388153076172\n",
      "layer:12,std:1.1486414670944214\n",
      "layer:13,std:1.139365553855896\n",
      "layer:14,std:1.1594090461730957\n",
      "layer:15,std:1.2147501707077026\n",
      "layer:16,std:1.166542410850525\n",
      "layer:17,std:1.162285327911377\n",
      "layer:18,std:1.1240496635437012\n",
      "layer:19,std:1.068245768547058\n",
      "layer:20,std:1.2006644010543823\n",
      "layer:21,std:1.240335464477539\n",
      "layer:22,std:1.4015294313430786\n",
      "layer:23,std:1.388387680053711\n",
      "layer:24,std:1.5033951997756958\n",
      "layer:25,std:1.641709804534912\n",
      "layer:26,std:1.3320049047470093\n",
      "layer:27,std:1.3643521070480347\n",
      "layer:28,std:1.3563874959945679\n",
      "layer:29,std:1.3409533500671387\n",
      "layer:30,std:1.400130271911621\n",
      "layer:31,std:1.5035147666931152\n",
      "layer:32,std:1.3495123386383057\n",
      "layer:33,std:1.2657448053359985\n",
      "layer:34,std:1.1944173574447632\n",
      "layer:35,std:1.2399741411209106\n",
      "layer:36,std:1.231257677078247\n",
      "layer:37,std:1.29042387008667\n",
      "layer:38,std:1.1970957517623901\n",
      "layer:39,std:1.1451598405838013\n",
      "layer:40,std:0.9884290099143982\n",
      "layer:41,std:0.9283195734024048\n",
      "layer:42,std:0.9223325252532959\n",
      "layer:43,std:0.9996013045310974\n",
      "layer:44,std:0.9302466511726379\n",
      "layer:45,std:0.8909880518913269\n",
      "layer:46,std:0.8803624510765076\n",
      "layer:47,std:0.7954410910606384\n",
      "layer:48,std:0.9457122683525085\n",
      "layer:49,std:0.9323951601982117\n",
      "layer:50,std:0.8926051259040833\n",
      "layer:51,std:1.025672197341919\n",
      "layer:52,std:0.9561845064163208\n",
      "layer:53,std:0.9628527164459229\n",
      "layer:54,std:0.8970843553543091\n",
      "layer:55,std:0.9346036911010742\n",
      "layer:56,std:0.9427918791770935\n",
      "layer:57,std:0.8483654856681824\n",
      "layer:58,std:0.9862955212593079\n",
      "layer:59,std:1.142346739768982\n",
      "layer:60,std:1.1444506645202637\n",
      "layer:61,std:1.24971342086792\n",
      "layer:62,std:1.2312647104263306\n",
      "layer:63,std:1.2142747640609741\n",
      "layer:64,std:1.2427897453308105\n",
      "layer:65,std:1.3307039737701416\n",
      "layer:66,std:1.3171392679214478\n",
      "layer:67,std:1.4062923192977905\n",
      "layer:68,std:1.5320764780044556\n",
      "layer:69,std:1.443307876586914\n",
      "layer:70,std:1.351259708404541\n",
      "layer:71,std:1.4261504411697388\n",
      "layer:72,std:1.3919895887374878\n",
      "layer:73,std:1.3359216451644897\n",
      "layer:74,std:1.4403564929962158\n",
      "layer:75,std:1.5190062522888184\n",
      "layer:76,std:1.6249046325683594\n",
      "layer:77,std:1.573883295059204\n",
      "layer:78,std:1.396878957748413\n",
      "layer:79,std:1.342642068862915\n",
      "layer:80,std:1.2774956226348877\n",
      "layer:81,std:1.2230138778686523\n",
      "layer:82,std:1.2296456098556519\n",
      "layer:83,std:1.102856159210205\n",
      "layer:84,std:1.1394715309143066\n",
      "layer:85,std:1.1058297157287598\n",
      "layer:86,std:1.1072354316711426\n",
      "layer:87,std:1.139025092124939\n",
      "layer:88,std:1.173694133758545\n",
      "layer:89,std:1.1337342262268066\n",
      "layer:90,std:1.124815821647644\n",
      "layer:91,std:0.9987770318984985\n",
      "layer:92,std:0.945033848285675\n",
      "layer:93,std:1.0050511360168457\n",
      "layer:94,std:0.997078537940979\n",
      "layer:95,std:0.9502992033958435\n",
      "layer:96,std:0.9973101019859314\n",
      "layer:97,std:1.0404813289642334\n",
      "layer:98,std:1.130167841911316\n",
      "layer:99,std:1.2186671495437622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.3819, 0.3579,  ..., 3.7246, 1.9951, 3.3243],\n",
       "        [0.0000, 1.3031, 0.2963,  ..., 3.7317, 1.8890, 3.2710],\n",
       "        [0.0000, 0.8254, 0.2258,  ..., 2.1510, 1.1945, 1.9262],\n",
       "        ...,\n",
       "        [0.0000, 0.9481, 0.2314,  ..., 2.2969, 1.3180, 2.1258],\n",
       "        [0.0000, 0.9808, 0.2747,  ..., 2.4863, 1.3197, 2.1989],\n",
       "        [0.0000, 0.6398, 0.1703,  ..., 1.6777, 0.8792, 1.4625]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_nums = 100\n",
    "neural_nums = 256\n",
    "batch_size = 16\n",
    "\n",
    "net = MLP(neural_nums, layer_nums)\n",
    "net.initialize()\n",
    "\n",
    "inputs = torch.randn((batch_size, neural_nums))\n",
    "\n",
    "output = net(inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38530f84",
   "metadata": {},
   "source": [
    "## Kaiming初始化\n",
    "\n",
    "遵循：方差一致性原则\n",
    "\n",
    "针对：ReLU激活函数及其变种\n",
    "\n",
    "最后权重标准差：\n",
    "\n",
    "$D(W)=\\frac{2}{n_i}$\n",
    "\n",
    "$D(W)=\\frac{2}{\\left(1+a^2\\right)*n_i}$\n",
    "\n",
    "$D(W)=\\sqrt{\\frac{2}{\\left(1+a^2\\right)*n_i}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c437458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, neural_num, layers):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(neural_num, neural_num, bias=False)\n",
    "                                     for i in range(layers)])\n",
    "        self.neural_num = neural_num\n",
    "    \n",
    "    # 正向传播\n",
    "    def forward(self, x):\n",
    "        for i, linear in enumerate(self.linears):\n",
    "            x = linear(x)\n",
    "            x = torch.relu(x)\n",
    "        \n",
    "            print(f\"layer:{i},std:{x.std()}\")\n",
    "\n",
    "            if torch.isnan(x.std()):\n",
    "                print(f\"output is nan in {i} layers\")\n",
    "                break\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    # 权值初始化，使用标准正态分布\n",
    "    def initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "141a6108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:0,std:0.8194370865821838\n",
      "layer:1,std:0.7863913774490356\n",
      "layer:2,std:0.7790502905845642\n",
      "layer:3,std:0.7336016297340393\n",
      "layer:4,std:0.721562385559082\n",
      "layer:5,std:0.719891369342804\n",
      "layer:6,std:0.7007282376289368\n",
      "layer:7,std:0.63581383228302\n",
      "layer:8,std:0.6558110117912292\n",
      "layer:9,std:0.6231154799461365\n",
      "layer:10,std:0.6212367415428162\n",
      "layer:11,std:0.5692794322967529\n",
      "layer:12,std:0.5806706547737122\n",
      "layer:13,std:0.5602917671203613\n",
      "layer:14,std:0.5692883729934692\n",
      "layer:15,std:0.5992907881736755\n",
      "layer:16,std:0.5045601725578308\n",
      "layer:17,std:0.5361236333847046\n",
      "layer:18,std:0.545310378074646\n",
      "layer:19,std:0.487845242023468\n",
      "layer:20,std:0.44877204298973083\n",
      "layer:21,std:0.41723302006721497\n",
      "layer:22,std:0.4157910645008087\n",
      "layer:23,std:0.42320042848587036\n",
      "layer:24,std:0.47227609157562256\n",
      "layer:25,std:0.4711170196533203\n",
      "layer:26,std:0.47471195459365845\n",
      "layer:27,std:0.4232582449913025\n",
      "layer:28,std:0.38460591435432434\n",
      "layer:29,std:0.38494592905044556\n",
      "layer:30,std:0.4043668508529663\n",
      "layer:31,std:0.37478581070899963\n",
      "layer:32,std:0.3947143256664276\n",
      "layer:33,std:0.39059972763061523\n",
      "layer:34,std:0.36845478415489197\n",
      "layer:35,std:0.3625209629535675\n",
      "layer:36,std:0.40180644392967224\n",
      "layer:37,std:0.3876851201057434\n",
      "layer:38,std:0.40263500809669495\n",
      "layer:39,std:0.36473730206489563\n",
      "layer:40,std:0.35032176971435547\n",
      "layer:41,std:0.3394170105457306\n",
      "layer:42,std:0.38269588351249695\n",
      "layer:43,std:0.3828835189342499\n",
      "layer:44,std:0.40331628918647766\n",
      "layer:45,std:0.42746999859809875\n",
      "layer:46,std:0.38934192061424255\n",
      "layer:47,std:0.37067610025405884\n",
      "layer:48,std:0.3949563205242157\n",
      "layer:49,std:0.4124741852283478\n",
      "layer:50,std:0.3973097801208496\n",
      "layer:51,std:0.41777604818344116\n",
      "layer:52,std:0.4143185317516327\n",
      "layer:53,std:0.3574855625629425\n",
      "layer:54,std:0.3778553903102875\n",
      "layer:55,std:0.3602222800254822\n",
      "layer:56,std:0.38216903805732727\n",
      "layer:57,std:0.3733018636703491\n",
      "layer:58,std:0.3589566648006439\n",
      "layer:59,std:0.3166232109069824\n",
      "layer:60,std:0.3165280520915985\n",
      "layer:61,std:0.30133262276649475\n",
      "layer:62,std:0.30529460310935974\n",
      "layer:63,std:0.3400013744831085\n",
      "layer:64,std:0.32361289858818054\n",
      "layer:65,std:0.33682623505592346\n",
      "layer:66,std:0.36145010590553284\n",
      "layer:67,std:0.36624953150749207\n",
      "layer:68,std:0.38981005549430847\n",
      "layer:69,std:0.42717793583869934\n",
      "layer:70,std:0.4094310700893402\n",
      "layer:71,std:0.4472016394138336\n",
      "layer:72,std:0.46282657980918884\n",
      "layer:73,std:0.4261879622936249\n",
      "layer:74,std:0.44930386543273926\n",
      "layer:75,std:0.49281740188598633\n",
      "layer:76,std:0.4218135476112366\n",
      "layer:77,std:0.43965449929237366\n",
      "layer:78,std:0.40461844205856323\n",
      "layer:79,std:0.4176812767982483\n",
      "layer:80,std:0.42882904410362244\n",
      "layer:81,std:0.4693719446659088\n",
      "layer:82,std:0.5089121460914612\n",
      "layer:83,std:0.5548104643821716\n",
      "layer:84,std:0.5388063788414001\n",
      "layer:85,std:0.5282326340675354\n",
      "layer:86,std:0.5137163400650024\n",
      "layer:87,std:0.5575731992721558\n",
      "layer:88,std:0.5769453048706055\n",
      "layer:89,std:0.5674256086349487\n",
      "layer:90,std:0.6010963916778564\n",
      "layer:91,std:0.6305368542671204\n",
      "layer:92,std:0.6199750900268555\n",
      "layer:93,std:0.6703606247901917\n",
      "layer:94,std:0.6461126208305359\n",
      "layer:95,std:0.6380062699317932\n",
      "layer:96,std:0.6042025089263916\n",
      "layer:97,std:0.5881716012954712\n",
      "layer:98,std:0.5057284235954285\n",
      "layer:99,std:0.4766100347042084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.8185, 0.4060,  ..., 1.9074, 0.4009, 1.4617],\n",
       "        [0.0000, 1.2005, 0.3790,  ..., 1.2151, 0.4098, 0.9926],\n",
       "        [0.0000, 1.7457, 0.4749,  ..., 1.8213, 0.4690, 1.4190],\n",
       "        ...,\n",
       "        [0.0000, 2.0995, 0.5222,  ..., 2.2139, 0.6825, 1.7255],\n",
       "        [0.0000, 0.8958, 0.3022,  ..., 0.9257, 0.3139, 0.7616],\n",
       "        [0.0000, 1.2969, 0.3834,  ..., 1.2798, 0.4639, 1.0696]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_nums = 100\n",
    "neural_nums = 256\n",
    "batch_size = 16\n",
    "\n",
    "net = MLP(neural_nums, layer_nums)\n",
    "net.initialize()\n",
    "\n",
    "inputs = torch.randn((batch_size, neural_nums))\n",
    "\n",
    "output = net(inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05580120",
   "metadata": {},
   "source": [
    "## 十种权重初始化方法\n",
    "\n",
    "PyTorch提供4大类权重初始化方法：\n",
    "- 针对饱和激活函数（sigmoid，tanh）：Xavier均匀分布，Xavier正态分布\n",
    "- 针对非饱和激活函数（relu及其变种）：Kaiming均匀分布，Kaiming正态分布\n",
    "- 常用的分布初始化方法：均匀分布，正态分布，常数分布\n",
    "- 特殊的矩阵初始化方法：正交矩阵初始化，单位矩阵初始化，稀疏矩阵初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a85701",
   "metadata": {},
   "source": [
    "# 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3af4ad",
   "metadata": {},
   "source": [
    "## 简介\n",
    "\n",
    "损失函数：衡量模型与真实标签的差异。\n",
    "\n",
    "- 损失函数Loss Function：计算一个样本的一个差异。$Loss=f(\\hat{y},y)$\n",
    "- 代价函数Cost Function：计算整个训练集Loss的平均值。$Cost=\\frac{1}{N}\\sum^N_i f(\\hat{y}, y)$\n",
    "- 目标函数Objective Function：模型训练的最终目标，过拟合与欠拟合之间权衡。$Obj=Cost+Regularization$\n",
    "\n",
    "一般在衡量模型输出和真实标签差异时，往往用损失函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5428af8f",
   "metadata": {},
   "source": [
    "PyTorch中损失函数：\n",
    "<img style=\"float: center;\" src=\"images/81.png\" width=\"70%\">\n",
    "\n",
    "\\_Loss也是继承Module，因此也包含8个参数字典，同时需要设置一个reduction参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e69835",
   "metadata": {},
   "source": [
    "以人民币二分类为例：\n",
    "\n",
    "先在定义损失函数和使用损失函数的地方打上断点：\n",
    "<img style=\"float: center;\" src=\"images/82.png\" width=\"70%\">\n",
    "\n",
    "**损失函数定义过程**\n",
    "\n",
    "程序运行到第一个断点处，进入loss.py文件中的一个class CrossEntropyLoss(\\_WeightedLoss)：交叉熵损失类的\\_\\_init\\_\\_方法，可以发现交叉熵损失函数继承\\_WeightedLoss类：\n",
    "<img style=\"float: center;\" src=\"images/83.png\" width=\"70%\">\n",
    "\n",
    "继续步入，进入class \\_WeightedLoss(\\_Loss)类中，继承\\_Loss类，继续步入\\_Loss类，继承Module，因此损失函数的初始化方法和模型类似，也是调用Module的初始化方法，最终会有8个属性字典，然后设置reduction参数。\n",
    "\n",
    "**损失函数使用过程**\n",
    "\n",
    "进入第二个断点，步入，由于损失函数也是一个Module，因此调用时也是调用forward方法：\n",
    "<img style=\"float: center;\" src=\"images/84.png\" width=\"70%\">\n",
    "\n",
    "再次步入，可以看到损失函数中的forward样子，在模型构建里的forward写的是各个模块的拼接方式，而损失函数的forward里调用F里的各种函数，进入该函数，可以看到交叉熵损失函数：\n",
    "<img style=\"float: center;\" src=\"images/85.png\" width=\"70%\">\n",
    "<img style=\"float: center;\" src=\"images/86.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ea9c5",
   "metadata": {},
   "source": [
    "以上就是损失函数初始化和使用方法的内部运行机制。\n",
    "\n",
    "损失函数其实也是一个Module，初始化依然有8个属性字典，使用方法定义在forward函数中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a81c3f",
   "metadata": {},
   "source": [
    "## 交叉熵损失CrossEntropyLoss\n",
    "\n",
    "nn.CrossEntropyLoss：nn.LogSortmax()与nn.NLLLoss()结合，进行交叉熵计算。\n",
    "\n",
    "nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
    "\n",
    "- weight：各类别loss设置权重\n",
    "- ignore_index：忽略某个类别\n",
    "- reduction：计算模式\n",
    "  - none：逐元素计算，多少个样本返回多少个loss\n",
    "  - sum：所有元素loss求和，返回标量\n",
    "  - mean：所有元素loss求加权平均，返回标量\n",
    "\n",
    "交叉熵损失函数：$H(P,Q)=-\\sum^N_{i=1}P(x_i)\\log Q(x_i)$\n",
    "- P表示数据的原始分布\n",
    "- Q表示模型的输出分布\n",
    "\n",
    "交叉熵损失衡量两个分布之间的差异程度，交叉熵越低，说明两个分布越接近。\n",
    "\n",
    "PyTorch中交叉熵损失先用nn.LogSoftmax()把模型的输出值归一化成概率分布形式，然后用单个样本输出，并且没有求和符号。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8fbde3",
   "metadata": {},
   "source": [
    "为什么交叉熵损失能衡量两个分布之间的差异？\n",
    "\n",
    "熵：信息论之父香农从热力学借鉴来的名词，用于描述事件的不确定性，事物的不确定性越大，则熵就越大。（例如，明天会下雨的熵就比明天太阳从东边升起的熵要大）\n",
    "\n",
    "熵的公式：$H(P)=E_{x\\sim p}[I(x)]=-\\sum^N_{i=0}P(x_i)\\log P(x_i)$\n",
    "\n",
    "熵是自信息的期望，自信息：$I(x)=-\\log p(x)$，一个事件发生的概率，然后取对数再取反，即一个事件发生的概率越大，则自信息越少。所有事件发生的概率都很大，则熵就会小，事件的不确定性就小。\n",
    "\n",
    "下图是一个两点分布的信息熵，当概率是0.5时熵最大，即事件的不确定性最大，熵大约是0.69（二分类模型中，模型训练坏了，或者刚训练时，Loss的值可能为0.69，这时候就说模型目前没有任何判断能力）\n",
    "<img style=\"float: center;\" src=\"images/87.png\" width=\"70%\">\n",
    "\n",
    "**相对熵**又称KL散度，用于衡量两个分布之间的差异（距离），但不是一个距离函数（因为距离函数具有对称性，即p到q的距离等于q到p的距离）：\n",
    "\n",
    "$D_{KL}(P,Q)$\n",
    "\n",
    "$=E_{x\\sim p}\\left[\\log\\frac{P(x)}{Q(x)}\\right]$\n",
    "\n",
    "$=E_{x\\sim p}\\left[\\log{P(x_i)}-\\log{Q(x_i)}\\right]$\n",
    "\n",
    "$=\\sum^N_{i=1}P(x_i)\\left[\\log{P(x_i)}-\\log{Q(x_i)}\\right]$\n",
    "\n",
    "$=\\sum^N_{i=1}P(x_i)\\log{P(x_i)}-\\sum^N_{i=1}P(x_i)\\log{Q(x_i)}$\n",
    "\n",
    "这里$P$是数据的真实分布，$Q$是模型输出的分布，此处就是用$Q$的分布去逼近$P$的分布。（因此不具备对称性）\n",
    "\n",
    "**交叉熵**：交叉熵=信息熵+相对熵\n",
    "\n",
    "$H(P,Q)=-\\sum^N_{i=1}P(x_i)\\log Q(x_i)$\n",
    "\n",
    "即，$H(P,Q)=D_{KL}(P,Q)+H(P)$\n",
    "\n",
    "机器学习中，最小化交叉熵，就是最小化相对熵，因为训练集取出来之后，信息熵就固定了。\n",
    "\n",
    "softmax可以将一个输出值转换到概率取值的一个范围：\n",
    "\n",
    "$loss(x, class)=-\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])}\n",
    "\\right)=-x[class]+\\log\\left(\\sum_j\\exp(x[j])\\right)$\n",
    "\n",
    "此处x为输出概率值，class为某一类别，括号里执行一个softmax，把某个神经元的输出归一化成概率取值，然后$-\\log$一下，就得到交叉熵损失函数。\n",
    "\n",
    "对比交叉熵公式：$H(P,Q)=-\\sum^N_{i=1}P(x_i)\\log Q(x_i)$\n",
    "\n",
    "由于是某个样本，则$P(x_i)$是1（因为已经取出来了），而是某个样本，也不用求和符号。这就是用softmax的原因，把模型的输出值转成概率分布形式，得到交叉熵损失函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eb1ddb",
   "metadata": {},
   "source": [
    "之后说一下参数：\n",
    "\n",
    "nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
    "- weight：各类别loss设置权值，如果类别不均衡则这个参数就很重要：\n",
    "  - $loss(x, class)=weight[class]\\left((-x[class]+\\log\\left(\\sum_j\\exp(x[j])\\right)\\right)$\n",
    "  - 如果想让模型更关注某一个类，可以把这一类的权值设置的更大一点。\n",
    "- ignore_index：表示某个类别不计算loss\n",
    "- reduction：3个计算模式none/sum/mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac903d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss:\n",
      "  tensor([1.3133, 0.1269, 0.1269]) tensor(1.5671) tensor(0.5224)\n"
     ]
    }
   ],
   "source": [
    "# 模型预测的输出\n",
    "# 两个类，可以看到模型输出是数值，得softmax转成分布\n",
    "inputs = torch.tensor([[1, 2], [1, 3], [1, 3]], dtype=torch.float) \n",
    "# 这里的类型必须是long，两个类0和1\n",
    "target = torch.tensor([0, 1, 1], dtype=torch.long)\n",
    "\n",
    "# 三种模式的损失函数\n",
    "loss_f_none = nn.CrossEntropyLoss(weight=None, reduction='none')\n",
    "loss_f_sum = nn.CrossEntropyLoss(weight=None, reduction='sum')\n",
    "loss_f_mean = nn.CrossEntropyLoss(weight=None, reduction='mean')\n",
    "\n",
    "# forward\n",
    "loss_none = loss_f_none(inputs, target)\n",
    "loss_sum = loss_f_sum(inputs, target)\n",
    "loss_mean = loss_f_mean(inputs, target)\n",
    "\n",
    "# view\n",
    "print(\"Cross Entropy Loss:\\n \", loss_none, loss_sum, loss_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25bfa9",
   "metadata": {},
   "source": [
    "weight损失，给类别加上权值后，对应样本的损失就会相应加倍\n",
    "\n",
    "关于mean模式loss计算：三个样本，第一个权值1，后两个权值2，分母变为1+2+2=5，所以mean模式下求平均不是除以样本的个数，而是样本所占权值的总份数。\n",
    "<img style=\"float: center;\" src=\"images/88.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8233f416",
   "metadata": {},
   "source": [
    "### 交叉熵损失函数的特例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddef2ff1",
   "metadata": {},
   "source": [
    "#### nn.NLLLoss\n",
    "\n",
    "上面的交叉熵损失中，发现是softmax和NLLLoss组合。\n",
    "\n",
    "此处nn.NLLLoss其实只是实现了一个负号功能\n",
    "\n",
    "nn.NLLLoss：实现负对数似然函数里的负号功能\n",
    "\n",
    "nn.NLLLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
    "<img style=\"float: center;\" src=\"images/89.png\" width=\"70%\">\n",
    "\n",
    "这个损失函数根据真实类别去获取相应的softmax之后的概率结果，然后取反得到最终损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b85a30f",
   "metadata": {},
   "source": [
    "#### nn.BCELoss\n",
    "\n",
    "二分类交叉熵：输入取值[0,1]\n",
    "\n",
    "nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "计算公式：$l_n=-w_n\\left[y_n*\\log x_n+(1-y_n)*\\log(1-x_n)\\right]$\n",
    "<img style=\"float: center;\" src=\"images/90.png\" width=\"70%\">\n",
    "\n",
    "注意这里target的类型是float，每个样本属于哪一类需要写成独热编码（每个神经元一一对应去计算loss，而不是一整个神经元向量去计算loss）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8b38b7",
   "metadata": {},
   "source": [
    "#### nn.BCEWithLogitsLoss\n",
    "\n",
    "该函数结合Sigmoid和二分类交叉熵（注意，网络最后不加sigmoid函数）\n",
    "\n",
    "nn.BCEWithLogitsLoss(weight=None, size_average=None, reduce=None, reduction='mean', pos_weight=None)\n",
    "\n",
    "这里参数多了一个pow_weight，主要用于平衡正负样本，对正样本进行一个权值设定。（例如正样本有100个，负样本有300个，则该数可以设为3）\n",
    "\n",
    "计算公式：$l_n=-w_n\\left[y_n*\\log\\sigma(x_n)+(1-y_n)*\\log(1-\\sigma(x_n))\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca32a79b",
   "metadata": {},
   "source": [
    "## 14种损失函数\n",
    "\n",
    "- 分类问题\n",
    "  - 二分类单标签问题：nn.BCELoss, nn.BCEWithLogitsLoss, nn.SoftMarginLoss\n",
    "  - 二分类多标签问题：nn.MultiLabelSoftMarginLoss\n",
    "  - 多分类单标签问题: nn.CrossEntropyLoss, nn.NLLLoss, nn.MultiMarginLoss\n",
    "  - 多分类多标签问题: nn.MultiLabelMarginLoss,\n",
    "  - 不常用：nn.PoissonNLLLoss, nn.KLDivLoss\n",
    "- 回归问题: nn.L1Loss, nn.MSELoss, nn.SmoothL1Loss\n",
    "- 时序问题：nn.CTCLoss\n",
    "- 人脸识别问题：nn.TripletMarginLoss\n",
    "- 半监督Embedding问题(输入之间的相似性): nn.MarginRankingLoss, nn.HingeEmbeddingLoss, nn.CosineEmbeddingLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e271b27e",
   "metadata": {},
   "source": [
    "### nn.L1Loss\n",
    "\n",
    "用于回归问题，计算inputs与target之差的绝对值\n",
    "\n",
    "nn.L1Loss(size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "计算公式：$l_n=|x_n-y_n|$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28e417a",
   "metadata": {},
   "source": [
    "### nn.MSE\n",
    "\n",
    "用于回归问题，计算inputs与target之差的平方\n",
    "\n",
    "nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "计算公式：$l_n=(x_n-y_n)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40de46b",
   "metadata": {},
   "source": [
    "### nn.SmoothL1Loss\n",
    "\n",
    "平滑的L1Loss（回归问题）\n",
    "\n",
    "nn.SmoothL1Loss(size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "计算公式：$loss(x,y)=\\frac{1}{n}\\sum_iz_i$\n",
    "\n",
    "$\n",
    "z_i=\n",
    "\\left\\{ \n",
    "\\begin{aligned}\n",
    "0.5(x_i-y_i)^2, |x_i-y_i|\\lt 1\\\\ \n",
    "|x_i-y_i|-0.5, |x_i-y_i|\\ge 1\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$\n",
    "\n",
    "采用这种平滑损失函数可以减轻离群点带来的影响\n",
    "<img style=\"float: center;\" src=\"images/91.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8546c789",
   "metadata": {},
   "source": [
    "### nn.PoissonNLLLoss\n",
    "\n",
    "泊松分布的负对数似然损失函数（分类里如果发现数据的类别服从泊松分布，可以用这个损失函数）\n",
    "\n",
    "nn.PoissonNLLLoss(log_input=True, full=False, size_average=None, eps=1e-8, reduce=None, reduction='mean')\n",
    "- log_input：输入是否为对数形式\n",
    "  - 若为True：$loss(input,target)=\\exp(input)-target\\times input$\n",
    "  - 若为False：$loss(input,target)=input-target\\times \\log(input+eps)$\n",
    "- full：计算所有loss，默认为False\n",
    "- eps：修正项，避免log(input)为nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836b2946",
   "metadata": {},
   "source": [
    "### nn.KLDivLoss\n",
    "\n",
    "计算KLD，KL散度，相对熵。\n",
    "\n",
    "**注意：需要提前将输入计算log-probabilities，例如通过nn.logsoftmax**\n",
    "\n",
    "nn.KLDivLoss(size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "<img style=\"float: center;\" src=\"images/92.png\" width=\"70%\">\n",
    "\n",
    "上面PyTorch里的计算与我们原来公式里的计算有点不一样，需要先logsoftmax()，完成转换为分布然后转成对数才可以。\n",
    "\n",
    "此处reduction还多了一种计算模式'batchmean'，按照batchsize大小求平均值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2539e0f7",
   "metadata": {},
   "source": [
    "### nn.MarginRankingLoss\n",
    "\n",
    "计算两个向量之间的相似度，用于排序任务。\n",
    "\n",
    "该方法计算两组数据之间的差异，即每个元素两两之间都会计算差异，返回一个n\\*n的loss矩阵，类似于相关性矩阵。\n",
    "\n",
    "nn.MarginRankingLoss(margin=0.0, size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "margin表示边界值，x1与x2之间的差异值。\n",
    "\n",
    "计算公式：$loss(x,y)=\\max(0, -y*(x_1-x_2)+margin)$\n",
    "- y=1时，希望x1比x2大，当x1>x2时，不产生loss\n",
    "- y=-1时，希望x2比x1大，当x2>x1时，不产生loss\n",
    "\n",
    "<img style=\"float: center;\" src=\"images/93.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308cb007",
   "metadata": {},
   "source": [
    "### nn.MultiLabelMarginLoss\n",
    "\n",
    "多标签边界损失函数，多标签分类，一个样本可能属于多个标签，与多分类任务不一样（多标签问题）。\n",
    "\n",
    "nn.MultiLabelMarginLoss(size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "计算公式：$loss(x,y)=\\sum_{i,j}\\frac{max(0, 1-(x[y[j]]-x[i]))}{x.size(0)}$\n",
    "，\n",
    "此处i的取值从0到输出的维度减1，j的取值也是0到输出的维度减1，对于所有的i和j，i不等于y[j]，即标签所在神经元减去那些非标签所在神经元。\n",
    "<img style=\"float: center;\" src=\"images/94.png\" width=\"70%\">\n",
    "\n",
    "假设有一个训练样本，输出层4个神经元（4分类问题），前向传播后，神经网络的四个神经元输出分布是[0.1, 0.2, 0.4, 0.8]，而这个样本的真实标签是[0, 3, -1, -1]，这说明该样本属于第0类和第3类（必须为torch.long型），并且必须和输出神经元个数一样，属于哪几类写再前面，不足用-1填补。\n",
    "\n",
    "使用多标签边界损失函数时，具体计算如下：\n",
    "\n",
    "输入样本属于0和3这两类，不属于1和2，根据上述公式，后面那部分是标签所在的神经元减去标签不在的神经元，比如标签在第0个神经元：\n",
    "- item_1=(1-(x[0]-x[1]))+(1-(x[0]-x[2]))  # 标签在第0个神经元\n",
    "- item_2=(1-(x[3]-x[1]))+(1-(x[3]-x[2]))  # 标签在第3个神经元\n",
    "- 两部分损失相加除以总的神经元个数：loss=(item_1+item_3)/x.shape[0]\n",
    "\n",
    "希望标签所在神经元要比非标签所在神经元的输出值要尽量的大：\n",
    "- 当这个差大于1时，根据max(0, 1-差值)才发现不会有损失产生\n",
    "- 当这个差小或非标签所在的神经元比标签所在神经元大的时候，就会产生损失\n",
    "\n",
    "因此，上面那个例子，要让第0个神经元的值比第1/2个大一些，第3个神经元的值比第1/2个大一些，才能说明这个样本属于第0类和第3类。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1f1168",
   "metadata": {},
   "source": [
    "### nn.SoftMarginLoss\n",
    "\n",
    "计算二分类的logistic损失（二分类问题）\n",
    "\n",
    "nn.SoftMarginLoss(size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "计算公式：$loss(x,y)=\\sum_i\\frac{\\log(1+\\exp(-y[i]*x[i]))}{x.nelement()}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c19d96",
   "metadata": {},
   "source": [
    "### nn.MultiLabelSortMarginLoss\n",
    "\n",
    "SoftMarginLoss多标签版本（多标签问题）\n",
    "\n",
    "nn.MultiLabelSoftMarginLoss(weight=None, size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "weight表示各类别的loss设置权值\n",
    "\n",
    "计算公式：$loss(x,y)=-\\frac{1}{C}*\\sum_i y[i] * \\log\\left((1+\\exp(-x[i]))^{-1}\\right)+(1-y[i])*\\log\\left(\\frac{\\exp(-x[i])}{(1+\\exp(-x[i]))})\\right)$\n",
    "\n",
    "以三分类任务为例，输入的这个样本属于第二类和第三类：\n",
    "<img style=\"float: center;\" src=\"images/95.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeebcde2",
   "metadata": {},
   "source": [
    "### nn.MultiMarginLoss(hingLoss)\n",
    "\n",
    "计算多分类的折页损失（多分类问题）\n",
    "\n",
    "nn.MultiMarginLoss(p=1, margin=1.0, weight=None, size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "此处p可选1或2，margin表示边界值\n",
    "\n",
    "计算公式：$loss(x,y)=\\frac{\\sum_i\\max(0, margin-x[y]+x[i])^p}{x.size(0)}$\n",
    "\n",
    "此处x，y是[0, 神经元个数-1]，对于所有i和j，i不等于y[j]。\n",
    "\n",
    "这里就类似于hing loss，x[y]表示标签所在的神经元，x[i]表示非标签所在神经元。\n",
    "<img style=\"float: center;\" src=\"images/96.png\" width=\"70%\">\n",
    "\n",
    "这个其实与多标签边界损失函数原理差不多，只不过那里是一个样本属于多个类，需要每个类都这样计算，而这里一个样本属于1个类，只需要计算一次即可。\n",
    "<img style=\"float: center;\" src=\"images/97.png\" width=\"70%\">\n",
    "\n",
    "假设现在有3个类别，得分函数计算某张图片的得分为$f(x_i,w)=[13, -7, 11]$，而实际结果是第一类($y_i=0$)，假设$\\triangle=10$，这个是margin，则上面的公式就把错误类别($j\\ne y_i$)都遍历了一遍，求值加和：$L_i=\\max(0, -7-13+10)+\\max(0, 11-13+10)$\n",
    "\n",
    "这个损失和交叉熵损失是不同的两种评判标准：\n",
    "- 多分类折页损失聚焦于分类错误的与正确类别之间的惩罚距离越小越好\n",
    "- 交叉熵损失聚焦分类正确的概率分布越大越好"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9509e1ca",
   "metadata": {},
   "source": [
    "### nn.TripletMarginLoss\n",
    "\n",
    "计算三元组损失，人脸验证中常用\n",
    "\n",
    "nn.TripleMarginLoss(margin=1.0, p=2.0, eps=1e-6, swap=False, size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "此处p表示范数的阶。\n",
    "\n",
    "计算公式：$L(a,p,n)=\\max(d(a_i,p_i)-d(a_i,n_i)+margin, 0)$\n",
    "\n",
    "在人脸识别训练模型时，往往需要把训练集做成三元组(A, P, N)，A和P是同一个人，A和N不是同一个人，然后训练我们的模型\n",
    "\n",
    "让模型把A和P看成一样，争取让A和P之间的距离小，而A和N之间的距离大，则模型就可以进行人脸识别任务了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797c0cbd",
   "metadata": {},
   "source": [
    "### nn.HingeEmbeddingLoss\n",
    "\n",
    "计算两个输入的相似性，常用于非线性embedding和半监督学习\n",
    "\n",
    "注意：输入的x应为两个输入之差的绝对值，即手动计算两个输入的差值\n",
    "\n",
    "nn.HingeEmbeddingLoss(margin=1.0, size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "计算公式：\n",
    "$\n",
    "l_n=\n",
    "\\left\\{ \n",
    "\\begin{aligned}\n",
    "x_n, y_n = 1\\\\ \n",
    "\\max(0, \\triangle - x_n), y_n=-1\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d712f",
   "metadata": {},
   "source": [
    "### nn.CosineEmbeddingLoss\n",
    "\n",
    "采用余弦相似度计算两个输入的相似性，常用于半监督学习和embedding\n",
    "\n",
    "nn.CosineEmbeddingLoss(margin=0.0, size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "此处margin可取值[-1,1]，推荐为[0,0.5]，计算公式：\n",
    "\n",
    "$\n",
    "loss(x,y)=\n",
    "\\left\\{ \n",
    "\\begin{aligned}\n",
    "1-\\cos(x_1,x_2), y_n = 1\\\\ \n",
    "\\max(0, \\cos(x_1,x_2)-margin), y_n=-1\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$\n",
    "\n",
    "之所以用cos，希望关注于这两个输入方向上的一个差异，而不是距离上的差异，cos函数如下：\n",
    "\n",
    "$\\cos(\\theta)=\\frac{A\\cdot B}{\\|A\\|\\|B\\|}=\\frac{\\sum^n_{i=1}A_i\\times B_i}{\\sqrt{\\sum^n_{i=1}(A_i)^2}\\times \\sqrt{\\sum^n_{i=1}(B_i)^2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f88316e",
   "metadata": {},
   "source": [
    "### nn.CTCLoss\n",
    "\n",
    "计算CTC损失，解决时序类数据的分类\n",
    "\n",
    "nn.CTCLoss(blank=0, reduction='mean', zero_infinity=False)\n",
    "- blank：空标签\n",
    "- zero_infinity：无穷大的值或者梯度置0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cbe996",
   "metadata": {},
   "source": [
    "# 思维导图\n",
    "\n",
    "<img style=\"float: center;\" src=\"images/98.png\" width=\"70%\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sEMG",
   "language": "python",
   "name": "semg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
