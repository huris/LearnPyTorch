{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a89191c",
   "metadata": {},
   "source": [
    "PyTorch神经网络建模：\n",
    "- 数据准备\n",
    "- 模型建立\n",
    "- 模型训练\n",
    "- 模型评估使用和保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac94b9c2",
   "metadata": {},
   "source": [
    "训练耗时两个原因：\n",
    "- 数据准备：使用更多的进程来准备数据\n",
    "- 参数迭代：GPU进行加速训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a093283",
   "metadata": {},
   "source": [
    "# PyTorch使用GPU加速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90dab60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "features = torch.tensor(range(10))\n",
    "labels = torch.tensor(range(10))\n",
    "\n",
    "model = nn.Linear(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68f9bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) # 移动模型到cuda\n",
    "\n",
    "# 训练模型\n",
    "features = features.to(device) # 移动数据到cuda\n",
    "labels = labels.to(device)  # 或者  labels = labels.cuda() if torch.cuda.is_available() else labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c51783",
   "metadata": {},
   "source": [
    "如果要使用多个GPU训练模型，可以将模型设置为数据并行风格。\n",
    "\n",
    "则模型移动到GPU上之后，会在每个GPU上拷贝一个副本，并把数据平分到各个GPU上进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a73e33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model) # 包装为并行风格模型\n",
    "\n",
    "# 训练模型\n",
    "features = features.to(device) # 移动数据到cuda\n",
    "labels = labels.to(device) # 或者 labels = labels.cuda() if torch.cuda.is_available() else labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039dc2cf",
   "metadata": {},
   "source": [
    "# GPU相关操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88546c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if_cuda= True\n"
     ]
    }
   ],
   "source": [
    "# 查看gpu信息\n",
    "if_cuda = torch.cuda.is_available()\n",
    "print(\"if_cuda=\", if_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "137581d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_count= 1\n"
     ]
    }
   ],
   "source": [
    "# GPU的数量\n",
    "gpu_count = torch.cuda.device_count()\n",
    "print(\"gpu_count=\", gpu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "591fb4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "True\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 将张量在gpu和cpu间移动\n",
    "tensor = torch.rand((100,100))\n",
    "tensor_gpu = tensor.to(\"cuda:0\") # 或者 tensor_gpu = tensor.cuda()\n",
    "print(tensor_gpu.device)\n",
    "print(tensor_gpu.is_cuda)\n",
    "\n",
    "tensor_cpu = tensor_gpu.to(\"cpu\") # 或者 tensor_cpu = tensor_gpu.cpu() \n",
    "print(tensor_cpu.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b01e78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 查看数据与模型的device\n",
    "tensor = torch.rand((100,100))\n",
    "print(tensor.device)\n",
    "\n",
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d070d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 将模型中的全部张量移动到gpu上\n",
    "net = nn.Linear(2, 1)\n",
    "print(next(net.parameters()).is_cuda)\n",
    "net.to(\"cuda:0\") # 将模型中的全部参数张量依次到GPU上，无需重新赋值net = net.to(\"cuda:0\")\n",
    "print(next(net.parameters()).is_cuda)\n",
    "print(next(net.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2bf1150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "[0]\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 创建支持多个gpu数据并行的模型\n",
    "linear = nn.Linear(2,1)\n",
    "print(next(linear.parameters()).device)\n",
    "\n",
    "model = nn.DataParallel(linear)\n",
    "print(model.device_ids)\n",
    "print(next(model.module.parameters()).device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "143b345c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注意保存参数时要指定保存model.module的参数\n",
    "torch.save(model.module.state_dict(), \"model_parameter.pkl\") \n",
    "\n",
    "linear = nn.Linear(2,1)\n",
    "linear.load_state_dict(torch.load(\"model_parameter.pkl\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de4e64a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清空cuda缓存, 该方在cuda超内存时十分有用\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201acb35",
   "metadata": {},
   "source": [
    "# 线性回归范例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74d7558e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available() =  True\n",
      "{'epoch': 0, 'loss': 214.75949096679688}\n",
      "{'epoch': 50, 'loss': 33.45890808105469}\n",
      "{'epoch': 100, 'loss': 9.039307594299316}\n",
      "{'epoch': 150, 'loss': 4.49655818939209}\n",
      "{'epoch': 200, 'loss': 4.030478000640869}\n",
      "{'epoch': 250, 'loss': 4.006821632385254}\n",
      "{'epoch': 300, 'loss': 4.006302356719971}\n",
      "{'epoch': 350, 'loss': 4.006300449371338}\n",
      "{'epoch': 400, 'loss': 4.0062994956970215}\n",
      "{'epoch': 450, 'loss': 4.006317615509033}\n",
      "time used: 0.6919867992401123\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 准备数据\n",
    "n = 1000000\n",
    "\n",
    "X = 10 * torch.rand([n, 2]) - 5.0  #torch.rand是均匀分布 \n",
    "w0 = torch.tensor([[2.0, -3.0]])\n",
    "b0 = torch.tensor([[10.0]])\n",
    "# @表示矩阵乘法, 增加正态扰动\n",
    "Y = X @ w0.t() + b0 + torch.normal(0.0, 2.0, size = [n, 1])\n",
    "\n",
    "# 移动到GPU上\n",
    "print(\"torch.cuda.is_available() = \", torch.cuda.is_available())\n",
    "X = X.cuda()\n",
    "Y = Y.cuda()\n",
    "\n",
    "# 定义模型\n",
    "class LinearRegression(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.w = nn.Parameter(torch.randn_like(w0))\n",
    "        self.b = nn.Parameter(torch.zeros_like(b0))\n",
    "    \n",
    "    #正向传播\n",
    "    def forward(self,x): \n",
    "        return x @ self.w.t() + self.b\n",
    "\n",
    "\n",
    "linear = LinearRegression() \n",
    "\n",
    "# 移动模型到GPU上\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "linear.to(device)\n",
    "\n",
    "# 训练模型\n",
    "optimizer = torch.optim.Adam(linear.parameters(), lr=0.1)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "\n",
    "def train(epoches):\n",
    "    tic = time.time()\n",
    "    for epoch in range(epoches):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        Y_pred = linear(X) \n",
    "        loss = loss_func(Y_pred, Y)\n",
    "        \n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 50==0:\n",
    "            print({\"epoch\":epoch, \"loss\":loss.item()})\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"time used:\",toc-tic)\n",
    "\n",
    "\n",
    "train(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162ad4b",
   "metadata": {},
   "source": [
    "# torchkeras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb68c707",
   "metadata": {},
   "source": [
    "## torchkeras单个GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2428ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchkeras\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torchkeras.Model(LinearRegression())\n",
    "\n",
    "# 注意此处compile时指定了device\n",
    "model.compile(loss_func = nn.MSELoss(),\n",
    "             optimizer= torch.optim.Adam(model.parameters(), lr=0.1),\n",
    "             device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47ff39",
   "metadata": {},
   "source": [
    "## torchkeras多GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "144940dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 30, 30]             320\n",
      "         MaxPool2d-2           [-1, 32, 15, 15]               0\n",
      "            Conv2d-3           [-1, 64, 11, 11]          51,264\n",
      "         MaxPool2d-4             [-1, 64, 5, 5]               0\n",
      "         Dropout2d-5             [-1, 64, 5, 5]               0\n",
      " AdaptiveMaxPool2d-6             [-1, 64, 1, 1]               0\n",
      "           Flatten-7                   [-1, 64]               0\n",
      "            Linear-8                   [-1, 32]           2,080\n",
      "              ReLU-9                   [-1, 32]               0\n",
      "           Linear-10                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 53,994\n",
      "Trainable params: 53,994\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.003906\n",
      "Forward/backward pass size (MB): 0.359695\n",
      "Params size (MB): 0.205971\n",
      "Estimated Total Size (MB): 0.569572\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class CnnModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1,out_channels=32,kernel_size = 3),\n",
    "            nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
    "            nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5),\n",
    "            nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
    "            nn.Dropout2d(p = 0.1),\n",
    "            nn.AdaptiveMaxPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,10)]\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)  \n",
    "        return x\n",
    "\n",
    "net = nn.DataParallel(CnnModule())  #Attention this line!!!   这一行， 要封装成并行的方式\n",
    "model = torchkeras.Model(net)\n",
    "\n",
    "model.summary(input_shape=(1,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69c7cd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchkeras import summary, Model\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "ds_train = torchvision.datasets.MNIST(root=\"data/minist/\", train=True, download=True, transform=transform)\n",
    "ds_valid = torchvision.datasets.MNIST(root=\"data/minist/\", train=False, download=True, transform=transform)\n",
    "\n",
    "dl_train =  torch.utils.data.DataLoader(ds_train, batch_size=128, shuffle=True, num_workers=4)\n",
    "dl_valid =  torch.utils.data.DataLoader(ds_valid, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "print(len(ds_train))  # 60000\n",
    "print(len(ds_valid))  # 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a281f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training ...\n",
      "\n",
      "================================================================================2022-02-09 10:54:30\n",
      "{'step': 100, 'loss': 0.899, 'accuracy': 0.676}\n",
      "{'step': 200, 'loss': 0.573, 'accuracy': 0.802}\n",
      "{'step': 300, 'loss': 0.459, 'accuracy': 0.846}\n",
      "{'step': 400, 'loss': 0.398, 'accuracy': 0.87}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   1   | 0.362 |  0.882   |  0.078   |    0.976     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-09 10:54:35\n",
      "{'step': 100, 'loss': 0.129, 'accuracy': 0.962}\n",
      "{'step': 200, 'loss': 0.135, 'accuracy': 0.96}\n",
      "{'step': 300, 'loss': 0.157, 'accuracy': 0.955}\n",
      "{'step': 400, 'loss': 0.151, 'accuracy': 0.957}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   2   | 0.148 |  0.958   |  0.131   |     0.97     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-09 10:54:39\n",
      "{'step': 100, 'loss': 0.168, 'accuracy': 0.954}\n",
      "{'step': 200, 'loss': 0.163, 'accuracy': 0.956}\n",
      "{'step': 300, 'loss': 0.195, 'accuracy': 0.95}\n",
      "{'step': 400, 'loss': 0.212, 'accuracy': 0.947}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   3   | 0.209 |  0.948   |   0.11   |    0.973     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-09 10:54:43\n",
      "Finished Training...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def accuracy(y_pred,y_true):\n",
    "    y_pred_cls = torch.argmax(nn.Softmax(dim=1)(y_pred),dim=1).data\n",
    "    return accuracy_score(y_true.cpu().numpy(),y_pred_cls.cpu().numpy()) \n",
    "    # 注意此处要将数据先移动到cpu上，然后才能转换成numpy数组\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.compile(loss_func = nn.CrossEntropyLoss(),\n",
    "             optimizer= torch.optim.Adam(model.parameters(),lr = 0.02),\n",
    "             metrics_dict={\"accuracy\":accuracy},device = device) # 注意此处compile时指定了device\n",
    "\n",
    "dfhistory = model.fit(3,dl_train = dl_train, dl_val=dl_valid, log_step_freq=100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e15bc1c",
   "metadata": {},
   "source": [
    "保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1f92889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.10967098912990451, 'val_accuracy': 0.9728045886075949}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model parameters\n",
    "torch.save(model.net.module.state_dict(), \"model_parameter.pkl\")  # 这里的model.net.module\n",
    "\n",
    "net_clone = CnnModule()\n",
    "net_clone.load_state_dict(torch.load(\"model_parameter.pkl\"))\n",
    "\n",
    "model_clone = torchkeras.Model(net_clone)\n",
    "model_clone.compile(loss_func = nn.CrossEntropyLoss(),\n",
    "             optimizer= torch.optim.Adam(model.parameters(),lr = 0.02),\n",
    "             metrics_dict={\"accuracy\":accuracy},device = device)\n",
    "model_clone.evaluate(dl_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sEMG",
   "language": "python",
   "name": "semg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
